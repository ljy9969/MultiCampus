{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD9gUQpaBxNa"
   },
   "source": [
    "# YOLOv5 on Custom Objects\n",
    "\n",
    "To train our detector we take the following steps:\n",
    "\n",
    "* Install YOLOv5 dependencies\n",
    "* Download custom YOLOv5 object detection data\n",
    "* Write our YOLOv5 Training configuration\n",
    "* Run YOLOv5 training\n",
    "* Evaluate YOLOv5 performance\n",
    "* Visualize YOLOv5 training data\n",
    "* Run YOLOv5 inference on test images\n",
    "* Export saved YOLOv5 weights for future inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "# wandb.login()\n",
    "# wandb.init(project=\"YOLOv5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ie5uLDH4uzAp",
    "outputId": "34e3857c-7780-4c62-b257-9a8058cfc1be",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "/home/lab03/EvolveYOLO/yolov5\n",
      "HEAD is now at 886f1c0 DDP after autoanchor reorder (#2421)\n"
     ]
    }
   ],
   "source": [
    "# clone YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "!git reset --hard 886f1c03d839575afecb059accf74296fad395b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wbvMlHd_QwMG",
    "outputId": "91c4fd5a-2f23-4393-e9ef-0ac530f6ce07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Setup complete. Using torch 1.8.1+cu111 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "# install dependencies as necessary\n",
    "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "from utils.google_utils import gdrive_download  # to download models/datasets\n",
    "\n",
    "# clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Knxi2ncxWffW",
    "outputId": "887cdb86-b534-4209-9372-6ec31885f59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=roboflow-yolov5\n"
     ]
    }
   ],
   "source": [
    "#follow the link below to get your download code from from Roboflow\n",
    "!pip install -q roboflow\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ug_PhK1oqwQA",
    "outputId": "7af362bb-621b-4696-9eb0-cea376f06967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab03/EvolveYOLO/yolov5\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in Geranium-3 to yolov5pytorch: 100% [17756282 / 17756282] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Geranium-3 in yolov5pytorch:: 100%|██████████| 2616/2616 [00:00<00:00, 7722.70it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd ./\n",
    "#after following the link above, recieve python code with these fields filled in\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"QWencAPU4nMRzIBHlDhp\")\n",
    "project = rf.workspace(\"smart-pot\").project(\"geranium\")\n",
    "dataset = project.version(3).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zk3vl9cebmBk"
   },
   "outputs": [],
   "source": [
    "# curl -L \"https://app.roboflow.com/ds/EbfTvnORki?key=IHIDfi7nN4\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"dataset.location\"] = \"./datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZZ3DmmGQztJj",
    "outputId": "6ff5fd2f-92a7-452b-9825-cbf1f5dfa1c9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names: ['Geranium', 'Geranium Gray Mold', 'Geranium Leaf Spot', 'Geranium Pest Damage']\r\n",
      "nc: 4\r\n",
      "train: Geranium-3/train/images\r\n",
      "val: Geranium-3/valid/images\r\n",
      "test: Geranium-3/test/images"
     ]
    }
   ],
   "source": [
    "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
    "%cat {dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count images on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302\n",
      "1140\n",
      "108\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "!find {dataset.location} -name *.jpg | wc -l\n",
    "!find {dataset.location}/train -name *.jpg | wc -l\n",
    "!find {dataset.location}/valid -name *.jpg | wc -l\n",
    "!find {dataset.location}/test -name *.jpg | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwJx-2NHsYxT"
   },
   "source": [
    "# Define Model Configuration and Architecture\n",
    "\n",
    "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n",
    "\n",
    "You do not need to edit these cells, but you may."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dOPn9wjOAwwK"
   },
   "outputs": [],
   "source": [
    "# define number of classes based on YAML\n",
    "import yaml\n",
    "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1Rvt5wilnDyX",
    "outputId": "a061f445-aaa0-48d5-e6d3-93af55fb355b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parameters\r\n",
      "nc: 80  # number of classes\r\n",
      "depth_multiple: 0.33  # model depth multiple\r\n",
      "width_multiple: 0.50  # layer channel multiple\r\n",
      "\r\n",
      "# anchors\r\n",
      "anchors:\r\n",
      "  - [10,13, 16,30, 33,23]  # P3/8\r\n",
      "  - [30,61, 62,45, 59,119]  # P4/16\r\n",
      "  - [116,90, 156,198, 373,326]  # P5/32\r\n",
      "\r\n",
      "# YOLOv5 backbone\r\n",
      "backbone:\r\n",
      "  # [from, number, module, args]\r\n",
      "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\r\n",
      "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\r\n",
      "   [-1, 3, C3, [128]],\r\n",
      "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\r\n",
      "   [-1, 9, C3, [256]],\r\n",
      "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\r\n",
      "   [-1, 9, C3, [512]],\r\n",
      "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\r\n",
      "   [-1, 1, SPP, [1024, [5, 9, 13]]],\r\n",
      "   [-1, 3, C3, [1024, False]],  # 9\r\n",
      "  ]\r\n",
      "\r\n",
      "# YOLOv5 head\r\n",
      "head:\r\n",
      "  [[-1, 1, Conv, [512, 1, 1]],\r\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\r\n",
      "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\r\n",
      "   [-1, 3, C3, [512, False]],  # 13\r\n",
      "\r\n",
      "   [-1, 1, Conv, [256, 1, 1]],\r\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\r\n",
      "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\r\n",
      "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\r\n",
      "\r\n",
      "   [-1, 1, Conv, [256, 3, 2]],\r\n",
      "   [[-1, 14], 1, Concat, [1]],  # cat head P4\r\n",
      "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\r\n",
      "\r\n",
      "   [-1, 1, Conv, [512, 3, 2]],\r\n",
      "   [[-1, 10], 1, Concat, [1]],  # cat head P5\r\n",
      "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\r\n",
      "\r\n",
      "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\r\n",
      "  ]\r\n"
     ]
    }
   ],
   "source": [
    "#this is the model configuration we will use for our tutorial \n",
    "%cat ./models/yolov5s.yaml\n",
    "# %cat ./models/yolov5m.yaml\n",
    "# %cat ./models/yolov5x.yaml\n",
    "# %cat ./models/hub/yolov5l6.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "t14hhyqdmw6O"
   },
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uDxebz13RdRA"
   },
   "outputs": [],
   "source": [
    "%%writetemplate ./models/custom_yolov5s.yaml\n",
    "\n",
    "# parameters\n",
    "nc: {num_classes}  # number of classes\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, C3, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, C3, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, C3, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, C3, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, C3, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUOiNLtMP5aG"
   },
   "source": [
    "# Train Custom YOLOv5 Detector\n",
    "\n",
    "### Next, we'll fire off training!\n",
    "\n",
    "\n",
    "Here, we are able to pass a number of arguments:\n",
    "- **img:** define input image size\n",
    "- **batch:** determine batch size\n",
    "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
    "- **data:** set the path to our yaml file\n",
    "- **cfg:** specify our model configuration\n",
    "- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n",
    "- **name:** result names\n",
    "- **nosave:** only save the final checkpoint\n",
    "- **cache:** cache images for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zvsnVTpBAObq",
    "outputId": "92caf0d2-116e-4f36-df62-a39357acc237",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Hyperparameters for COCO training from scratch\r\n",
      "# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\r\n",
      "# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\r\n",
      "\r\n",
      "\r\n",
      "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\r\n",
      "lrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)\r\n",
      "momentum: 0.937  # SGD momentum/Adam beta1\r\n",
      "weight_decay: 0.0005  # optimizer weight decay 5e-4\r\n",
      "warmup_epochs: 3.0  # warmup epochs (fractions ok)\r\n",
      "warmup_momentum: 0.8  # warmup initial momentum\r\n",
      "warmup_bias_lr: 0.1  # warmup initial bias lr\r\n",
      "box: 0.05  # box loss gain\r\n",
      "cls: 0.5  # cls loss gain\r\n",
      "cls_pw: 1.0  # cls BCELoss positive_weight\r\n",
      "obj: 1.0  # obj loss gain (scale with pixels)\r\n",
      "obj_pw: 1.0  # obj BCELoss positive_weight\r\n",
      "iou_t: 0.20  # IoU training threshold\r\n",
      "anchor_t: 4.0  # anchor-multiple threshold\r\n",
      "# anchors: 3  # anchors per output layer (0 to ignore)\r\n",
      "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\r\n",
      "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\r\n",
      "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\r\n",
      "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\r\n",
      "degrees: 0.0  # image rotation (+/- deg)\r\n",
      "translate: 0.1  # image translation (+/- fraction)\r\n",
      "scale: 0.5  # image scale (+/- gain)\r\n",
      "shear: 0.0  # image shear (+/- deg)\r\n",
      "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\r\n",
      "flipud: 0.0  # image flip up-down (probability)\r\n",
      "fliplr: 0.5  # image flip left-right (probability)\r\n",
      "mosaic: 1.0  # image mosaic (probability)\r\n",
      "mixup: 0.0  # image mixup (probability)\r\n"
     ]
    }
   ],
   "source": [
    "%cat ./data/hyp.scratch.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YhGDpUkHFpx5",
    "outputId": "656c06bc-9476-4fce-e8a7-86b48b820993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Google utils: https://cloud.google.com/storage/docs/reference/libraries\r\n",
      "\r\n",
      "import os\r\n",
      "import platform\r\n",
      "import subprocess\r\n",
      "import time\r\n",
      "from pathlib import Path\r\n",
      "\r\n",
      "import requests\r\n",
      "import torch\r\n",
      "\r\n",
      "\r\n",
      "def gsutil_getsize(url=''):\r\n",
      "    # gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du\r\n",
      "    s = subprocess.check_output(f'gsutil du {url}', shell=True).decode('utf-8')\r\n",
      "    return eval(s.split(' ')[0]) if len(s) else 0  # bytes\r\n",
      "\r\n",
      "\r\n",
      "def attempt_download(file, repo='ultralytics/yolov5'):\r\n",
      "    # Attempt file download if does not exist\r\n",
      "    file = Path(str(file).strip().replace(\"'\", '').lower())\r\n",
      "\r\n",
      "    if not file.exists():\r\n",
      "        try:\r\n",
      "            response = requests.get(f'https://api.github.com/repos/{repo}/releases/tags/v5.0').json() # github api\r\n",
      "            assets = [x['name'] for x in response['assets']]  # release assets, i.e. ['yolov5s.pt', 'yolov5m.pt', ...]\r\n",
      "            tag = response['tag_name']  # i.e. 'v1.0'\r\n",
      "        except:  # fallback plan\r\n",
      "            assets = ['yolov5s.pt', 'yolov5m.pt', 'yolov5l.pt', 'yolov5x.pt']\r\n",
      "            tag = subprocess.check_output('git tag', shell=True).decode().split()[-1]\r\n",
      "\r\n",
      "        name = file.name\r\n",
      "        if name in assets:\r\n",
      "            msg = f'{file} missing, try downloading from https://github.com/{repo}/releases/'\r\n",
      "            redundant = False  # second download option\r\n",
      "            try:  # GitHub\r\n",
      "                url = f'https://github.com/{repo}/releases/download/{tag}/{name}'\r\n",
      "                print(f'Downloading {url} to {file}...')\r\n",
      "                torch.hub.download_url_to_file(url, file)\r\n",
      "                assert file.exists() and file.stat().st_size > 1E6  # check\r\n",
      "            except Exception as e:  # GCP\r\n",
      "                print(f'Download error: {e}')\r\n",
      "                assert redundant, 'No secondary mirror'\r\n",
      "                url = f'https://storage.googleapis.com/{repo}/ckpt/{name}'\r\n",
      "                print(f'Downloading {url} to {file}...')\r\n",
      "                os.system(f'curl -L {url} -o {file}')  # torch.hub.download_url_to_file(url, weights)\r\n",
      "            finally:\r\n",
      "                if not file.exists() or file.stat().st_size < 1E6:  # check\r\n",
      "                    file.unlink(missing_ok=True)  # remove partial downloads\r\n",
      "                    print(f'ERROR: Download failure: {msg}')\r\n",
      "                print('')\r\n",
      "                return\r\n",
      "\r\n",
      "\r\n",
      "def gdrive_download(id='16TiPfZj7htmTyhntwcZyEEAejOUxuT6m', file='tmp.zip'):\r\n",
      "    # Downloads a file from Google Drive. from yolov5.utils.google_utils import *; gdrive_download()\r\n",
      "    t = time.time()\r\n",
      "    file = Path(file)\r\n",
      "    cookie = Path('cookie')  # gdrive cookie\r\n",
      "    print(f'Downloading https://drive.google.com/uc?export=download&id={id} as {file}... ', end='')\r\n",
      "    file.unlink(missing_ok=True)  # remove existing file\r\n",
      "    cookie.unlink(missing_ok=True)  # remove existing cookie\r\n",
      "\r\n",
      "    # Attempt file download\r\n",
      "    out = \"NUL\" if platform.system() == \"Windows\" else \"/dev/null\"\r\n",
      "    os.system(f'curl -c ./cookie -s -L \"drive.google.com/uc?export=download&id={id}\" > {out}')\r\n",
      "    if os.path.exists('cookie'):  # large file\r\n",
      "        s = f'curl -Lb ./cookie \"drive.google.com/uc?export=download&confirm={get_token()}&id={id}\" -o {file}'\r\n",
      "    else:  # small file\r\n",
      "        s = f'curl -s -L -o {file} \"drive.google.com/uc?export=download&id={id}\"'\r\n",
      "    r = os.system(s)  # execute, capture return\r\n",
      "    cookie.unlink(missing_ok=True)  # remove existing cookie\r\n",
      "\r\n",
      "    # Error check\r\n",
      "    if r != 0:\r\n",
      "        file.unlink(missing_ok=True)  # remove partial\r\n",
      "        print('Download error ')  # raise Exception('Download error')\r\n",
      "        return r\r\n",
      "\r\n",
      "    # Unzip if archive\r\n",
      "    if file.suffix == '.zip':\r\n",
      "        print('unzipping... ', end='')\r\n",
      "        os.system(f'unzip -q {file}')  # unzip\r\n",
      "        file.unlink()  # remove zip to free space\r\n",
      "\r\n",
      "    print(f'Done ({time.time() - t:.1f}s)')\r\n",
      "    return r\r\n",
      "\r\n",
      "\r\n",
      "def get_token(cookie=\"./cookie\"):\r\n",
      "    with open(cookie) as f:\r\n",
      "        for line in f:\r\n",
      "            if \"download\" in line:\r\n",
      "                return line.split()[-1]\r\n",
      "    return \"\"\r\n",
      "\r\n",
      "# def upload_blob(bucket_name, source_file_name, destination_blob_name):\r\n",
      "#     # Uploads a file to a bucket\r\n",
      "#     # https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python\r\n",
      "#\r\n",
      "#     storage_client = storage.Client()\r\n",
      "#     bucket = storage_client.get_bucket(bucket_name)\r\n",
      "#     blob = bucket.blob(destination_blob_name)\r\n",
      "#\r\n",
      "#     blob.upload_from_filename(source_file_name)\r\n",
      "#\r\n",
      "#     print('File {} uploaded to {}.'.format(\r\n",
      "#         source_file_name,\r\n",
      "#         destination_blob_name))\r\n",
      "#\r\n",
      "#\r\n",
      "# def download_blob(bucket_name, source_blob_name, destination_file_name):\r\n",
      "#     # Uploads a blob from a bucket\r\n",
      "#     storage_client = storage.Client()\r\n",
      "#     bucket = storage_client.get_bucket(bucket_name)\r\n",
      "#     blob = bucket.blob(source_blob_name)\r\n",
      "#\r\n",
      "#     blob.download_to_filename(destination_file_name)\r\n",
      "#\r\n",
      "#     print('Blob {} downloaded to {}.'.format(\r\n",
      "#         source_blob_name,\r\n",
      "#         destination_file_name))\r\n"
     ]
    }
   ],
   "source": [
    "%cat ./utils/google_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %cd ./\n",
    "# !python train.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"YOLOv5\",\n",
    "#            config={\n",
    "#                \"batch_size\": 32,\n",
    "#                \"learning_rate\": 0.01,\n",
    "#                \"dataset\": \"Geranium-2\",\n",
    "#            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics/mAP_0.5 0.33859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1NcFxRcFdJ_O",
    "outputId": "c6d79ddc-8011-4532-9b9b-12e3d23d511b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab03/EvolveYOLO/yolov5\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 1118 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
      "YOLOv5 v4.0-126-g886f1c0 torch 1.8.1+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Namespace(adam=False, batch_size=8, bucket='', cache_images=True, cfg='./models/custom_yolov5s.yaml', data='/home/lab03/EvolveYOLO/yolov5/Geranium-3/data.yaml', device='', entity=None, epochs=10, evolve=False, exist_ok=False, global_rank=-1, hyp='./data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], linear_lr=False, local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='yolov5l6_geranium', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov5l6_geranium2', single_cls=False, sync_bn=False, total_batch_size=8, weights='yolov5s.pt', workers=8, world_size=1)\n",
      "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mangelajlee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_221437-1gpss0mj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5l6_geranium2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1gpss0mj\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1154.70it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100%|███████████| 108/108 [00:00<00:00, 818.30it/s]\u001b[0m\n",
      "Plotting labels... \n",
      "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.90, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/yolov5l6_geranium2\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.761G   0.08741   0.02988   0.04213    0.1594        11       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197      0.0391      0.0609      0.0173     0.00443\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.07574   0.03148   0.03923    0.1464         7       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197      0.0396       0.142      0.0201     0.00306\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G     0.066   0.03511    0.0378    0.1389        12       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.108       0.208      0.0531     0.00867\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.05615   0.03601   0.03659    0.1287        11       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.207       0.157      0.0774       0.019\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.05091   0.03371   0.03632    0.1209        15       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.262       0.193      0.0794      0.0263\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.04558   0.02986   0.03652     0.112        10       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.237       0.247      0.0899      0.0291\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.04418    0.0288   0.03514    0.1081        10       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.409       0.269       0.191      0.0703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.04009   0.02591   0.03608    0.1021         6       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.331       0.239        0.12      0.0404\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.03512   0.02491   0.03445   0.09448        12       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.289       0.203      0.0914      0.0307\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.03234   0.02271   0.03586   0.09091         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.272       0.239       0.108      0.0393\n",
      "            Geranium         108         197       0.272       0.239       0.108      0.0393\n",
      "Optimizer stripped from runs/train/yolov5l6_geranium2/weights/last.pt, 14.8MB\n",
      "Optimizer stripped from runs/train/yolov5l6_geranium2/weights/best.pt, 14.8MB\n",
      "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
      "10 epochs completed in 0.063 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▂▃▃▄█▅▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▂▃▃▄█▅▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▂▄▅▅█▇▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▄▆▄▅▇█▇▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▄▃▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▃▃▂▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆██▇▅▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss █▂▁▃▄▄▁▄▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▄▇▆▇▇███▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▄▇█▅▂▁▃▂▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.10791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.03927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.27245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.23858\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.03234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.03586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02271\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.06019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.05439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov5l6_geranium2\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1gpss0mj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 49 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_221437-1gpss0mj/logs\u001b[0m\n",
      "CPU times: user 4.57 s, sys: 806 ms, total: 5.37 s\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%%wandb\n",
    "\n",
    "%cd ./\n",
    "!python train.py \\\n",
    "--img 416 \\\n",
    "--batch 8 \\\n",
    "--epochs 10 \\\n",
    "--data {dataset.location}/data.yaml \\\n",
    "--cfg ./models/custom_yolov5s.yaml \\\n",
    "--weights yolov5s.pt \\\n",
    "--name yolov5s_geranium \\\n",
    "--cache \\\n",
    "--hyp \"./data/hyp.scratch.yaml\" \\\n",
    "# --resume \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Evolution (Optional. 300 scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 1118 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
      "YOLOv5 v4.0-126-g886f1c0 torch 1.8.1+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Namespace(adam=False, batch_size=8, bucket='', cache_images=True, cfg='./models/custom_yolov5s.yaml', data='/home/lab03/EvolveYOLO/yolov5/Geranium-3/data.yaml', device='', entity=None, epochs=10, evolve=True, exist_ok=False, global_rank=-1, hyp='./data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], linear_lr=False, local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='evolve', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/evolve', single_cls=False, sync_bn=False, total_batch_size=8, weights='yolov5s.pt', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.22969, momentum=0.73434, weight_decay=0.00019, warmup_epochs=1.63, warmup_momentum=0.88098, warmup_bias_lr=0.15817, box=0.0206, cls=0.38576, cls_pw=0.95222, obj=1.11, obj_pw=0.77324, iou_t=0.2, anchor_t=3.13496, anchors=4.17903, fl_gamma=0.0, hsv_h=0.01572, hsv_s=0.59721, hsv_v=0.30511, degrees=0.0, translate=0.09205, scale=0.348, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.62849, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=4.17903\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mangelajlee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_222114-3lrze5o7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3lrze5o7\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1143.36it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.32: 1.0000 best possible recall, 9.72 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.586-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.32: 1.0000 best possible recall, 9.72 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.587-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.763G   0.03399   0.03082   0.03213   0.09694         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.02909   0.03301   0.03021   0.09231         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.02341   0.03565   0.02933   0.08839         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G   0.01971   0.03504   0.02877   0.08353         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.01917   0.03457   0.02842   0.08216         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G   0.01824   0.03166   0.02821   0.07812         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G   0.01857   0.02969   0.02816   0.07642         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.01847   0.02732   0.02831    0.0741         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G   0.01671   0.02675   0.02789   0.07134         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       9/9    0.807G   0.01517   0.02541   0.02792    0.0685         6       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197        0.44       0.193       0.143      0.0525\n",
      "            Geranium         108         197        0.44       0.193       0.143      0.0525\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▂▂▂▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆██▇▅▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14347\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.43975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02523\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3lrze5o7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_222114-3lrze5o7/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152      0.23     0.734   0.00019      1.63     0.881     0.158    0.0206     0.386     0.952      1.11     0.773       0.2      3.13      4.18         0    0.0157     0.597     0.305         0    0.0921     0.348         0         0         0       0.5     0.628         0\n",
      "Evolved fitness:     0.4398    0.1929    0.1435   0.05251   0.02542   0.02523   0.04107\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.19473, momentum=0.77782, weight_decay=0.00019, warmup_epochs=1.63, warmup_momentum=0.79996, warmup_bias_lr=0.13607, box=0.02633, cls=0.38822, cls_pw=0.86562, obj=1.1558, obj_pw=0.734, iou_t=0.2, anchor_t=2.72676, anchors=2.23775, fl_gamma=0.0, hsv_h=0.018, hsv_s=0.69345, hsv_v=0.3705, degrees=0.0, translate=0.0612, scale=0.34594, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.5699, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.23775\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_222329-3dl58kgm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3dl58kgm\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1147.35it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 4.52 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.623-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 4.46 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.627-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.887G   0.04156   0.02827   0.03013   0.09996         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.889G   0.03653   0.02948   0.02818   0.09419         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.889G   0.02875   0.03207   0.02714   0.08795         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.889G    0.0235   0.03393   0.02706   0.08448        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.889G   0.02235   0.03171   0.02704    0.0811         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.889G   0.02256   0.02947   0.02668   0.07872         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.889G   0.02207   0.02856   0.02681   0.07744         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.889G   0.02208   0.02588   0.02624   0.07421         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.889G   0.01939   0.02493   0.02575   0.07008         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.889G   0.01728   0.02361   0.02517   0.06606         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.312       0.234       0.185       0.076\n",
      "            Geranium         108         197       0.312       0.234       0.185       0.076\n",
      "10 epochs completed in 0.045 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▄▄▃▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅▇█▆▅▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.18516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.07596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.31195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3dl58kgm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_222329-3dl58kgm/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.195     0.778   0.00019      1.63       0.8     0.136    0.0263     0.388     0.866      1.16     0.734       0.2      2.73      2.24         0     0.018     0.693      0.37         0    0.0612     0.346         0         0         0       0.5      0.57         0\n",
      "Evolved fitness:     0.3119    0.2335    0.1852   0.07596   0.03314   0.02157   0.02461\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01513, lrf=0.207, momentum=0.76717, weight_decay=0.0002, warmup_epochs=1.62016, warmup_momentum=0.77261, warmup_bias_lr=0.13553, box=0.0244, cls=0.38865, cls_pw=0.822, obj=1.03395, obj_pw=0.74974, iou_t=0.2, anchor_t=2.69823, anchors=2.8249, fl_gamma=0.0, hsv_h=0.01739, hsv_s=0.72868, hsv_v=0.35875, degrees=0.0, translate=0.0659, scale=0.34315, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.61253, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.8249\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_222628-f9xgbnrc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/f9xgbnrc\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 747.31it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.59 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.615-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.59 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.620-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.929G   0.03885     0.026   0.02928   0.09412         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.931G   0.03465   0.02755   0.02801   0.09021         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.931G   0.02771   0.03006    0.0273   0.08507         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.931G    0.0228   0.03115   0.02697   0.08092         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.931G   0.02057   0.03173    0.0263    0.0786         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.931G   0.01972   0.03139   0.02619   0.07729         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.931G   0.01936   0.02872   0.02606   0.07413         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.931G   0.01949   0.02779     0.026   0.07328         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.931G   0.01733   0.02614   0.02603    0.0695         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.931G    0.0162   0.02427     0.026   0.06646         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.389       0.206       0.115      0.0435\n",
      "            Geranium         108         197       0.389       0.206       0.115      0.0435\n",
      "10 epochs completed in 0.060 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▆▇██▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.11466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.38854\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03609\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00428\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/f9xgbnrc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_222628-f9xgbnrc/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0151     0.207     0.767    0.0002      1.62     0.773     0.136    0.0244     0.389     0.822      1.03      0.75       0.2       2.7      2.82         0    0.0174     0.729     0.359         0    0.0659     0.343         0         0         0       0.5     0.613         0\n",
      "Evolved fitness:     0.3885    0.2064    0.1147   0.04349   0.03026   0.02075   0.03609\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01536, lrf=0.20894, momentum=0.77176, weight_decay=0.00021, warmup_epochs=1.61016, warmup_momentum=0.767, warmup_bias_lr=0.13931, box=0.02488, cls=0.37604, cls_pw=0.86024, obj=1.09349, obj_pw=0.7506, iou_t=0.2, anchor_t=2.62529, anchors=2.75182, fl_gamma=0.0, hsv_h=0.01605, hsv_s=0.77112, hsv_v=0.347, degrees=0.0, translate=0.0659, scale=0.33515, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.58139, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.75182\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_223025-22m38k0i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/22m38k0i\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 899.40it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.44 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.620-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.47 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.624-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03936   0.02627   0.02931   0.09494         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03472   0.02823   0.02805     0.091         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02741   0.03079   0.02693   0.08513         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02304   0.03207   0.02678   0.08189         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02075   0.03183   0.02631   0.07889         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02037   0.03028    0.0264   0.07705         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01985   0.02929   0.02634   0.07549         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01896   0.02782   0.02626   0.07304         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01781   0.02724   0.02606   0.07111         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01685   0.02457    0.0261   0.06752         6       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.425       0.218       0.142      0.0641\n",
      "            Geranium         108         197       0.425       0.218       0.142      0.0641\n",
      "10 epochs completed in 0.038 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▇██▆▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06405\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.42542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.21799\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/22m38k0i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_223025-22m38k0i/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0154     0.209     0.772   0.00021      1.61     0.767     0.139    0.0249     0.376      0.86      1.09     0.751       0.2      2.63      2.75         0     0.016     0.771     0.347         0    0.0659     0.335         0         0         0       0.5     0.581         0\n",
      "Evolved fitness:     0.4254     0.218    0.1419   0.06405   0.03046   0.02122   0.03713\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01556, lrf=0.20508, momentum=0.74493, weight_decay=0.00019, warmup_epochs=1.58141, warmup_momentum=0.77019, warmup_bias_lr=0.12453, box=0.02452, cls=0.383, cls_pw=0.853, obj=1.05164, obj_pw=0.70844, iou_t=0.2, anchor_t=3.00033, anchors=2.91435, fl_gamma=0.0, hsv_h=0.01643, hsv_s=0.79577, hsv_v=0.31246, degrees=0.0, translate=0.0659, scale=0.34368, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.62614, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.91435\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_223259-2389nb2a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2389nb2a\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1199.34it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.33: 1.0000 best possible recall, 7.08 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.597-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.33: 1.0000 best possible recall, 7.07 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.601-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04051   0.02696   0.02976   0.09723         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03647   0.02823   0.02862   0.09332         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02953   0.03123   0.02772   0.08847         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02355   0.03273   0.02723   0.08351        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02094   0.03346   0.02674   0.08115        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02062    0.0325   0.02651   0.07963         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01978   0.03102   0.02663   0.07744         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01966   0.02985   0.02632   0.07584         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01787   0.02761   0.02658   0.07206         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01641   0.02577   0.02617   0.06834         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.439       0.203       0.123      0.0439\n",
      "            Geranium         108         197       0.439       0.203       0.123      0.0439\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▃▆▇█▇▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.12317\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.43907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03898\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2389nb2a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_223259-2389nb2a/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0156     0.205     0.745   0.00019      1.58      0.77     0.125    0.0245     0.383     0.853      1.05     0.708       0.2         3      2.91         0    0.0164     0.796     0.312         0    0.0659     0.344         0         0         0       0.5     0.626         0\n",
      "Evolved fitness:     0.4391     0.203    0.1232   0.04389   0.03305   0.02054   0.03898\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01197, lrf=0.18499, momentum=0.71295, weight_decay=0.00022, warmup_epochs=1.4997, warmup_momentum=0.60981, warmup_bias_lr=0.12584, box=0.02678, cls=0.56047, cls_pw=0.853, obj=1.07786, obj_pw=0.78059, iou_t=0.2, anchor_t=2.60297, anchors=2.40958, fl_gamma=0.0, hsv_h=0.01167, hsv_s=0.741, hsv_v=0.39442, degrees=0.0, translate=0.05962, scale=0.30545, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.40958\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00022\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_223515-2yof4u7z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2yof4u7z\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1157.46it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm::   0%| | 0/1000 [00:00<?, ?\u001b[0m\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 4.37 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.631-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 4.32 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.636-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G   0.04205   0.02739   0.04349    0.1129         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.03938   0.02786   0.04163    0.1089        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.803G    0.0338   0.02941   0.03966    0.1029         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.803G   0.02822   0.03129   0.03914   0.09865         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.803G   0.02477   0.03198   0.03788   0.09463         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02393   0.03212   0.03752   0.09357         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G    0.0226   0.03153   0.03604   0.09016         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02244   0.03078   0.03555   0.08877         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.02053   0.02986   0.03506   0.08546         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01888    0.0287    0.0344   0.08199         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.289       0.193       0.164      0.0606\n",
      "            Geranium         108         197       0.289       0.193       0.164      0.0606\n",
      "10 epochs completed in 0.045 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▆▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▅▅▄▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▄▇██▇▆▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.16358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.28927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2yof4u7z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_223515-2yof4u7z/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "     0.012     0.185     0.713   0.00022       1.5      0.61     0.126    0.0268      0.56     0.853      1.08     0.781       0.2       2.6      2.41         0    0.0117     0.741     0.394         0    0.0596     0.305         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.2893    0.1929    0.1636   0.06063   0.03418   0.02232   0.02459\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01439, lrf=0.1992, momentum=0.75884, weight_decay=0.00019, warmup_epochs=1.69479, warmup_momentum=0.74755, warmup_bias_lr=0.138, box=0.02369, cls=0.38037, cls_pw=0.86416, obj=1.10967, obj_pw=0.76543, iou_t=0.2, anchor_t=2.80727, anchors=2.78226, fl_gamma=0.0, hsv_h=0.01501, hsv_s=0.71847, hsv_v=0.347, degrees=0.0, translate=0.0659, scale=0.36567, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.61678, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.78226\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_223812-3htoj0k5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3htoj0k5\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 859.72it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.77 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.608-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.76 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.613-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03833    0.0293   0.02978    0.0974         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03495   0.03032   0.02861   0.09388         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02893   0.03263   0.02767   0.08923         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02401   0.03378   0.02717   0.08496         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02077   0.03475   0.02678    0.0823         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02049   0.03491   0.02652   0.08192         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01985   0.03156   0.02626   0.07767         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02018   0.03016   0.02614   0.07648         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01795   0.02887   0.02645   0.07326         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01605   0.02685   0.02594   0.06883         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.444       0.208       0.138      0.0522\n",
      "            Geranium         108         197       0.444       0.208       0.138      0.0522\n",
      "10 epochs completed in 0.054 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▄▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▃▂▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▆▇██▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.13767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.44357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01605\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3htoj0k5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_223812-3htoj0k5/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0144     0.199     0.759   0.00019      1.69     0.748     0.138    0.0237      0.38     0.864      1.11     0.765       0.2      2.81      2.78         0     0.015     0.718     0.347         0    0.0659     0.366         0         0         0       0.5     0.617         0\n",
      "Evolved fitness:     0.4436    0.2081    0.1377    0.0522   0.03117   0.02223   0.03497\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.00921, lrf=0.18952, momentum=0.74045, weight_decay=0.00024, warmup_epochs=1.24512, warmup_momentum=0.66946, warmup_bias_lr=0.17381, box=0.02713, cls=0.39481, cls_pw=0.6921, obj=1.04932, obj_pw=0.67058, iou_t=0.2, anchor_t=2.73, anchors=3.97626, fl_gamma=0.0, hsv_h=0.01782, hsv_s=0.70841, hsv_v=0.31444, degrees=0.0, translate=0.0659, scale=0.34653, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.66952, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=3.97626\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00024\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_224145-22fz0jpp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/22fz0jpp\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 903.08it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.82 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.611-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.82 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.612-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.807G   0.04394    0.0247   0.02667    0.0953         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.04137   0.02483    0.0261    0.0923         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.03745    0.0265   0.02562   0.08958         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G    0.0315   0.02832   0.02518   0.08501        14       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.02839    0.0285     0.025    0.0819        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G   0.02496    0.0294   0.02466   0.07902         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G   0.02243   0.03064   0.02446   0.07753         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.02175   0.03105    0.0244    0.0772         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G    0.0202   0.02949   0.02412   0.07381         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.807G   0.01922   0.02963    0.0246   0.07345         3       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.446       0.213       0.154      0.0686\n",
      "            Geranium         108         197       0.446       0.213       0.154      0.0686\n",
      "10 epochs completed in 0.044 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▆▄▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▂▂▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▁▃▅▅▆██▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▃▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.15421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06862\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.44566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02963\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/22fz0jpp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_224145-22fz0jpp/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "   0.00921      0.19      0.74   0.00024      1.25     0.669     0.174    0.0271     0.395     0.692      1.05     0.671       0.2      2.73      3.98         0    0.0178     0.708     0.314         0    0.0659     0.347         0         0         0       0.5      0.67         0\n",
      "Evolved fitness:     0.4457    0.2132    0.1542   0.06862   0.03535   0.01866   0.03417\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.23506, momentum=0.81095, weight_decay=0.00021, warmup_epochs=1.62143, warmup_momentum=0.767, warmup_bias_lr=0.15446, box=0.02511, cls=0.21343, cls_pw=0.81188, obj=1.09, obj_pw=0.77396, iou_t=0.2, anchor_t=2.73, anchors=3.42031, fl_gamma=0.0, hsv_h=0.01886, hsv_s=0.61001, hsv_v=0.41333, degrees=0.0, translate=0.07442, scale=0.35323, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.45743, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.42031\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_224441-5bmeqeh1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/5bmeqeh1\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1200.94it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04014   0.02638   0.01609    0.0826         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03598   0.02811   0.01565   0.07973         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G    0.0286   0.03066   0.01528   0.07454         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02366   0.03163   0.01493   0.07022         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G    0.0214   0.03125   0.01471   0.06736         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02124   0.03052   0.01463   0.06639         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02017   0.02878   0.01449   0.06344         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G    0.0197   0.02695   0.01438   0.06103         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01747   0.02559   0.01452   0.05758         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01633   0.02392   0.01446   0.05472         6       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.356       0.198      0.0994        0.04\n",
      "            Geranium         108         197       0.356       0.198      0.0994        0.04\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▃▂▂▁▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▅▇██▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▃▆▇██▇▇▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▃▆▇██▇▇▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.09935\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.03999\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.35592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02392\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/5bmeqeh1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_224441-5bmeqeh1/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.235     0.811   0.00021      1.62     0.767     0.154    0.0251     0.213     0.812      1.09     0.774       0.2      2.73      3.42         0    0.0189      0.61     0.413         0    0.0744     0.353         0         0         0       0.5     0.457         0\n",
      "Evolved fitness:     0.3559     0.198   0.09935   0.03999   0.03266     0.022   0.01977\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01567, lrf=0.16654, momentum=0.765, weight_decay=0.00018, warmup_epochs=1.37536, warmup_momentum=0.781, warmup_bias_lr=0.138, box=0.02151, cls=0.37613, cls_pw=0.8702, obj=0.96225, obj_pw=0.7624, iou_t=0.2, anchor_t=2.96808, anchors=2.84209, fl_gamma=0.0, hsv_h=0.01449, hsv_s=0.741, hsv_v=0.35039, degrees=0.0, translate=0.0542, scale=0.32702, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.69538, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.84209\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00018\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_224706-hq2shdsj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/hq2shdsj\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1181.66it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 7.03 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.598-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 7.01 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.604-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03536    0.0262   0.02959   0.09115        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03136   0.02787   0.02837    0.0876         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02596   0.03002    0.0274   0.08338         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02105   0.03276   0.02698   0.08079         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01874   0.03216   0.02644   0.07734         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01798   0.03129   0.02617   0.07544         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01769   0.03049   0.02629   0.07447         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       7/9    0.805G   0.01728   0.02862   0.02588   0.07179         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01657   0.02718   0.02586   0.06961         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01454   0.02562   0.02545   0.06561         6       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.332       0.274       0.141      0.0474\n",
      "            Geranium         108         197       0.332       0.274       0.141      0.0474\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▃▅█▇▇▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.33191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.27411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/hq2shdsj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_224706-hq2shdsj/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0157     0.167     0.765   0.00018      1.38     0.781     0.138    0.0215     0.376      0.87     0.962     0.762       0.2      2.97      2.84         0    0.0145     0.741      0.35         0    0.0542     0.327         0         0         0       0.5     0.695         0\n",
      "Evolved fitness:     0.3319    0.2741    0.1406   0.04744   0.02809   0.01967    0.0342\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01473, lrf=0.20462, momentum=0.765, weight_decay=0.0002, warmup_epochs=1.56696, warmup_momentum=0.74774, warmup_bias_lr=0.1334, box=0.0248, cls=0.37824, cls_pw=0.853, obj=1.10114, obj_pw=0.74021, iou_t=0.2, anchor_t=2.77473, anchors=2.86296, fl_gamma=0.0, hsv_h=0.01615, hsv_s=0.73709, hsv_v=0.34762, degrees=0.0, translate=0.06779, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.59364, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.86296\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_224922-2s37r760\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2s37r760\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1158.88it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.71 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.610-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.71 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.615-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03997   0.02717   0.02934   0.09648         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03653   0.02842   0.02815    0.0931         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02979   0.03142   0.02718   0.08839         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02495   0.03219   0.02679   0.08394         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02161   0.03334   0.02634   0.08129         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02042   0.03294   0.02629   0.07965        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02026   0.03072   0.02622    0.0772         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01975    0.0292   0.02568   0.07463         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01788   0.02834   0.02611   0.07233        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01683   0.02613   0.02559   0.06855         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.392       0.226       0.105      0.0423\n",
      "            Geranium         108         197       0.392       0.226       0.105      0.0423\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▃▆▇██▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.10509\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.39204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22587\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03356\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2s37r760\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_224922-2s37r760/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0147     0.205     0.765    0.0002      1.57     0.748     0.133    0.0248     0.378     0.853       1.1      0.74       0.2      2.77      2.86         0    0.0162     0.737     0.348         0    0.0678     0.349         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:      0.392    0.2259    0.1051    0.0423   0.03356   0.02102   0.03648\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0148, lrf=0.207, momentum=0.74418, weight_decay=0.0002, warmup_epochs=1.63, warmup_momentum=0.81333, warmup_bias_lr=0.138, box=0.0244, cls=0.3447, cls_pw=0.76195, obj=1.02355, obj_pw=0.734, iou_t=0.2, anchor_t=2.46558, anchors=2.0, fl_gamma=0.0, hsv_h=0.01602, hsv_s=0.82078, hsv_v=0.34072, degrees=0.0, translate=0.0752, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.63292, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_225138-2kjnsqi6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2kjnsqi6\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1178.53it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.41: 1.0000 best possible recall, 4.20 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.641-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.41: 1.0000 best possible recall, 4.16 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.645-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G   0.03723   0.02456   0.02459   0.08638         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.03329   0.02557   0.02347   0.08232        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.803G   0.02608   0.02736   0.02255   0.07599        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.803G   0.02105   0.02799   0.02262   0.07166         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01951    0.0279   0.02241   0.06981         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01937   0.02704   0.02211   0.06852         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01902   0.02593    0.0221   0.06705         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01852   0.02472   0.02198   0.06523         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01679   0.02266   0.02157   0.06101         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01592   0.02177   0.02133   0.05903         7       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.469       0.198       0.164      0.0584\n",
      "            Geranium         108         197       0.469       0.198       0.164      0.0584\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅▇██▇▆▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.16369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.46872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03034\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01771\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00418\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2kjnsqi6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_225138-2kjnsqi6/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0148     0.207     0.744    0.0002      1.63     0.813     0.138    0.0244     0.345     0.762      1.02     0.734       0.2      2.47         2         0     0.016     0.821     0.341         0    0.0752     0.349         0         0         0       0.5     0.633         0\n",
      "Evolved fitness:     0.4687     0.198    0.1637   0.05844   0.03034   0.01771   0.02456\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.22961, momentum=0.77825, weight_decay=0.00025, warmup_epochs=1.64032, warmup_momentum=0.69477, warmup_bias_lr=0.138, box=0.03206, cls=0.383, cls_pw=0.853, obj=0.92878, obj_pw=0.734, iou_t=0.2, anchor_t=2.86383, anchors=2.44211, fl_gamma=0.0, hsv_h=0.01877, hsv_s=0.48328, hsv_v=0.52656, degrees=0.0, translate=0.05412, scale=0.39962, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.44211\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00025\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_225354-nqqdztve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/nqqdztve\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1152.88it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.35: 1.0000 best possible recall, 4.75 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.610-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.35: 1.0000 best possible recall, 4.62 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.618-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G    0.0512   0.02393   0.02972    0.1049         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.04533   0.02527   0.02849   0.09909        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.803G   0.03569   0.02793   0.02732   0.09094         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.803G   0.02852   0.03018   0.02698   0.08569         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.803G   0.02668   0.02961   0.02631   0.08259         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02607   0.02911   0.02657   0.08175         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02547   0.02839   0.02598   0.07984         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02458   0.02754   0.02585   0.07797         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.02283   0.02581   0.02545    0.0741         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.02181   0.02421   0.02499   0.07101         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.325       0.208       0.172      0.0672\n",
      "            Geranium         108         197       0.325       0.208       0.172      0.0672\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▅█▇▇▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.17217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.32522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.02181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/nqqdztve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_225354-nqqdztve/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152      0.23     0.778   0.00025      1.64     0.695     0.138    0.0321     0.383     0.853     0.929     0.734       0.2      2.86      2.44         0    0.0188     0.483     0.527         0    0.0541       0.4         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.3252    0.2081    0.1722   0.06719   0.03912   0.01956   0.02315\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01337, lrf=0.20775, momentum=0.75842, weight_decay=0.0002, warmup_epochs=1.63, warmup_momentum=0.73591, warmup_bias_lr=0.134, box=0.02584, cls=0.383, cls_pw=0.8358, obj=1.16081, obj_pw=0.72223, iou_t=0.2, anchor_t=2.70086, anchors=3.7767, fl_gamma=0.0, hsv_h=0.0165, hsv_s=0.741, hsv_v=0.347, degrees=0.0, translate=0.06331, scale=0.34675, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.70551, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.7767\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_225614-50yw4fpc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/50yw4fpc\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1189.02it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.74 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.613-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.74 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.614-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.807G   0.04171   0.02832   0.02948   0.09951         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.03807   0.02939   0.02866   0.09612         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.03196   0.03238    0.0279   0.09224        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G   0.02681   0.03414   0.02714   0.08809         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.02319   0.03491   0.02705   0.08516         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G   0.02123   0.03449   0.02661   0.08232         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G   0.02063   0.03469   0.02651   0.08183         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.02072   0.03269   0.02632   0.07972         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G   0.01916   0.03075   0.02605   0.07596         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.807G   0.01788   0.02955   0.02605   0.07348         1       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.227       0.213       0.098      0.0393\n",
      "            Geranium         108         197       0.227       0.213       0.098      0.0393\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▅▇███▆▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.09801\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.03926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.22736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02605\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02139\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/50yw4fpc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_225614-50yw4fpc/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0134     0.208     0.758    0.0002      1.63     0.736     0.134    0.0258     0.383     0.836      1.16     0.722       0.2       2.7      3.78         0    0.0165     0.741     0.347         0    0.0633     0.347         0         0         0       0.5     0.706         0\n",
      "Evolved fitness:     0.2274    0.2132   0.09801   0.03926   0.03372   0.02139   0.03658\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01432, lrf=0.22048, momentum=0.765, weight_decay=0.0002, warmup_epochs=1.76594, warmup_momentum=0.77478, warmup_bias_lr=0.13909, box=0.0244, cls=0.40319, cls_pw=0.88662, obj=0.93433, obj_pw=0.734, iou_t=0.2, anchor_t=2.74978, anchors=2.77851, fl_gamma=0.0, hsv_h=0.01849, hsv_s=0.77453, hsv_v=0.34812, degrees=0.0, translate=0.06386, scale=0.3512, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.60246, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.77851\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_225832-p5obnn8x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/p5obnn8x\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1147.66it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.66 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.612-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.68 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.616-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03915    0.0234   0.03206   0.09461         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03503   0.02463   0.03044    0.0901         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02877   0.02652   0.02946   0.08476        13       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02366   0.02724   0.02908   0.07999         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02072   0.02827   0.02841   0.07741         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01979   0.02843   0.02847   0.07669         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01954   0.02677   0.02813   0.07444         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01892   0.02667   0.02794   0.07353         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G    0.0174   0.02546   0.02798   0.07084         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01603   0.02427   0.02777   0.06807         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.357       0.228       0.129      0.0479\n",
      "            Geranium         108         197       0.357       0.228       0.129      0.0479\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▅▆██▆▆▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.12896\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04791\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.35712\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01603\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02777\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03304\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/p5obnn8x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_225832-p5obnn8x/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0143      0.22     0.765    0.0002      1.77     0.775     0.139    0.0244     0.403     0.887     0.934     0.734       0.2      2.75      2.78         0    0.0185     0.775     0.348         0    0.0639     0.351         0         0         0       0.5     0.602         0\n",
      "Evolved fitness:     0.3571    0.2284     0.129   0.04791   0.03304   0.01727   0.03851\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01495, lrf=0.20948, momentum=0.77389, weight_decay=0.00022, warmup_epochs=1.63, warmup_momentum=0.80338, warmup_bias_lr=0.138, box=0.02428, cls=0.38155, cls_pw=0.853, obj=1.16824, obj_pw=0.734, iou_t=0.2, anchor_t=2.66937, anchors=2.61927, fl_gamma=0.0, hsv_h=0.01681, hsv_s=0.741, hsv_v=0.34295, degrees=0.0, translate=0.0659, scale=0.38658, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.58578, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.61927\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00022\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_230048-14gzeow4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/14gzeow4\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1174.90it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.53 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.617-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.54 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.622-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03869   0.02793   0.02948    0.0961         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03457   0.02937    0.0281   0.09204         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02812   0.03218   0.02711   0.08741         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02351   0.03315   0.02675   0.08342         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02082   0.03313   0.02631   0.08026         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02026   0.03203   0.02657   0.07885         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01959   0.03066   0.02649   0.07674         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01957   0.02857   0.02642   0.07456         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01764   0.02701   0.02636   0.07102         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01646   0.02528   0.02624   0.06799         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197        0.43       0.222       0.144      0.0623\n",
      "            Geranium         108         197        0.43       0.222       0.144      0.0623\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▂▁▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▅▇██▇▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.43013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01646\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03882\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/14gzeow4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_230048-14gzeow4/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0149     0.209     0.774   0.00022      1.63     0.803     0.138    0.0243     0.382     0.853      1.17     0.734       0.2      2.67      2.62         0    0.0168     0.741     0.343         0    0.0659     0.387         0         0         0       0.5     0.586         0\n",
      "Evolved fitness:     0.4301    0.2222    0.1436   0.06227   0.03224   0.02125   0.03882\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.207, momentum=0.75438, weight_decay=0.00019, warmup_epochs=1.85397, warmup_momentum=0.7769, warmup_bias_lr=0.13799, box=0.0244, cls=0.3868, cls_pw=0.79494, obj=1.07495, obj_pw=0.69126, iou_t=0.2, anchor_t=2.6292, anchors=2.88, fl_gamma=0.0, hsv_h=0.01523, hsv_s=0.66579, hsv_v=0.35871, degrees=0.0, translate=0.07443, scale=0.35037, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.63336, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_230303-asu00nvy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/asu00nvy\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1225.45it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.45 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.620-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.48 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.624-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03838   0.02557   0.02851   0.09246         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03478   0.02631   0.02747   0.08856         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02846   0.02871    0.0266   0.08377         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02325   0.03004   0.02633   0.07962        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02043   0.03021   0.02585   0.07649         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01988   0.03012   0.02574   0.07574         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01892   0.02861    0.0256   0.07313         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01871   0.02673    0.0256   0.07104         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G    0.0167   0.02652    0.0254   0.06863         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01633   0.02447   0.02518   0.06598         1       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.372       0.208       0.131      0.0566\n",
      "            Geranium         108         197       0.372       0.208       0.131      0.0566\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▃▆███▆▄▄▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.13062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.37204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/asu00nvy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_230303-asu00nvy/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.207     0.754   0.00019      1.85     0.777     0.138    0.0244     0.387     0.795      1.07     0.691       0.2      2.63      2.88         0    0.0152     0.666     0.359         0    0.0744      0.35         0         0         0       0.5     0.633         0\n",
      "Evolved fitness:      0.372    0.2081    0.1306    0.0566   0.03224   0.01835   0.03606\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01623, lrf=0.15073, momentum=0.765, weight_decay=0.0002, warmup_epochs=1.63, warmup_momentum=0.67354, warmup_bias_lr=0.138, box=0.03122, cls=0.41405, cls_pw=0.66557, obj=0.91525, obj_pw=0.734, iou_t=0.2, anchor_t=2.73, anchors=2.88, fl_gamma=0.0, hsv_h=0.01492, hsv_s=0.69482, hsv_v=0.33016, degrees=0.0, translate=0.08671, scale=0.34212, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.58407, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_230519-1vavoe56\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1vavoe56\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1206.88it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G    0.0501   0.02228   0.02711   0.09948         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.04438   0.02379   0.02625   0.09442         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G    0.0354   0.02666   0.02559   0.08765         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02876   0.02814   0.02532   0.08222         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02529   0.02866   0.02491   0.07886         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02391   0.02801   0.02488    0.0768         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02308    0.0279   0.02478   0.07575         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02303    0.0268   0.02476   0.07459         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G    0.0206   0.02675   0.02466   0.07201         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01871   0.02543   0.02439   0.06854         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.395       0.213       0.119      0.0481\n",
      "            Geranium         108         197       0.395       0.213       0.119      0.0481\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▆▇█▇▇▆▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.11901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.3946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04052\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01764\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1vavoe56\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_230519-1vavoe56/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0162     0.151     0.765    0.0002      1.63     0.674     0.138    0.0312     0.414     0.666     0.915     0.734       0.2      2.73      2.88         0    0.0149     0.695      0.33         0    0.0867     0.342         0         0         0       0.5     0.584         0\n",
      "Evolved fitness:     0.3946    0.2132     0.119   0.04806   0.04052   0.01764   0.03421\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01414, lrf=0.1953, momentum=0.80707, weight_decay=0.00019, warmup_epochs=1.46624, warmup_momentum=0.767, warmup_bias_lr=0.12623, box=0.0244, cls=0.40541, cls_pw=0.8256, obj=1.10082, obj_pw=0.76661, iou_t=0.2, anchor_t=2.79555, anchors=2.82001, fl_gamma=0.0, hsv_h=0.01827, hsv_s=0.741, hsv_v=0.347, degrees=0.0, translate=0.0659, scale=0.36454, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.61494, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.82001\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_230734-3ci75zy2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3ci75zy2\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1213.88it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.74 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.609-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.74 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.614-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03944   0.02892   0.03071   0.09906         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03511   0.03055   0.02938   0.09504         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02828   0.03313   0.02856   0.08998         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02321   0.03412   0.02811   0.08544         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02066   0.03463   0.02749   0.08279         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02068   0.03404   0.02731   0.08202         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01996   0.03062    0.0271   0.07768         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01964    0.0289   0.02693   0.07547         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01786   0.02692   0.02691   0.07169         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01606   0.02511   0.02659   0.06776         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197        0.55       0.192       0.164      0.0528\n",
      "            Geranium         108         197        0.55       0.192       0.164      0.0528\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅▇███▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.1639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05282\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.55016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02511\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00385\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3ci75zy2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_230734-3ci75zy2/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0141     0.195     0.807   0.00019      1.47     0.767     0.126    0.0244     0.405     0.826       1.1     0.767       0.2       2.8      2.82         0    0.0183     0.741     0.347         0    0.0659     0.365         0         0         0       0.5     0.615         0\n",
      "Evolved fitness:     0.5502    0.1925    0.1639   0.05282   0.03122   0.02205   0.03463\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01862, lrf=0.207, momentum=0.73637, weight_decay=0.00016, warmup_epochs=1.52706, warmup_momentum=0.69299, warmup_bias_lr=0.138, box=0.0244, cls=0.42932, cls_pw=0.84815, obj=0.96222, obj_pw=0.61817, iou_t=0.2, anchor_t=2.73, anchors=2.72412, fl_gamma=0.0, hsv_h=0.0174, hsv_s=0.70491, hsv_v=0.33873, degrees=0.0, translate=0.07718, scale=0.29479, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.59616, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.72412\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00016\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_230950-33mdkn92\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/33mdkn92\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1178.58it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03926   0.02068    0.0332   0.09314         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03564   0.02166   0.03171     0.089         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02942   0.02342   0.03067   0.08351        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02446   0.02427    0.0301   0.07882         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02114   0.02505   0.02931    0.0755         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01971   0.02542   0.02893   0.07407        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01895   0.02491   0.02846   0.07233         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01865   0.02428   0.02785   0.07078         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01739   0.02379   0.02753   0.06871        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01626    0.0226   0.02659   0.06545         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.348       0.218       0.165      0.0632\n",
      "            Geranium         108         197       0.348       0.218       0.165      0.0632\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▅▆▇█▇▆▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.16507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.34839\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.21827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02659\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/33mdkn92\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_230950-33mdkn92/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0186     0.207     0.736   0.00016      1.53     0.693     0.138    0.0244     0.429     0.848     0.962     0.618       0.2      2.73      2.72         0    0.0174     0.705     0.339         0    0.0772     0.295         0         0         0       0.5     0.596         0\n",
      "Evolved fitness:     0.3484    0.2183    0.1651   0.06318   0.03104    0.0162    0.0252\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01657, lrf=0.207, momentum=0.72909, weight_decay=0.0002, warmup_epochs=1.7022, warmup_momentum=0.80463, warmup_bias_lr=0.13565, box=0.0244, cls=0.39604, cls_pw=0.75122, obj=0.96172, obj_pw=0.78244, iou_t=0.2, anchor_t=2.7958, anchors=3.23648, fl_gamma=0.0, hsv_h=0.01454, hsv_s=0.64482, hsv_v=0.29634, degrees=0.0, translate=0.06746, scale=0.35504, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.23648\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_231207-37nk8z6u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/37nk8z6u\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1166.92it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.74 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.609-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.74 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.614-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G    0.0392   0.02489     0.028   0.09208         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G    0.0342   0.02702   0.02678     0.088         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02666    0.0301   0.02609   0.08285         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02191   0.03084   0.02583   0.07858         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01984   0.03093   0.02536   0.07613         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01967   0.02964   0.02528   0.07459        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G    0.0195   0.02764   0.02524   0.07238         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01992   0.02607   0.02491    0.0709         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01765   0.02529   0.02497    0.0679        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01615   0.02336   0.02455   0.06406         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.421       0.208       0.148      0.0522\n",
      "            Geranium         108         197       0.421       0.208       0.148      0.0522\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▄▇██▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14783\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.42064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01615\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0338\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/37nk8z6u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_231207-37nk8z6u/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0166     0.207     0.729    0.0002       1.7     0.805     0.136    0.0244     0.396     0.751     0.962     0.782       0.2       2.8      3.24         0    0.0145     0.645     0.296         0    0.0675     0.355         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.4206    0.2081    0.1478   0.05224    0.0311   0.02002    0.0338\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01503, lrf=0.20711, momentum=0.76503, weight_decay=0.0002, warmup_epochs=1.63, warmup_momentum=0.74987, warmup_bias_lr=0.138, box=0.0244, cls=0.38649, cls_pw=0.853, obj=1.0449, obj_pw=0.72804, iou_t=0.2, anchor_t=2.73, anchors=2.74497, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.74697, hsv_v=0.3441, degrees=0.0, translate=0.06532, scale=0.35254, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.74497\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_231423-36qtk8sm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/36qtk8sm\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1180.62it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03914   0.02525   0.02993   0.09432         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03517    0.0268   0.02873    0.0907         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02824   0.02971   0.02776   0.08571         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02347   0.03059   0.02734    0.0814         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02047   0.03159   0.02679   0.07885         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G    0.0196   0.03093   0.02672   0.07725        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01841    0.0295   0.02663   0.07454         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01968   0.02785    0.0263   0.07383         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01735   0.02733   0.02633   0.07101        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01606   0.02526   0.02594   0.06725         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197         0.4       0.223       0.123      0.0495\n",
      "            Geranium         108         197         0.4       0.223       0.123      0.0495\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▃▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▆▇█▇▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.12337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.39965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.031\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/36qtk8sm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_231423-36qtk8sm/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "     0.015     0.207     0.765    0.0002      1.63      0.75     0.138    0.0244     0.386     0.853      1.04     0.728       0.2      2.73      2.74         0    0.0164     0.747     0.344         0    0.0653     0.353         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.3996    0.2234    0.1234   0.04953     0.031   0.02008   0.03517\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.20105, momentum=0.76471, weight_decay=0.00019, warmup_epochs=1.58793, warmup_momentum=0.79705, warmup_bias_lr=0.13766, box=0.02493, cls=0.383, cls_pw=0.84894, obj=0.93268, obj_pw=0.72925, iou_t=0.2, anchor_t=2.52686, anchors=3.46352, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.76282, hsv_v=0.30162, degrees=0.0, translate=0.06482, scale=0.36669, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.56035, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.46352\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_231641-2d0rmhlp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2d0rmhlp\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1167.71it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.40: 1.0000 best possible recall, 6.18 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.630-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.40: 1.0000 best possible recall, 6.30 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.630-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03891   0.02159   0.02948   0.08998         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03423   0.02295   0.02811   0.08529         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02706   0.02488   0.02736   0.07929        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02178   0.02636   0.02715   0.07528        13       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G    0.0203   0.02664    0.0265   0.07343         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01923   0.02602   0.02634    0.0716         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01847   0.02539   0.02645   0.07031        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01867    0.0237   0.02628   0.06865         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01674   0.02384   0.02627   0.06685         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01542   0.02252    0.0261   0.06403         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.412       0.223        0.15      0.0573\n",
      "            Geranium         108         197       0.412       0.223        0.15      0.0573\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▁▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▆██▇▆▄▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.41191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01542\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00422\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2d0rmhlp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_231641-2d0rmhlp/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.201     0.765   0.00019      1.59     0.797     0.138    0.0249     0.383     0.849     0.933     0.729       0.2      2.53      3.46         0    0.0164     0.763     0.302         0    0.0648     0.367         0         0         0       0.5      0.56         0\n",
      "Evolved fitness:     0.4119    0.2234    0.1499    0.0573   0.03131   0.01674   0.03721\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01635, lrf=0.207, momentum=0.765, weight_decay=0.0002, warmup_epochs=1.63, warmup_momentum=0.66559, warmup_bias_lr=0.14871, box=0.02266, cls=0.37137, cls_pw=0.76601, obj=1.05165, obj_pw=0.63079, iou_t=0.2, anchor_t=2.63232, anchors=2.14113, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.58997, hsv_v=0.347, degrees=0.0, translate=0.06955, scale=0.32309, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.67037, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.14113\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_231858-ozcwsr0i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/ozcwsr0i\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1497.64it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 4.41 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.629-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 4.36 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.633-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03561   0.02321   0.02679   0.08561         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03252   0.02346    0.0257   0.08168        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G    0.0266   0.02539   0.02466   0.07666        13       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02175   0.02767   0.02439   0.07381         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01952   0.02763   0.02396   0.07111         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01879   0.02751   0.02364   0.06994        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01788   0.02615     0.023   0.06704         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G    0.0179    0.0256   0.02247   0.06597         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01644   0.02333   0.02203    0.0618         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01517   0.02208   0.02177   0.05902         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.632       0.193       0.192      0.0602\n",
      "            Geranium         108         197       0.632       0.193       0.192      0.0602\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▃▅███▆▅▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.19211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.63236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02177\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02721\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01722\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/ozcwsr0i\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_231858-ozcwsr0i/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0163     0.207     0.765    0.0002      1.63     0.666     0.149    0.0227     0.371     0.766      1.05     0.631       0.2      2.63      2.14         0    0.0164      0.59     0.347         0    0.0696     0.323         0         0         0       0.5      0.67         0\n",
      "Evolved fitness:     0.6324    0.1929    0.1921    0.0602   0.02721   0.01722   0.01744\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01473, lrf=0.207, momentum=0.7651, weight_decay=0.0002, warmup_epochs=1.65616, warmup_momentum=0.79376, warmup_bias_lr=0.13508, box=0.0235, cls=0.36038, cls_pw=0.853, obj=1.09, obj_pw=0.74875, iou_t=0.2, anchor_t=2.73, anchors=2.76519, fl_gamma=0.0, hsv_h=0.01751, hsv_s=0.72135, hsv_v=0.347, degrees=0.0, translate=0.06822, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.58528, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.76519\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_232134-1l9c7paw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1l9c7paw\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1176.85it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03794   0.02668   0.02791   0.09252         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03395    0.0281   0.02658   0.08864         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02709    0.0313   0.02569   0.08407         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02212   0.03255   0.02537   0.08004         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01995   0.03215   0.02483   0.07694         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01973   0.03086     0.025   0.07559         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01937   0.02952   0.02479   0.07369         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01912   0.02753   0.02473   0.07138         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01739   0.02634   0.02464   0.06837         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01632   0.02484    0.0243   0.06546         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.348       0.223       0.135      0.0489\n",
      "            Geranium         108         197       0.348       0.223       0.135      0.0489\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▇██▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.13517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.34832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01632\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1l9c7paw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_232134-1l9c7paw/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0147     0.207     0.765    0.0002      1.66     0.794     0.135    0.0235      0.36     0.853      1.09     0.749       0.2      2.73      2.77         0    0.0175     0.721     0.347         0    0.0682     0.349         0         0         0       0.5     0.585         0\n",
      "Evolved fitness:     0.3483    0.2234    0.1352   0.04891   0.03067    0.0211   0.03374\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.207, momentum=0.76712, weight_decay=0.0002, warmup_epochs=1.63, warmup_momentum=0.77796, warmup_bias_lr=0.13841, box=0.02551, cls=0.383, cls_pw=0.853, obj=1.11313, obj_pw=0.71697, iou_t=0.2, anchor_t=2.73, anchors=2.78886, fl_gamma=0.0, hsv_h=0.01663, hsv_s=0.73381, hsv_v=0.35392, degrees=0.0, translate=0.06818, scale=0.34895, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.58654, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.78886\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_232350-350w8zcv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/350w8zcv\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1187.11it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04093   0.02658   0.02963   0.09713         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03686   0.02792   0.02824   0.09302         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02949    0.0309   0.02733   0.08772         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02366   0.03242   0.02698   0.08307         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02136   0.03219   0.02641   0.07996         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02024   0.03137   0.02657   0.07818         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02093   0.02987   0.02645   0.07724         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02006   0.02823   0.02641   0.07471         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01867   0.02715   0.02622   0.07204         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G    0.0172   0.02564   0.02605    0.0689         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.458       0.234       0.154      0.0577\n",
      "            Geranium         108         197       0.458       0.234       0.154      0.0577\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▃▆██▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.15414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.45844\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02605\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/350w8zcv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_232350-350w8zcv/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.207     0.767    0.0002      1.63     0.778     0.138    0.0255     0.383     0.853      1.11     0.717       0.2      2.73      2.79         0    0.0166     0.734     0.354         0    0.0682     0.349         0         0         0       0.5     0.587         0\n",
      "Evolved fitness:     0.4584    0.2335    0.1541    0.0577   0.03472   0.01967   0.03699\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.24911, momentum=0.80959, weight_decay=0.00019, warmup_epochs=1.26659, warmup_momentum=0.767, warmup_bias_lr=0.12649, box=0.02209, cls=0.26345, cls_pw=0.853, obj=1.18685, obj_pw=0.57973, iou_t=0.2, anchor_t=2.36809, anchors=2.88522, fl_gamma=0.0, hsv_h=0.01493, hsv_s=0.73347, hsv_v=0.347, degrees=0.0, translate=0.0728, scale=0.3289, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.57459, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.88522\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_232606-2iaob4kb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2iaob4kb\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1195.50it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.42: 0.9994 best possible recall, 5.81 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.644-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.42: 1.0000 best possible recall, 5.90 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.646-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03397   0.02219   0.02054    0.0767         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03032   0.02283   0.01983   0.07298         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02472   0.02424   0.01907   0.06803         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02014   0.02604   0.01892    0.0651         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G    0.0178   0.02583   0.01861   0.06224         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01725   0.02478   0.01848   0.06052         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01644   0.02421   0.01849   0.05914        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01593   0.02307   0.01841   0.05741         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01487    0.0225    0.0184   0.05578         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01363   0.02057    0.0181    0.0523         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.421       0.218        0.13      0.0545\n",
      "            Geranium         108         197       0.421       0.218        0.13      0.0545\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▆██▆▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▃▆▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▃▆▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.1302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05455\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.42079\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.21827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02544\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2iaob4kb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_232606-2iaob4kb/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.249      0.81   0.00019      1.27     0.767     0.126    0.0221     0.263     0.853      1.19      0.58       0.2      2.37      2.89         0    0.0149     0.733     0.347         0    0.0728     0.329         0         0         0       0.5     0.575         0\n",
      "Evolved fitness:     0.4208    0.2183    0.1302   0.05455   0.02551   0.01789   0.02544\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01411, lrf=0.207, momentum=0.75421, weight_decay=0.00021, warmup_epochs=1.44898, warmup_momentum=0.767, warmup_bias_lr=0.10396, box=0.02803, cls=0.4567, cls_pw=0.9953, obj=1.09, obj_pw=0.84134, iou_t=0.2, anchor_t=2.49539, anchors=3.72045, fl_gamma=0.0, hsv_h=0.01404, hsv_s=0.83861, hsv_v=0.32326, degrees=0.0, translate=0.05911, scale=0.32174, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.64692, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=3.72045\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_232822-22wzrsu0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/22wzrsu0\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1170.03it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.40: 1.0000 best possible recall, 8.09 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.631-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.40: 1.0000 best possible recall, 8.08 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.633-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.807G   0.04392   0.02886   0.03987    0.1126         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.03915   0.02988   0.03803    0.1071         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.03177   0.03194    0.0365    0.1002         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G   0.02644   0.03255   0.03563   0.09462         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.02338   0.03315   0.03502   0.09156        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G   0.02239   0.03247   0.03467   0.08953         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G    0.0228   0.03088   0.03432     0.088         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.02221   0.02903   0.03384   0.08508         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G   0.02027   0.02756   0.03378   0.08161         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.807G   0.01867   0.02572   0.03336   0.07775         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.347       0.208       0.118      0.0478\n",
      "            Geranium         108         197       0.347       0.208       0.118      0.0478\n",
      "10 epochs completed in 0.033 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅▇▇█▇▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.11781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0478\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.34706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.03336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/22wzrsu0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_232822-22wzrsu0/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0141     0.207     0.754   0.00021      1.45     0.767     0.104     0.028     0.457     0.995      1.09     0.841       0.2       2.5      3.72         0     0.014     0.839     0.323         0    0.0591     0.322         0         0         0       0.5     0.647         0\n",
      "Evolved fitness:     0.3471    0.2081    0.1178    0.0478    0.0343   0.02224   0.04529\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01445, lrf=0.25158, momentum=0.78308, weight_decay=0.0002, warmup_epochs=1.41609, warmup_momentum=0.71176, warmup_bias_lr=0.14695, box=0.02546, cls=0.44952, cls_pw=0.62602, obj=0.85315, obj_pw=0.734, iou_t=0.2, anchor_t=2.64708, anchors=2.88, fl_gamma=0.0, hsv_h=0.01777, hsv_s=0.61212, hsv_v=0.25912, degrees=0.0, translate=0.0659, scale=0.32357, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.66039, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_233039-1hdcjoae\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1hdcjoae\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1174.81it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.50 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.618-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.50 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.623-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04044   0.02131   0.02823   0.08998         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03676   0.02215   0.02741   0.08632         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.03021   0.02422   0.02666   0.08109        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02462    0.0266   0.02643   0.07766         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02132   0.02607   0.02604   0.07344         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01973   0.02598   0.02558   0.07129         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01905    0.0257   0.02564   0.07039         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01922   0.02421   0.02543   0.06885         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01738   0.02318   0.02536   0.06592         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G    0.0163   0.02259   0.02506   0.06396         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.396       0.188       0.101      0.0421\n",
      "            Geranium         108         197       0.396       0.188       0.101      0.0421\n",
      "10 epochs completed in 0.054 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▅█▇▇▇▅▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▃▆▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▃▆▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.10124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.3962\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.18782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0163\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1hdcjoae\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_233039-1hdcjoae/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0144     0.252     0.783    0.0002      1.42     0.712     0.147    0.0255      0.45     0.626     0.853     0.734       0.2      2.65      2.88         0    0.0178     0.612     0.259         0    0.0659     0.324         0         0         0       0.5      0.66         0\n",
      "Evolved fitness:     0.3962    0.1878    0.1012    0.0421   0.03129   0.01683   0.03361\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01373, lrf=0.1788, momentum=0.76109, weight_decay=0.00019, warmup_epochs=1.51749, warmup_momentum=0.62727, warmup_bias_lr=0.138, box=0.02833, cls=0.36947, cls_pw=0.84691, obj=1.09, obj_pw=0.734, iou_t=0.2, anchor_t=2.73, anchors=2.88, fl_gamma=0.0, hsv_h=0.01872, hsv_s=0.6839, hsv_v=0.37708, degrees=0.0, translate=0.05492, scale=0.37769, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.66156, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_233410-grcklizu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/grcklizu\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 821.59it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm::   0%| | 0/1000 [00:00<?, ?\u001b[0m\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04589   0.02769   0.02869    0.1023         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.04216   0.02868   0.02792   0.09877         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.03605   0.03074   0.02703   0.09382        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02973   0.03415   0.02669   0.09058         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02546   0.03368   0.02619   0.08534         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02334   0.03384   0.02567   0.08285         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G    0.0221   0.03433   0.02581   0.08224         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G    0.0224   0.03181   0.02553   0.07974         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G    0.0203   0.03008   0.02549   0.07587         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01875   0.02997   0.02528     0.074         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.388       0.218       0.148      0.0621\n",
      "            Geranium         108         197       0.388       0.218       0.148      0.0621\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▄█▇▇█▅▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.38846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.21827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02528\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00353\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/grcklizu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_233410-grcklizu/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0137     0.179     0.761   0.00019      1.52     0.627     0.138    0.0283     0.369     0.847      1.09     0.734       0.2      2.73      2.88         0    0.0187     0.684     0.377         0    0.0549     0.378         0         0         0       0.5     0.662         0\n",
      "Evolved fitness:     0.3885    0.2183    0.1481   0.06208   0.03716   0.02075   0.03581\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01566, lrf=0.19869, momentum=0.765, weight_decay=0.00021, warmup_epochs=1.63, warmup_momentum=0.81349, warmup_bias_lr=0.15299, box=0.0244, cls=0.36365, cls_pw=0.84281, obj=1.02202, obj_pw=0.74579, iou_t=0.2, anchor_t=2.66946, anchors=2.54216, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.70963, hsv_v=0.36908, degrees=0.0, translate=0.06878, scale=0.31587, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.55791, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.54216\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_233755-i5s66kqv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/i5s66kqv\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 847.93it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.53 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.617-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.54 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.622-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03861    0.0246   0.02784   0.09106         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03371   0.02657   0.02639   0.08667         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02664   0.02845   0.02574   0.08083        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02217   0.02998   0.02552   0.07767         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02048   0.03018   0.02479   0.07545         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01987   0.02867    0.0247   0.07324         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01899   0.02732   0.02484   0.07115        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01907   0.02558   0.02465    0.0693         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01725   0.02513   0.02435   0.06672         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01586   0.02373   0.02447   0.06405         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.532       0.208       0.168       0.065\n",
      "            Geranium         108         197       0.532       0.208       0.168       0.065\n",
      "10 epochs completed in 0.060 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▄▆██▆▅▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.16756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.53212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02447\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02373\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03118\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01897\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/i5s66kqv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_233755-i5s66kqv/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0157     0.199     0.765   0.00021      1.63     0.813     0.153    0.0244     0.364     0.843      1.02     0.746       0.2      2.67      2.54         0    0.0164      0.71     0.369         0    0.0688     0.316         0         0         0       0.5     0.558         0\n",
      "Evolved fitness:     0.5321    0.2081    0.1676   0.06503   0.03118   0.01897   0.03264\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01188, lrf=0.23003, momentum=0.84446, weight_decay=0.00025, warmup_epochs=1.27598, warmup_momentum=0.95, warmup_bias_lr=0.13268, box=0.0244, cls=0.33361, cls_pw=0.73936, obj=0.98946, obj_pw=0.81339, iou_t=0.2, anchor_t=3.06661, anchors=2.78199, fl_gamma=0.0, hsv_h=0.0154, hsv_s=0.55923, hsv_v=0.29905, degrees=0.0, translate=0.0659, scale=0.39266, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.52848, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.78199\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00025\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_234151-2dewxbad\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2dewxbad\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 889.03it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.33: 1.0000 best possible recall, 7.17 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.593-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.33: 1.0000 best possible recall, 7.17 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.598-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03924   0.02777   0.02287   0.08988         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03093   0.03137   0.02165   0.08395         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02289   0.03425   0.02133   0.07847         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01947   0.03255   0.02099   0.07301         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01901   0.03072   0.02106   0.07079         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02005   0.02682   0.02122   0.06809         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G    0.0189   0.02491   0.02125   0.06506         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G    0.0186   0.02365    0.0212   0.06345         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01613   0.02202   0.02097   0.05912         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01426   0.02137   0.02102   0.05665         1       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.391       0.228       0.126      0.0423\n",
      "            Geranium         108         197       0.391       0.228       0.126      0.0423\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▃▂▂▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▃▂▁▁▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▆█▇▆▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.12558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.3907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2dewxbad\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_234151-2dewxbad/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0119      0.23     0.844   0.00025      1.28      0.95     0.133    0.0244     0.334     0.739     0.989     0.813       0.2      3.07      2.78         0    0.0154     0.559     0.299         0    0.0659     0.393         0         0         0       0.5     0.528         0\n",
      "Evolved fitness:     0.3907    0.2284    0.1256   0.04232   0.03154    0.0226   0.03278\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.02482, lrf=0.2256, momentum=0.71103, weight_decay=0.0002, warmup_epochs=2.05174, warmup_momentum=0.767, warmup_bias_lr=0.14824, box=0.02562, cls=0.46781, cls_pw=0.853, obj=1.31833, obj_pw=0.71836, iou_t=0.2, anchor_t=2.20106, anchors=2.0, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.82665, hsv_v=0.43572, degrees=0.0, translate=0.05709, scale=0.34928, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_234535-289oyrsc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/289oyrsc\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 854.82it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.45: 0.9965 best possible recall, 3.78 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.664-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8299: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.45: 0.9988 best possible recall, 3.74 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.535/0.830-mean/best, past_thr=0.666-mean: 87,100,  129,175,  192,257,  289,237,  266,356,  391,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03649   0.02809   0.03572    0.1003         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03132   0.02865   0.03332    0.0933        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02534   0.02971     0.031   0.08605         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02268   0.03047   0.03026   0.08341         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02208   0.02886   0.02925   0.08019         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02229   0.02791   0.02879   0.07899         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02129   0.02618   0.02812   0.07558         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02203   0.02468   0.02816   0.07486         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01927    0.0234   0.02774   0.07041         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01757   0.02238   0.02738   0.06733         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.315       0.249       0.175        0.06\n",
      "            Geranium         108         197       0.315       0.249       0.175        0.06\n",
      "10 epochs completed in 0.061 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▃▃▂▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▆▆▇█▇▆▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▃▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.1755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.31495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.24873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01757\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00743\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/289oyrsc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_234535-289oyrsc/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0248     0.226     0.711    0.0002      2.05     0.767     0.148    0.0256     0.468     0.853      1.32     0.718       0.2       2.2         2         0    0.0164     0.827     0.436         0    0.0571     0.349         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:      0.315    0.2487    0.1755   0.05998   0.02824   0.02125   0.01816\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01497, lrf=0.24331, momentum=0.74746, weight_decay=0.00024, warmup_epochs=1.67638, warmup_momentum=0.92217, warmup_bias_lr=0.16486, box=0.02345, cls=0.29499, cls_pw=0.98632, obj=1.09, obj_pw=0.86121, iou_t=0.2, anchor_t=2.18778, anchors=2.88, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.9, hsv_v=0.40006, degrees=0.0, translate=0.0692, scale=0.30483, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.53521, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00024\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_234933-2fpfyiqg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2fpfyiqg\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 823.20it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.46: 0.9988 best possible recall, 5.35 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.662-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8599: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.46: 0.9994 best possible recall, 5.43 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.662-mean: 71,92,  111,121,  133,193,  207,171,  193,263,  294,254,  223,358,  309,376,  400,400\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03417   0.02574   0.02483   0.08474         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02961   0.02677   0.02316   0.07954         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02242   0.02857   0.02257   0.07356         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01894   0.02834    0.0224   0.06968         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01872   0.02733   0.02218   0.06822         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01835   0.02494    0.0223   0.06559         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01769   0.02416   0.02243   0.06428         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01803   0.02274   0.02219   0.06296         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01596   0.02117    0.0222   0.05933        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01473   0.02057   0.02207   0.05738         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.363       0.213       0.168       0.063\n",
      "            Geranium         108         197       0.363       0.213       0.168       0.063\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▄▂▂▁▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▆▆██▇▅▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▃▆▇██▇▇▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▃▆▇██▇▇▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.16828\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.36292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01473\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02207\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2fpfyiqg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_234933-2fpfyiqg/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "     0.015     0.243     0.747   0.00024      1.68     0.922     0.165    0.0234     0.295     0.986      1.09     0.861       0.2      2.19      2.88         0    0.0164       0.9       0.4         0    0.0692     0.305         0         0         0       0.5     0.535         0\n",
      "Evolved fitness:     0.3629    0.2132    0.1683   0.06296   0.02677   0.02061   0.03421\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01694, lrf=0.16328, momentum=0.80089, weight_decay=0.00023, warmup_epochs=1.63, warmup_momentum=0.6795, warmup_bias_lr=0.08581, box=0.0244, cls=0.44638, cls_pw=0.5, obj=1.12417, obj_pw=0.67979, iou_t=0.2, anchor_t=2.75107, anchors=2.71224, fl_gamma=0.0, hsv_h=0.01645, hsv_s=0.741, hsv_v=0.39947, degrees=0.0, translate=0.05703, scale=0.27998, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.71224\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00023\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_235319-1871kt00\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1871kt00\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 833.24it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.66 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.612-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.68 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.616-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03982   0.02568   0.02437   0.08987         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03613   0.02706   0.02379   0.08699         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02966   0.02961    0.0232   0.08247         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02421   0.03089   0.02283   0.07793         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02114   0.03179   0.02246   0.07538         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01973   0.03123   0.02237   0.07333        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01966    0.0292   0.02227   0.07113         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01917   0.02771    0.0221   0.06897         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01755    0.0265   0.02198   0.06602        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G    0.0155   0.02461   0.02165   0.06176         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.379       0.213       0.145      0.0564\n",
      "            Geranium         108         197       0.379       0.213       0.145      0.0564\n",
      "10 epochs completed in 0.054 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▄▃▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▅▄▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▃▆▇█▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▃▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14452\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.3787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02013\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1871kt00\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_235319-1871kt00/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0169     0.163     0.801   0.00023      1.63     0.679    0.0858    0.0244     0.446       0.5      1.12      0.68       0.2      2.75      2.71         0    0.0164     0.741     0.399         0     0.057      0.28         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.3787    0.2132    0.1445   0.05638   0.03193   0.02013   0.02939\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.22459, momentum=0.765, weight_decay=0.00014, warmup_epochs=1.63, warmup_momentum=0.86709, warmup_bias_lr=0.11965, box=0.02, cls=0.40265, cls_pw=0.66557, obj=0.99504, obj_pw=0.5, iou_t=0.2, anchor_t=3.3379, anchors=2.77698, fl_gamma=0.0, hsv_h=0.014, hsv_s=0.9, hsv_v=0.43511, degrees=0.0, translate=0.0659, scale=0.38511, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.71166, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.77698\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00014\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_235653-20yas8s9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/20yas8s9\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 847.24it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.30: 1.0000 best possible recall, 7.63 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.576-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.30: 1.0000 best possible recall, 7.58 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.582-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03393   0.02073   0.02618   0.08085         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02951   0.02217   0.02521    0.0769         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02338   0.02437   0.02453   0.07228        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G    0.0191    0.0264   0.02422   0.06973         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01671   0.02761   0.02386   0.06818        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01668   0.02557   0.02355    0.0658         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01593   0.02556    0.0236    0.0651         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01546   0.02409    0.0237   0.06324         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G     0.015   0.02325   0.02327   0.06152        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01369   0.02226   0.02331   0.05927        10       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.395       0.228       0.163      0.0636\n",
      "            Geranium         108         197       0.395       0.228       0.163      0.0636\n",
      "10 epochs completed in 0.060 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▅▇█▆▆▄▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.16319\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.39451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02647\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/20yas8s9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_235653-20yas8s9/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.225     0.765   0.00014      1.63     0.867      0.12      0.02     0.403     0.666     0.995       0.5       0.2      3.34      2.78         0     0.014       0.9     0.435         0    0.0659     0.385         0         0         0       0.5     0.712         0\n",
      "Evolved fitness:     0.3945    0.2284    0.1632   0.06362   0.02647    0.0157   0.03129\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01508, lrf=0.19281, momentum=0.75536, weight_decay=0.0002, warmup_epochs=1.62242, warmup_momentum=0.74676, warmup_bias_lr=0.14663, box=0.02343, cls=0.383, cls_pw=0.853, obj=1.09, obj_pw=0.70611, iou_t=0.2, anchor_t=2.71219, anchors=2.84912, fl_gamma=0.0, hsv_h=0.01565, hsv_s=0.72771, hsv_v=0.34792, degrees=0.0, translate=0.06719, scale=0.34674, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.84912\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_000048-2xk65qyn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2xk65qyn\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 843.32it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.61 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.614-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8601:  93%|▉| 9\u001b[0m\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.62 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.619-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03773   0.02554   0.02969   0.09295         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03432   0.02679   0.02843   0.08953         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02829   0.02932   0.02752   0.08513         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02335   0.03038   0.02709   0.08081         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02017   0.03147    0.0266   0.07824         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01938   0.03086   0.02649   0.07673        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01831   0.02942   0.02649   0.07422         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01867   0.02824    0.0262    0.0731         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01677   0.02769   0.02616   0.07062        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01555   0.02608   0.02566   0.06729         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197        0.38       0.213        0.11        0.04\n",
      "            Geranium         108         197        0.38       0.213        0.11        0.04\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▃▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▅▇█▇▆▄▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.1096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.03997\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.37956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02608\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2xk65qyn\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_000048-2xk65qyn/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0151     0.193     0.755    0.0002      1.62     0.747     0.147    0.0234     0.383     0.853      1.09     0.706       0.2      2.71      2.85         0    0.0157     0.728     0.348         0    0.0672     0.347         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.3796    0.2132    0.1096   0.03997   0.03101    0.0197   0.03681\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01741, lrf=0.18767, momentum=0.76415, weight_decay=0.00021, warmup_epochs=1.92274, warmup_momentum=0.88834, warmup_bias_lr=0.138, box=0.02168, cls=0.46317, cls_pw=0.72105, obj=1.09, obj_pw=0.5, iou_t=0.2, anchor_t=2.57792, anchors=3.50033, fl_gamma=0.0, hsv_h=0.01831, hsv_s=0.80823, hsv_v=0.3784, degrees=0.0, translate=0.07774, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.51743, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.50033\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_000433-230bx4gx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/230bx4gx\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 763.26it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.39: 1.0000 best possible recall, 8.33 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.625-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.39: 1.0000 best possible recall, 8.33 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.626-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.807G   0.03349   0.01925    0.0317   0.08444         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.02818   0.01963   0.03007   0.07789         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.02256   0.02121   0.02952   0.07328         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G   0.01881   0.02162   0.02903   0.06946         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.01691   0.02206   0.02844   0.06741        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G   0.01635   0.02104   0.02773   0.06512         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G    0.0162   0.02064   0.02711   0.06395         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.01605   0.02008   0.02666   0.06278         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G   0.01546   0.01913   0.02646   0.06106         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.807G   0.01372    0.0187   0.02582   0.05824         1       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.427       0.208       0.174      0.0616\n",
      "            Geranium         108         197       0.427       0.208       0.174      0.0616\n",
      "10 epochs completed in 0.060 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▃▆▇█▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.17421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.4268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02582\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02813\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/230bx4gx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_000433-230bx4gx/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0174     0.188     0.764   0.00021      1.92     0.888     0.138    0.0217     0.463     0.721      1.09       0.5       0.2      2.58       3.5         0    0.0183     0.808     0.378         0    0.0777     0.349         0         0         0       0.5     0.517         0\n",
      "Evolved fitness:     0.4268    0.2081    0.1742   0.06164   0.02813   0.01388   0.02017\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01515, lrf=0.20841, momentum=0.765, weight_decay=0.0002, warmup_epochs=1.6302, warmup_momentum=0.76599, warmup_bias_lr=0.13792, box=0.02446, cls=0.37928, cls_pw=0.85564, obj=1.09, obj_pw=0.73309, iou_t=0.2, anchor_t=2.73, anchors=2.88, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.741, hsv_v=0.34697, degrees=0.0, translate=0.06563, scale=0.34587, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.59326, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_000830-39jchgoc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/39jchgoc\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 820.44it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03926   0.02643   0.02943   0.09512         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03547   0.02777   0.02821   0.09144         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02833   0.03087   0.02724   0.08643         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02343   0.03154   0.02686   0.08184         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02052   0.03213   0.02644   0.07909         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G      0.02   0.03134   0.02644   0.07778        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G    0.0199   0.02893   0.02642   0.07526         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01974   0.02735   0.02602   0.07312         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01748   0.02636   0.02635   0.07019        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G    0.0164   0.02445   0.02591   0.06676         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.428       0.208        0.15      0.0587\n",
      "            Geranium         108         197       0.428       0.208        0.15      0.0587\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▇▇█▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.1504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.42807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0164\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/39jchgoc\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_000830-39jchgoc/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.208     0.765    0.0002      1.63     0.766     0.138    0.0245     0.379     0.856      1.09     0.733       0.2      2.73      2.88         0    0.0164     0.741     0.347         0    0.0656     0.346         0         0         0       0.5     0.593         0\n",
      "Evolved fitness:     0.4281    0.2081    0.1504   0.05875   0.03166   0.02072   0.03815\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01508, lrf=0.20029, momentum=0.75308, weight_decay=0.0002, warmup_epochs=1.4098, warmup_momentum=0.67086, warmup_bias_lr=0.10776, box=0.02627, cls=0.383, cls_pw=0.85927, obj=1.02967, obj_pw=0.68979, iou_t=0.2, anchor_t=2.78807, anchors=3.13209, fl_gamma=0.0, hsv_h=0.01768, hsv_s=0.741, hsv_v=0.29312, degrees=0.0, translate=0.07453, scale=0.2992, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.59714, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.13209\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_001213-3l4tbgxk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3l4tbgxk\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 848.05it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.73 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.609-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602:  98%|▉| 9\u001b[0m\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.73 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.614-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04278   0.02421   0.03008   0.09707         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03933   0.02538   0.02913   0.09384         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.03283   0.02753    0.0282   0.08857        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02704   0.02868   0.02762   0.08334         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02331   0.02955   0.02696   0.07982         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02116   0.02998   0.02685   0.07799        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02093   0.02883   0.02671   0.07647         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02045   0.02791   0.02643   0.07479         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01899    0.0268    0.0262   0.07199        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01723   0.02532   0.02574    0.0683         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.401       0.208       0.135      0.0526\n",
      "            Geranium         108         197       0.401       0.208       0.135      0.0526\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▅▆▇█▇▅▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.13536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05258\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.40059\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02532\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3l4tbgxk\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_001213-3l4tbgxk/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0151       0.2     0.753    0.0002      1.41     0.671     0.108    0.0263     0.383     0.859      1.03      0.69       0.2      2.79      3.13         0    0.0177     0.741     0.293         0    0.0745     0.299         0         0         0       0.5     0.597         0\n",
      "Evolved fitness:     0.4006    0.2081    0.1354   0.05258   0.03424   0.01889   0.03591\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01341, lrf=0.23284, momentum=0.765, weight_decay=0.0002, warmup_epochs=1.50191, warmup_momentum=0.72691, warmup_bias_lr=0.138, box=0.02709, cls=0.30614, cls_pw=0.91633, obj=1.07398, obj_pw=0.7733, iou_t=0.2, anchor_t=3.01478, anchors=2.20284, fl_gamma=0.0, hsv_h=0.01373, hsv_s=0.741, hsv_v=0.32231, degrees=0.0, translate=0.07599, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.56736, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.20284\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_001558-2sqxk66r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2sqxk66r\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 798.05it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.33: 1.0000 best possible recall, 4.87 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.604-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.33: 1.0000 best possible recall, 4.78 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.609-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G   0.04397   0.02887   0.02507   0.09791         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.03973   0.03026   0.02391    0.0939         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.803G   0.03216   0.03329   0.02294    0.0884         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.803G   0.02582   0.03587   0.02254   0.08423        13       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.803G   0.02421   0.03465   0.02222   0.08108         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02308   0.03334   0.02211   0.07853         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02308   0.03201    0.0223   0.07739         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02316   0.02905    0.0222   0.07441         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.02005   0.02722   0.02216   0.06944         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01873   0.02549   0.02194   0.06616         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197         0.4       0.203       0.101      0.0417\n",
      "            Geranium         108         197         0.4       0.203       0.101      0.0417\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▂▂▁▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▆█▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▃▆▇██▇▇▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▃▆▇██▇▇▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.10077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04173\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.39968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2sqxk66r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_001558-2sqxk66r/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0134     0.233     0.765    0.0002       1.5     0.727     0.138    0.0271     0.306     0.916      1.07     0.773       0.2      3.01       2.2         0    0.0137     0.741     0.322         0     0.076     0.349         0         0         0       0.5     0.567         0\n",
      "Evolved fitness:     0.3997     0.203    0.1008   0.04173   0.03536   0.02345    0.0329\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.02328, lrf=0.21852, momentum=0.734, weight_decay=0.0002, warmup_epochs=1.63, warmup_momentum=0.65757, warmup_bias_lr=0.138, box=0.02002, cls=0.33061, cls_pw=0.61391, obj=1.17346, obj_pw=0.7374, iou_t=0.2, anchor_t=2.50448, anchors=2.0, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.741, hsv_v=0.347, degrees=0.0, translate=0.05083, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_001940-1ny8lno4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1ny8lno4\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 857.65it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.40: 1.0000 best possible recall, 4.24 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.639-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.40: 1.0000 best possible recall, 4.21 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.642-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G   0.03089   0.02789   0.02051    0.0793         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.02773   0.02862   0.01983   0.07618        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.803G    0.0219   0.03061   0.01902   0.07153         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.803G   0.01845   0.03176   0.01884   0.06905         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.803G   0.01786   0.03038   0.01842   0.06665         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.803G   0.01768   0.02894   0.01838   0.06501         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.803G   0.01795   0.02661   0.01789   0.06245         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.803G   0.01748   0.02462   0.01749   0.05959         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.803G     0.016   0.02332   0.01736   0.05667         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.803G   0.01379   0.02231   0.01716   0.05326         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.374       0.264       0.211      0.0768\n",
      "            Geranium         108         197       0.374       0.264       0.211      0.0768\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▃▃▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▅▅▄▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆▇█▇▆▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▃▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.21131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.07675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.37398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.26396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01379\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00682\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1ny8lno4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_001940-1ny8lno4/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0233     0.219     0.734    0.0002      1.63     0.658     0.138      0.02     0.331     0.614      1.17     0.737       0.2       2.5         2         0    0.0164     0.741     0.347         0    0.0508     0.349         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:      0.374     0.264    0.2113   0.07675   0.02547   0.02072   0.01075\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.21064, momentum=0.76256, weight_decay=0.0002, warmup_epochs=1.6219, warmup_momentum=0.75926, warmup_bias_lr=0.13885, box=0.02417, cls=0.383, cls_pw=0.86761, obj=1.07845, obj_pw=0.76534, iou_t=0.2, anchor_t=2.65571, anchors=2.81212, fl_gamma=0.0, hsv_h=0.01626, hsv_s=0.7601, hsv_v=0.347, degrees=0.0, translate=0.0652, scale=0.33771, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.81212\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_002325-8f870ne9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/8f870ne9\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 796.62it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.51 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.618-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.52 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.622-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03849   0.02659   0.03002   0.09509         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03488   0.02799   0.02864   0.09152         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02869   0.03051   0.02762   0.08683         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02403   0.03115   0.02727   0.08245         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02073   0.03208    0.0268   0.07961         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01988   0.03118   0.02673   0.07779        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01945   0.02941   0.02673   0.07559         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01982    0.0279   0.02644   0.07416         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01743   0.02731   0.02629   0.07103        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01617   0.02529   0.02578   0.06724         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.371       0.203       0.124      0.0487\n",
      "            Geranium         108         197       0.371       0.203       0.124      0.0487\n",
      "10 epochs completed in 0.060 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▄▆▇█▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.12416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.37093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/8f870ne9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_002325-8f870ne9/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.211     0.763    0.0002      1.62     0.759     0.139    0.0242     0.383     0.868      1.08     0.765       0.2      2.66      2.81         0    0.0163      0.76     0.347         0    0.0652     0.338         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.3709     0.203    0.1242   0.04866   0.03165   0.02041   0.03602\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01469, lrf=0.21936, momentum=0.78387, weight_decay=0.00019, warmup_epochs=1.63, warmup_momentum=0.71653, warmup_bias_lr=0.13822, box=0.02323, cls=0.37943, cls_pw=0.86086, obj=1.14236, obj_pw=0.70638, iou_t=0.2, anchor_t=2.68434, anchors=3.37184, fl_gamma=0.0, hsv_h=0.01654, hsv_s=0.68192, hsv_v=0.34566, degrees=0.0, translate=0.0659, scale=0.35319, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.37184\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_002719-2nal19bp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2nal19bp\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 845.78it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.57 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.616-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.57 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.621-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03727   0.02666   0.02966   0.09359         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03392   0.02797    0.0285   0.09039         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02816    0.0305   0.02755   0.08621         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02323   0.03149   0.02711   0.08182         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02024   0.03249   0.02658   0.07931         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01927   0.03182   0.02649   0.07757        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G    0.0189   0.03002   0.02645   0.07537         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01843   0.02814   0.02607   0.07263         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01788   0.02685   0.02597   0.07071        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01586   0.02477   0.02545   0.06607         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.394       0.234       0.165      0.0608\n",
      "            Geranium         108         197       0.394       0.234       0.165      0.0608\n",
      "10 epochs completed in 0.056 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▆▇█▇▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.16456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.39366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02477\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2nal19bp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_002719-2nal19bp/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0147     0.219     0.784   0.00019      1.63     0.717     0.138    0.0232     0.379     0.861      1.14     0.706       0.2      2.68      3.37         0    0.0165     0.682     0.346         0    0.0659     0.353         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.3937    0.2335    0.1646   0.06084   0.02867   0.02103   0.03498\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01766, lrf=0.207, momentum=0.8171, weight_decay=0.00019, warmup_epochs=1.24284, warmup_momentum=0.79896, warmup_bias_lr=0.13811, box=0.03018, cls=0.33493, cls_pw=0.7629, obj=1.26941, obj_pw=0.57067, iou_t=0.2, anchor_t=2.61922, anchors=2.54635, fl_gamma=0.0, hsv_h=0.01723, hsv_s=0.72513, hsv_v=0.3789, degrees=0.0, translate=0.07795, scale=0.30216, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.56414, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.54635\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_003100-xsj4h15p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/xsj4h15p\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 815.25it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.44 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.620-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.46 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.625-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04723    0.0249   0.02399   0.09612         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G    0.0403   0.02642   0.02303   0.08975         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G    0.0303   0.02925   0.02256    0.0821         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02485   0.03048   0.02224   0.07757         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02259   0.03001   0.02189   0.07448         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02357   0.02848   0.02174   0.07379         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02174   0.02728   0.02172   0.07075         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02144   0.02559   0.02171   0.06873         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01957   0.02472   0.02193   0.06623         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01836   0.02296   0.02149    0.0628         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197        0.42       0.198       0.115      0.0441\n",
      "            Geranium         108         197        0.42       0.198       0.115      0.0441\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▇██▆▅▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.1155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.42009\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01836\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02149\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01929\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/xsj4h15p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_003100-xsj4h15p/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0177     0.207     0.817   0.00019      1.24     0.799     0.138    0.0302     0.335     0.763      1.27     0.571       0.2      2.62      2.55         0    0.0172     0.725     0.379         0     0.078     0.302         0         0         0       0.5     0.564         0\n",
      "Evolved fitness:     0.4201     0.198    0.1155   0.04406   0.03859   0.01929   0.03136\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0154, lrf=0.20362, momentum=0.765, weight_decay=0.0002, warmup_epochs=1.6068, warmup_momentum=0.74846, warmup_bias_lr=0.13772, box=0.02408, cls=0.383, cls_pw=0.853, obj=1.09, obj_pw=0.73277, iou_t=0.2, anchor_t=2.70475, anchors=2.85672, fl_gamma=0.0, hsv_h=0.01597, hsv_s=0.73247, hsv_v=0.347, degrees=0.0, translate=0.06611, scale=0.34275, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.85672\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_003445-2na3m42w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2na3m42w\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 841.57it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.60 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.614-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.60 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.619-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03863   0.02632   0.02967   0.09461         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G    0.0352   0.02752   0.02845   0.09118         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02925   0.02996   0.02744   0.08665         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02393   0.03106   0.02701     0.082         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02096   0.03202   0.02654   0.07952         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01963    0.0314   0.02642   0.07746        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01933   0.02979   0.02633   0.07545         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01968   0.02812   0.02593   0.07373         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01694   0.02759   0.02586   0.07039        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01617   0.02537   0.02534   0.06687         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.339       0.254       0.168      0.0626\n",
      "            Geranium         108         197       0.339       0.254       0.168      0.0626\n",
      "10 epochs completed in 0.060 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▃▆▇█▇▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.16775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06264\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.33888\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.25381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01617\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03233\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2na3m42w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_003445-2na3m42w/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0154     0.204     0.765    0.0002      1.61     0.748     0.138    0.0241     0.383     0.853      1.09     0.733       0.2       2.7      2.86         0     0.016     0.732     0.347         0    0.0661     0.343         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.3389    0.2538    0.1678   0.06264   0.03233   0.01975   0.03318\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.25325, momentum=0.79633, weight_decay=0.00026, warmup_epochs=2.02954, warmup_momentum=0.60488, warmup_bias_lr=0.138, box=0.0244, cls=0.383, cls_pw=0.88637, obj=0.64381, obj_pw=0.75034, iou_t=0.2, anchor_t=3.31435, anchors=3.13185, fl_gamma=0.0, hsv_h=0.01643, hsv_s=0.65442, hsv_v=0.22257, degrees=0.0, translate=0.05634, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.55199, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.13185\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00026\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_003840-ho1yhde6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/ho1yhde6\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 825.85it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.30: 1.0000 best possible recall, 7.60 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.577-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.30: 1.0000 best possible recall, 7.56 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.583-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04195   0.01718    0.0307   0.08983         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G    0.0382   0.01845   0.02973   0.08637        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.03173   0.01988   0.02894   0.08055         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02597   0.02184   0.02831   0.07612         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02238   0.02379   0.02756   0.07373         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02031   0.02285   0.02742   0.07058         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01938   0.02276    0.0272   0.06934         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01879   0.02206   0.02675   0.06761         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01751   0.02195   0.02635   0.06582         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01623    0.0211   0.02629   0.06362         7       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.404       0.208       0.125      0.0451\n",
      "            Geranium         108         197       0.404       0.208       0.125      0.0451\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▄▆█▇▇▆▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▃▆▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▃▆▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.12463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.40367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/ho1yhde6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_003840-ho1yhde6/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.253     0.796   0.00026      2.03     0.605     0.138    0.0244     0.383     0.886     0.644      0.75       0.2      3.31      3.13         0    0.0164     0.654     0.223         0    0.0563     0.349         0         0         0       0.5     0.552         0\n",
      "Evolved fitness:     0.4037    0.2081    0.1246   0.04507   0.03311   0.01456   0.03425\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01549, lrf=0.2696, momentum=0.84807, weight_decay=0.00019, warmup_epochs=1.06725, warmup_momentum=0.85402, warmup_bias_lr=0.13912, box=0.02968, cls=0.34467, cls_pw=0.83023, obj=1.09, obj_pw=0.72133, iou_t=0.2, anchor_t=2.06801, anchors=3.22998, fl_gamma=0.0, hsv_h=0.0187, hsv_s=0.63189, hsv_v=0.347, degrees=0.0, translate=0.0634, scale=0.26098, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.45414, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.22998\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_004226-167afn7x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/167afn7x\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 807.96it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.48: 0.9988 best possible recall, 4.90 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.679-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8597: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.48: 0.9994 best possible recall, 4.96 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.528/0.860-mean/best, past_thr=0.681-mean: 72,93,  107,120,  132,194,  205,168,  191,257,  287,258,  228,362,  311,369,  403,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04204   0.02078   0.02606   0.08888         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03533   0.02188    0.0248   0.08202         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02794   0.02287   0.02417   0.07497         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02341   0.02275   0.02356   0.06973         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02195   0.02235   0.02355   0.06785         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02108   0.02201   0.02335   0.06643         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01935   0.02106   0.02311   0.06351         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01948    0.0201   0.02299   0.06257         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01741   0.01933    0.0234   0.06014         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G    0.0161   0.01808   0.02349   0.05767         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.379       0.203      0.0941      0.0404\n",
      "            Geranium         108         197       0.379       0.203      0.0941      0.0404\n",
      "10 epochs completed in 0.061 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▂▂▂▁▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▇██▇▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▃▅▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▃▅▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.09413\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.37873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02349\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01808\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03157\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/167afn7x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_004226-167afn7x/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0155      0.27     0.848   0.00019      1.07     0.854     0.139    0.0297     0.345      0.83      1.09     0.721       0.2      2.07      3.23         0    0.0187     0.632     0.347         0    0.0634     0.261         0         0         0       0.5     0.454         0\n",
      "Evolved fitness:     0.3787     0.203   0.09413   0.04037   0.03495   0.01664   0.03157\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01666, lrf=0.207, momentum=0.77561, weight_decay=0.0002, warmup_epochs=1.38154, warmup_momentum=0.64323, warmup_bias_lr=0.138, box=0.02582, cls=0.383, cls_pw=0.76761, obj=1.26211, obj_pw=0.734, iou_t=0.2, anchor_t=2.24512, anchors=2.43039, fl_gamma=0.0, hsv_h=0.01363, hsv_s=0.69426, hsv_v=0.347, degrees=0.0, translate=0.06406, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.43039\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_004622-15un05e7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/15un05e7\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 832.63it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.45: 0.9965 best possible recall, 3.86 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.660-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8301: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.45: 0.9988 best possible recall, 3.82 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.831-mean/best, past_thr=0.664-mean: 87,100,  133,174,  192,263,  278,239,  276,355,  395,397\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G    0.0382   0.02771   0.02771   0.09363         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.03555   0.02758   0.02675   0.08988        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.803G   0.02942   0.02903   0.02552   0.08397         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.803G   0.02427    0.0308   0.02524   0.08031         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.803G   0.02198   0.03037   0.02455    0.0769         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.803G    0.0218    0.0299   0.02456   0.07626         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.803G   0.02063   0.02835   0.02371    0.0727         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.803G   0.01985   0.02723    0.0232   0.07029         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.803G   0.01906   0.02482    0.0228   0.06668         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.803G   0.01713   0.02366   0.02268   0.06347         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.548       0.188       0.196      0.0596\n",
      "            Geranium         108         197       0.548       0.188       0.196      0.0596\n",
      "10 epochs completed in 0.056 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▃▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▇▅▅▄▄▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▅▆██▇▆▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.19597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.54756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.18782\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02268\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02366\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01696\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02178\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/15un05e7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_004622-15un05e7/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0167     0.207     0.776    0.0002      1.38     0.643     0.138    0.0258     0.383     0.768      1.26     0.734       0.2      2.25      2.43         0    0.0136     0.694     0.347         0    0.0641     0.349         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.5476    0.1878     0.196   0.05965   0.02987   0.02178   0.01696\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01485, lrf=0.16372, momentum=0.71075, weight_decay=0.00015, warmup_epochs=1.63, warmup_momentum=0.69024, warmup_bias_lr=0.17403, box=0.02915, cls=0.35784, cls_pw=0.79539, obj=1.41148, obj_pw=0.5, iou_t=0.2, anchor_t=2.73, anchors=4.42126, fl_gamma=0.0, hsv_h=0.01483, hsv_s=0.741, hsv_v=0.347, degrees=0.0, translate=0.05639, scale=0.22918, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.58686, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=4.42126\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00015\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_005003-wm9dp8k5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/wm9dp8k5\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 832.18it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.82 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.611-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.82 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.612-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.807G   0.04667   0.02565   0.02661   0.09894         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.04295   0.02567   0.02594   0.09456         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.03553   0.02743   0.02526   0.08822         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G   0.03025   0.02924   0.02475   0.08424         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.02623   0.03105   0.02446   0.08175         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G   0.02307   0.03058   0.02411   0.07777         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G   0.02281    0.0307   0.02412   0.07763         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.02195   0.02995   0.02379   0.07569         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G   0.02018   0.02892   0.02397   0.07307         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.807G    0.0188   0.02818   0.02398   0.07096         7       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.393       0.193        0.11      0.0415\n",
      "            Geranium         108         197       0.393       0.193        0.11      0.0415\n",
      "10 epochs completed in 0.057 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▁▃▆█▇█▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.10972\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.39336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00362\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/wm9dp8k5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_005003-wm9dp8k5/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0149     0.164     0.711   0.00015      1.63      0.69     0.174    0.0291     0.358     0.795      1.41       0.5       0.2      2.73      4.42         0    0.0148     0.741     0.347         0    0.0564     0.229         0         0         0       0.5     0.587         0\n",
      "Evolved fitness:     0.3934    0.1929    0.1097    0.0415   0.03825   0.01939   0.03408\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.18417, momentum=0.75927, weight_decay=0.00019, warmup_epochs=1.63, warmup_momentum=0.84981, warmup_bias_lr=0.132, box=0.02647, cls=0.383, cls_pw=0.74545, obj=1.14714, obj_pw=0.71215, iou_t=0.2, anchor_t=3.40541, anchors=3.90446, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.75856, hsv_v=0.32071, degrees=0.0, translate=0.08649, scale=0.41114, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.64734, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=3.90446\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_005345-kyy4foo6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/kyy4foo6\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 618.70it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.29: 1.0000 best possible recall, 10.20 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm::   0%| | 0/1000 [00:00<?, ?\u001b[0m\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.572-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.29: 1.0000 best possible recall, 10.17 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.575-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.807G   0.04496   0.03131   0.02704    0.1033         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.03922   0.03337   0.02607   0.09866         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.03104   0.03674   0.02542    0.0932         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G   0.02582   0.03762   0.02496    0.0884         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.02328    0.0375   0.02464   0.08542        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G   0.02279   0.03514   0.02453   0.08246         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G   0.02389   0.03253   0.02426   0.08068         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.02297   0.03045   0.02411   0.07753         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G   0.01996   0.02897   0.02438   0.07331         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.807G   0.01807   0.02715   0.02407   0.06929         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.455       0.208       0.134      0.0541\n",
      "            Geranium         108         197       0.455       0.208       0.134      0.0541\n",
      "10 epochs completed in 0.059 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▁▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅▇██▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.13429\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.45515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20778\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02407\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02715\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02438\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/kyy4foo6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_005345-kyy4foo6/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.184     0.759   0.00019      1.63      0.85     0.132    0.0265     0.383     0.745      1.15     0.712       0.2      3.41       3.9         0    0.0164     0.759     0.321         0    0.0865     0.411         0         0         0       0.5     0.647         0\n",
      "Evolved fitness:     0.4551    0.2078    0.1343   0.05408   0.03512   0.02438   0.03537\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01718, lrf=0.21424, momentum=0.74291, weight_decay=0.00017, warmup_epochs=1.63, warmup_momentum=0.95, warmup_bias_lr=0.14218, box=0.0244, cls=0.36733, cls_pw=0.88997, obj=1.08287, obj_pw=0.734, iou_t=0.2, anchor_t=2.34822, anchors=4.52484, fl_gamma=0.0, hsv_h=0.0179, hsv_s=0.74142, hsv_v=0.37513, degrees=0.0, translate=0.06255, scale=0.35297, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.61347, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=4.52484\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7279367 parameters, 7279367 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00017\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_005737-wdp9t4mm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/wdp9t4mm\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 920.40it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 15 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.43: 1.0000 best possible recall, 9.57 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=15, img_size=416, metric_all=0.518/0.884-mean/best, past_thr=0.639-mean: 72,81,  94,129,  131,108,  135,180,  110,251,  211,143,  187,218,  197,276,  299,201,  202,353,  270,275,  275,368,  371,293,  344,390,  404,404\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8845: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.43: 1.0000 best possible recall, 9.62 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=15, img_size=416, metric_all=0.520/0.884-mean/best, past_thr=0.640-mean: 74,83,  92,125,  133,109,  136,179,  113,248,  209,136,  180,217,  202,270,  294,203,  202,345,  275,263,  274,362,  358,301,  342,395,  408,409\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9     1.01G   0.03658   0.02482   0.02891   0.09032         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9     1.02G   0.03122   0.02558   0.02706   0.08386         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9     1.02G    0.0233   0.02864   0.02649   0.07843         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9     1.02G   0.01951   0.02843   0.02636    0.0743         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9     1.02G   0.01845   0.02705   0.02622   0.07172         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9     1.02G    0.0185   0.02647   0.02618   0.07115        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9     1.02G   0.01845   0.02463   0.02571   0.06879         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9     1.02G   0.01778   0.02339   0.02555   0.06672         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9     1.02G   0.01666   0.02214   0.02551   0.06431         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9     1.02G   0.01562   0.02129   0.02558    0.0625         6       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.405       0.198       0.111      0.0445\n",
      "            Geranium         108         197       0.405       0.198       0.111      0.0445\n",
      "10 epochs completed in 0.058 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▂▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▄▃▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅██▆▆▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.40529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03563\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00497\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/wdp9t4mm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_005737-wdp9t4mm/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0172     0.214     0.743   0.00017      1.63      0.95     0.142    0.0244     0.367      0.89      1.08     0.734       0.2      2.35      4.52         0    0.0179     0.741     0.375         0    0.0625     0.353         0         0         0       0.5     0.613         0\n",
      "Evolved fitness:     0.4053     0.198     0.111   0.04449    0.0314   0.01821   0.03563\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0148, lrf=0.20174, momentum=0.76934, weight_decay=0.0002, warmup_epochs=1.63051, warmup_momentum=0.767, warmup_bias_lr=0.13656, box=0.02536, cls=0.37514, cls_pw=0.86719, obj=1.06635, obj_pw=0.734, iou_t=0.2, anchor_t=2.79668, anchors=2.89442, fl_gamma=0.0, hsv_h=0.01633, hsv_s=0.7712, hsv_v=0.35038, degrees=0.0, translate=0.0648, scale=0.33237, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.89442\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_010145-3037zrqw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3037zrqw\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 802.72it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.75 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.609-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.75 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.614-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04083   0.02623   0.02943   0.09649         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03674   0.02787   0.02814   0.09275         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02985   0.03068   0.02721   0.08774         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02494   0.03152   0.02681   0.08327         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02183   0.03242   0.02629   0.08055         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02052   0.03164   0.02624    0.0784        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02042   0.02979   0.02622   0.07642         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02025   0.02859   0.02595    0.0748         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G    0.0186   0.02769   0.02599   0.07228        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01681   0.02592   0.02559   0.06832         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.413       0.234        0.11      0.0399\n",
      "            Geranium         108         197       0.413       0.234        0.11      0.0399\n",
      "10 epochs completed in 0.060 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▆▇█▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.10974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.03991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.41291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01681\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02559\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3037zrqw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_010145-3037zrqw/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0148     0.202     0.769    0.0002      1.63     0.767     0.137    0.0254     0.375     0.867      1.07     0.734       0.2       2.8      2.89         0    0.0163     0.771      0.35         0    0.0648     0.332         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.4129    0.2335    0.1097   0.03991   0.03384   0.02054   0.03767\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01584, lrf=0.16992, momentum=0.74166, weight_decay=0.0002, warmup_epochs=1.79634, warmup_momentum=0.89212, warmup_bias_lr=0.08016, box=0.0244, cls=0.36946, cls_pw=0.75069, obj=0.92641, obj_pw=0.734, iou_t=0.2, anchor_t=2.73, anchors=3.28497, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.71706, hsv_v=0.347, degrees=0.0, translate=0.0659, scale=0.36692, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=3.28497\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_010538-138unenj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/138unenj\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1129.94it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G    0.0385   0.02278   0.02609   0.08738         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03182   0.02523   0.02502   0.08207         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02389   0.02806   0.02433   0.07628         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02048   0.02799    0.0241   0.07257         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01895    0.0279   0.02373   0.07057         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01833   0.02662   0.02371   0.06867        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01788   0.02519   0.02369   0.06677         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01816   0.02408    0.0235   0.06574         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01752   0.02357   0.02351   0.06461        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01514   0.02212    0.0231   0.06036         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.385       0.213       0.118      0.0501\n",
      "            Geranium         108         197       0.385       0.213       0.118      0.0501\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▅███▆▅▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▃▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.11839\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05015\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.38498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.21289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0231\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/138unenj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_010538-138unenj/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0158      0.17     0.742    0.0002       1.8     0.892    0.0802    0.0244     0.369     0.751     0.926     0.734       0.2      2.73      3.28         0    0.0164     0.717     0.347         0    0.0659     0.367         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:      0.385    0.2129    0.1184   0.05015   0.03072     0.018   0.03252\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01496, lrf=0.219, momentum=0.765, weight_decay=0.0002, warmup_epochs=1.57995, warmup_momentum=0.82719, warmup_bias_lr=0.138, box=0.0244, cls=0.45233, cls_pw=0.79999, obj=1.09, obj_pw=0.82456, iou_t=0.2, anchor_t=2.68935, anchors=2.08226, fl_gamma=0.0, hsv_h=0.01445, hsv_s=0.74375, hsv_v=0.38857, degrees=0.0, translate=0.07953, scale=0.33614, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.08226\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_010756-p60npi18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/p60npi18\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1170.83it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 4.47 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.626-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 4.41 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.630-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G   0.03793   0.02945   0.03309    0.1005         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.03254   0.03128   0.03116   0.09499        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.803G   0.02523   0.03347   0.02981   0.08851         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.803G   0.02172   0.03432   0.02964   0.08568         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.803G   0.02132   0.03216   0.02841   0.08189         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.803G   0.02115   0.02981   0.02779   0.07875         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.803G    0.0217   0.02751   0.02691   0.07612         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.803G   0.02162   0.02607   0.02662   0.07431         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.803G   0.01892     0.025   0.02634   0.07026         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.803G   0.01651   0.02408   0.02614   0.06673         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197        0.39       0.249       0.187      0.0717\n",
      "            Geranium         108         197        0.39       0.249       0.187      0.0717\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▃▃▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▃▃▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆▇█▇▅▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.18748\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.07174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.39019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.24873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01651\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02854\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01824\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/p60npi18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_010756-p60npi18/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "     0.015     0.219     0.765    0.0002      1.58     0.827     0.138    0.0244     0.452       0.8      1.09     0.825       0.2      2.69      2.08         0    0.0144     0.744     0.389         0    0.0795     0.336         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.3902    0.2487    0.1875   0.07174   0.02854   0.02343   0.01824\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0192, lrf=0.207, momentum=0.72089, weight_decay=0.00023, warmup_epochs=1.63, warmup_momentum=0.91687, warmup_bias_lr=0.11788, box=0.0244, cls=0.48179, cls_pw=0.853, obj=1.09, obj_pw=0.74487, iou_t=0.2, anchor_t=2.35866, anchors=2.0, fl_gamma=0.0, hsv_h=0.01885, hsv_s=0.74345, hsv_v=0.24413, degrees=0.0, translate=0.05754, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.67703, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00023\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_011016-s17oqldi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/s17oqldi\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1115.42it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.42: 0.9988 best possible recall, 4.05 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.649-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.42: 1.0000 best possible recall, 4.05 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.539/0.830-mean/best, past_thr=0.652-mean: 90,103,  136,177,  188,262,  274,239,  266,353,  395,396\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G   0.03622   0.02544   0.03604    0.0977         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.03022   0.02664   0.03308   0.08994        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02351   0.02868    0.0313   0.08349         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02096    0.0291   0.03034    0.0804         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02066   0.02695   0.02903   0.07664         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02076   0.02587   0.02864   0.07527         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02005   0.02469    0.0289   0.07364        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01947   0.02332   0.02819   0.07097         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G    0.0178   0.02151   0.02757   0.06688         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01581   0.02125   0.02728   0.06434         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.347       0.249       0.187      0.0635\n",
      "            Geranium         108         197       0.347       0.249       0.187      0.0635\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▃▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆██▆▅▄▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▃▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06345\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.34704\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.24873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01581\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02728\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0278\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01908\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/s17oqldi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_011016-s17oqldi/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0192     0.207     0.721   0.00023      1.63     0.917     0.118    0.0244     0.482     0.853      1.09     0.745       0.2      2.36         2         0    0.0188     0.743     0.244         0    0.0575     0.349         0         0         0       0.5     0.677         0\n",
      "Evolved fitness:      0.347    0.2487     0.187   0.06345    0.0278   0.01908   0.01561\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01658, lrf=0.15828, momentum=0.83061, weight_decay=0.00019, warmup_epochs=1.63922, warmup_momentum=0.767, warmup_bias_lr=0.15612, box=0.02459, cls=0.383, cls_pw=0.82088, obj=1.12644, obj_pw=0.78699, iou_t=0.2, anchor_t=3.12422, anchors=3.54593, fl_gamma=0.0, hsv_h=0.01665, hsv_s=0.67566, hsv_v=0.35382, degrees=0.0, translate=0.0659, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.49909, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.54593\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_011235-go2i4p1a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/go2i4p1a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1128.11it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.32: 1.0000 best possible recall, 9.70 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.586-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.32: 1.0000 best possible recall, 9.70 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.588-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.807G   0.04117   0.02951   0.02901   0.09969        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.03655   0.03186   0.02801   0.09642         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.02889   0.03519   0.02714   0.09123        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G   0.02447   0.03581   0.02657   0.08685         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.02192   0.03606   0.02617   0.08416         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G   0.02095   0.03282   0.02589   0.07967         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G   0.02102   0.03066   0.02571   0.07738         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.02039   0.02861    0.0258    0.0748         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G   0.01811    0.0259   0.02585   0.06986         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.807G   0.01567   0.02459   0.02579   0.06606         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.441       0.193       0.119      0.0423\n",
      "            Geranium         108         197       0.441       0.193       0.119      0.0423\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▃▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅▇██▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.11861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.44082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02459\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/go2i4p1a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_011235-go2i4p1a/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0166     0.158     0.831   0.00019      1.64     0.767     0.156    0.0246     0.383     0.821      1.13     0.787       0.2      3.12      3.55         0    0.0167     0.676     0.354         0    0.0659     0.349         0         0         0       0.5     0.499         0\n",
      "Evolved fitness:     0.4408    0.1929    0.1186   0.04229   0.03152   0.02551   0.03763\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01588, lrf=0.22003, momentum=0.76364, weight_decay=0.0002, warmup_epochs=1.58795, warmup_momentum=0.76283, warmup_bias_lr=0.14946, box=0.02483, cls=0.383, cls_pw=0.87289, obj=1.08586, obj_pw=0.76508, iou_t=0.2, anchor_t=2.76601, anchors=2.88, fl_gamma=0.0, hsv_h=0.01586, hsv_s=0.6954, hsv_v=0.33751, degrees=0.0, translate=0.06907, scale=0.35249, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.54795, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_011455-2c2mrxca\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2c2mrxca\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1177.14it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.69 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.611-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.70 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.616-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G    0.0398   0.02749   0.03012   0.09741         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03557   0.02887   0.02876    0.0932        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02812   0.03161   0.02807    0.0878         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02324   0.03318   0.02747   0.08389         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02121   0.03431   0.02692   0.08244         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02092   0.03129   0.02673   0.07895         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02004   0.03003   0.02707   0.07714         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01958   0.02786   0.02656   0.07399         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01871   0.02652   0.02656   0.07179         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G    0.0168   0.02517   0.02648   0.06845         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197        0.33       0.213       0.137      0.0607\n",
      "            Geranium         108         197        0.33       0.213       0.137      0.0607\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▁▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▆▇█▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.13711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.32973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0318\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03804\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2c2mrxca\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_011455-2c2mrxca/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0159      0.22     0.764    0.0002      1.59     0.763     0.149    0.0248     0.383     0.873      1.09     0.765       0.2      2.77      2.88         0    0.0159     0.695     0.338         0    0.0691     0.352         0         0         0       0.5     0.548         0\n",
      "Evolved fitness:     0.3297    0.2132    0.1371   0.06072    0.0318   0.02213   0.03804\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.016, lrf=0.19125, momentum=0.74835, weight_decay=0.00021, warmup_epochs=1.69704, warmup_momentum=0.767, warmup_bias_lr=0.138, box=0.02483, cls=0.383, cls_pw=0.82846, obj=1.24876, obj_pw=0.69297, iou_t=0.2, anchor_t=2.72319, anchors=2.81866, fl_gamma=0.0, hsv_h=0.0171, hsv_s=0.741, hsv_v=0.30208, degrees=0.0, translate=0.06117, scale=0.36808, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.57221, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.81866\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_011715-2jx9fd8j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2jx9fd8j\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1139.37it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.62 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.63 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03969   0.02879   0.02904   0.09753         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03446   0.03099   0.02783   0.09328         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02734   0.03387   0.02697   0.08817         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02309     0.036   0.02678   0.08587         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02126   0.03487   0.02624   0.08237         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02046    0.0336   0.02622   0.08028         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02043   0.03162   0.02627   0.07832        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01968   0.03028   0.02607   0.07603         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01776   0.02916   0.02633   0.07324         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01636   0.02641   0.02595   0.06872         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.451       0.208       0.137      0.0608\n",
      "            Geranium         108         197       0.451       0.208       0.137      0.0608\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▃▂▂▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▆█▇▆▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.13729\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06084\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.45133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20812\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01636\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2jx9fd8j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_011715-2jx9fd8j/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "     0.016     0.191     0.748   0.00021       1.7     0.767     0.138    0.0248     0.383     0.828      1.25     0.693       0.2      2.72      2.82         0    0.0171     0.741     0.302         0    0.0612     0.368         0         0         0       0.5     0.572         0\n",
      "Evolved fitness:     0.4513    0.2081    0.1373   0.06084   0.03074   0.02311   0.03706\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01553, lrf=0.22992, momentum=0.765, weight_decay=0.00021, warmup_epochs=1.63, warmup_momentum=0.767, warmup_bias_lr=0.13023, box=0.0244, cls=0.40497, cls_pw=0.8356, obj=1.18676, obj_pw=0.82738, iou_t=0.2, anchor_t=2.81252, anchors=2.0, fl_gamma=0.0, hsv_h=0.01713, hsv_s=0.76756, hsv_v=0.36152, degrees=0.0, translate=0.0659, scale=0.35772, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.70575, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_011935-1q9gz9zu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1q9gz9zu\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1130.72it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 4.63 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm::   0%| | 0/1000 [00:00<?, ?\u001b[0m\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.617-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 4.57 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.621-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G   0.03879   0.03334   0.03082     0.103         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.03426   0.03608   0.02925   0.09958         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.803G   0.02692   0.03906   0.02824   0.09423         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.803G   0.02274   0.04017   0.02776   0.09067         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.803G   0.02204   0.03789   0.02759   0.08752         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.803G   0.02262   0.03406   0.02711   0.08378        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02139   0.03084   0.02746    0.0797         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02166   0.02939     0.027   0.07805        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01879    0.0285   0.02654   0.07383         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01731   0.02762   0.02595   0.07088         1       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.422       0.244       0.196      0.0676\n",
      "            Geranium         108         197       0.422       0.244       0.196      0.0676\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▃▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▆▇█▇▅▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.19592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.42193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.24365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02595\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02985\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1q9gz9zu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_011935-1q9gz9zu/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0155      0.23     0.765   0.00021      1.63     0.767      0.13    0.0244     0.405     0.836      1.19     0.827       0.2      2.81         2         0    0.0171     0.768     0.362         0    0.0659     0.358         0         0         0       0.5     0.706         0\n",
      "Evolved fitness:     0.4219    0.2437    0.1959   0.06761   0.03189    0.0244   0.02985\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.20782, momentum=0.7732, weight_decay=0.0002, warmup_epochs=1.6163, warmup_momentum=0.767, warmup_bias_lr=0.13515, box=0.02444, cls=0.38986, cls_pw=0.86696, obj=1.09, obj_pw=0.6995, iou_t=0.2, anchor_t=2.86767, anchors=2.50709, fl_gamma=0.0, hsv_h=0.0174, hsv_s=0.72877, hsv_v=0.34401, degrees=0.0, translate=0.06975, scale=0.35302, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.50709\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_012154-2ey6je8m\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2ey6je8m\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1122.75it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.35: 1.0000 best possible recall, 6.88 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm::   0%| | 0/1000 [00:00<?, ?\u001b[0m\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.604-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.35: 1.0000 best possible recall, 6.86 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.609-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03966    0.0262   0.03052   0.09638         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03545   0.02791   0.02916   0.09253         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02866   0.03083   0.02818   0.08767         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G    0.0238   0.03163   0.02768   0.08311         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G    0.0209   0.03236    0.0272   0.08047         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02027   0.03119    0.0271   0.07856        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01999   0.02952   0.02695   0.07646         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01996    0.0281   0.02648   0.07454         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01758   0.02736   0.02633   0.07126        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01679    0.0253   0.02569   0.06777         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.407       0.213       0.172      0.0589\n",
      "            Geranium         108         197       0.407       0.213       0.172      0.0589\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▄▆▇█▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.17169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05886\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.40749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.21296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2ey6je8m\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_012154-2ey6je8m/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.208     0.773    0.0002      1.62     0.767     0.135    0.0244      0.39     0.867      1.09       0.7       0.2      2.87      2.51         0    0.0174     0.729     0.344         0    0.0698     0.353         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.4075     0.213    0.1717   0.05886   0.03256   0.02078   0.03191\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01756, lrf=0.19333, momentum=0.765, weight_decay=0.00019, warmup_epochs=1.60623, warmup_momentum=0.79835, warmup_bias_lr=0.14043, box=0.02, cls=0.40577, cls_pw=0.853, obj=1.03872, obj_pw=0.73658, iou_t=0.2, anchor_t=2.92197, anchors=2.95198, fl_gamma=0.0, hsv_h=0.0154, hsv_s=0.66737, hsv_v=0.347, degrees=0.0, translate=0.06091, scale=0.27052, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.58583, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.95198\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_012414-wp8jzldp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/wp8jzldp\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1111.60it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 6.96 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.601-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 6.94 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.606-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03263   0.02604   0.03128   0.08996         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02882   0.02773   0.02971   0.08627         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02285    0.0309   0.02861   0.08236         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01885   0.03216   0.02834   0.07936         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01694   0.03135   0.02765   0.07594         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01705   0.02948   0.02793   0.07446         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01678   0.02798   0.02764   0.07241         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G    0.0166   0.02593   0.02755   0.07009         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01502   0.02457   0.02734   0.06693         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01369   0.02357     0.027   0.06426         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.394       0.269       0.146      0.0607\n",
      "            Geranium         108         197       0.394       0.269       0.146      0.0607\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▂▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▇█▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.39384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.26904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01369\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03535\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/wp8jzldp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_012414-wp8jzldp/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0176     0.193     0.765   0.00019      1.61     0.798      0.14      0.02     0.406     0.853      1.04     0.737       0.2      2.92      2.95         0    0.0154     0.667     0.347         0    0.0609     0.271         0         0         0       0.5     0.586         0\n",
      "Evolved fitness:     0.3938     0.269    0.1463   0.06075   0.02698   0.01975   0.03535\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.25014, momentum=0.81736, weight_decay=0.0002, warmup_epochs=1.69619, warmup_momentum=0.79007, warmup_bias_lr=0.138, box=0.02, cls=0.383, cls_pw=0.74598, obj=0.97271, obj_pw=0.90995, iou_t=0.2, anchor_t=2.73, anchors=2.36229, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.74395, hsv_v=0.23598, degrees=0.0, translate=0.0659, scale=0.39538, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.36229\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_012634-ciuu9zxr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/ciuu9zxr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1165.38it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 4.53 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.622-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 4.47 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.627-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G    0.0316   0.02862    0.0269   0.08712         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.803G   0.02837   0.02999   0.02572   0.08408        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.803G   0.02269   0.03208   0.02466   0.07942         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.803G   0.01906   0.03326   0.02454   0.07687         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.803G   0.01795   0.03129   0.02374   0.07297         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G    0.0181   0.02847   0.02352   0.07009         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01776   0.02592   0.02273   0.06641         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01694   0.02449   0.02235   0.06377         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01564    0.0232   0.02235   0.06119         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01368   0.02209    0.0218   0.05756         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197        0.51       0.238       0.241      0.0844\n",
      "            Geranium         108         197        0.51       0.238       0.241      0.0844\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆▇█▇▅▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▃▆▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▃▆▇████▆▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.24052\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.08445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.51017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.23792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01368\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01833\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02323\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/ciuu9zxr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_012634-ciuu9zxr/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152      0.25     0.817    0.0002       1.7      0.79     0.138      0.02     0.383     0.746     0.973      0.91       0.2      2.73      2.36         0    0.0164     0.744     0.236         0    0.0659     0.395         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.5102    0.2379    0.2405   0.08445   0.02253   0.02323   0.01833\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01435, lrf=0.20702, momentum=0.74564, weight_decay=0.00019, warmup_epochs=1.74052, warmup_momentum=0.80765, warmup_bias_lr=0.138, box=0.02421, cls=0.40641, cls_pw=0.8837, obj=1.09, obj_pw=0.68358, iou_t=0.2, anchor_t=2.73, anchors=3.21311, fl_gamma=0.0, hsv_h=0.01596, hsv_s=0.75944, hsv_v=0.37249, degrees=0.0, translate=0.06793, scale=0.33138, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.58817, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.21311\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_012854-2ajh0zkr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2ajh0zkr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1125.95it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0/9    0.805G   0.03874   0.02508   0.03212   0.09593         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03455    0.0265   0.03041   0.09146         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02793   0.02934   0.02942    0.0867         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02303    0.0302    0.0291   0.08234         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02049   0.03089   0.02848   0.07986         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01955   0.03021   0.02853    0.0783         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01932   0.02899    0.0281   0.07641         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01873   0.02783   0.02791   0.07448         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01804   0.02692   0.02745   0.07241         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01685     0.026   0.02676   0.06962         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.386       0.228       0.171      0.0555\n",
      "            Geranium         108         197       0.386       0.228       0.171      0.0555\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▆▇█▇▆▄▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.17056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05554\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.38618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22843\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02676\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.026\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2ajh0zkr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_012854-2ajh0zkr/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0143     0.207     0.746   0.00019      1.74     0.808     0.138    0.0242     0.406     0.884      1.09     0.684       0.2      2.73      3.21         0     0.016     0.759     0.372         0    0.0679     0.331         0         0         0       0.5     0.588         0\n",
      "Evolved fitness:     0.3862    0.2284    0.1706   0.05554   0.03665   0.01754   0.02692\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0162, lrf=0.207, momentum=0.75778, weight_decay=0.00021, warmup_epochs=1.69846, warmup_momentum=0.74601, warmup_bias_lr=0.14488, box=0.0244, cls=0.34387, cls_pw=0.76756, obj=1.00336, obj_pw=0.734, iou_t=0.2, anchor_t=2.67314, anchors=3.99354, fl_gamma=0.0, hsv_h=0.01566, hsv_s=0.741, hsv_v=0.347, degrees=0.0, translate=0.07147, scale=0.36966, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.56292, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.99354\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_013115-3vj13h8h\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3vj13h8h\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1145.23it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.68 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.615-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.67 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.616-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.807G   0.03908   0.02394   0.02493   0.08795         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.03494    0.0245   0.02413   0.08356         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.02832   0.02665    0.0236   0.07856         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G   0.02411   0.02797   0.02306   0.07515         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.02114   0.02917   0.02292   0.07324         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G    0.0198   0.02859   0.02251    0.0709         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G   0.01968   0.02754   0.02267   0.06989         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.01903    0.0273   0.02256   0.06889         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G   0.01719   0.02494   0.02234   0.06446         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.807G    0.0162   0.02397   0.02248   0.06265         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.406       0.198       0.112      0.0437\n",
      "            Geranium         108         197       0.406       0.198       0.112      0.0437\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▃▁▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▅▆█▇▆▅▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.11217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.40572\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02397\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03301\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03195\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01766\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3vj13h8h\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_013115-3vj13h8h/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0162     0.207     0.758   0.00021       1.7     0.746     0.145    0.0244     0.344     0.768         1     0.734       0.2      2.67      3.99         0    0.0157     0.741     0.347         0    0.0715      0.37         0         0         0       0.5     0.563         0\n",
      "Evolved fitness:     0.4057     0.198    0.1122   0.04372   0.03301   0.01766   0.03195\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01168, lrf=0.1552, momentum=0.70767, weight_decay=0.00018, warmup_epochs=1.53636, warmup_momentum=0.89152, warmup_bias_lr=0.138, box=0.02458, cls=0.30073, cls_pw=0.88761, obj=0.76583, obj_pw=0.64497, iou_t=0.2, anchor_t=2.95838, anchors=2.96891, fl_gamma=0.0, hsv_h=0.01772, hsv_s=0.82697, hsv_v=0.30906, degrees=0.0, translate=0.05518, scale=0.30163, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.68484, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.96891\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00018\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_013335-22xlxxvy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/22xlxxvy\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1108.49it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 7.02 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.599-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 6.99 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.604-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03984   0.01815   0.02382   0.08182         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03526   0.01939   0.02274   0.07739         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02837   0.02186   0.02208   0.07231        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02286   0.02374   0.02192   0.06852        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G    0.0199   0.02368   0.02166   0.06524         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01893   0.02322    0.0214   0.06355         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01829   0.02368    0.0215   0.06346         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01761   0.02313   0.02143   0.06216         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01666   0.02215   0.02119      0.06         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01553    0.0225   0.02099   0.05902        10       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.372       0.203       0.121      0.0451\n",
      "            Geranium         108         197       0.372       0.203       0.121      0.0451\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▆██▇█▇▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.37224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.20305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03134\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01444\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/22xlxxvy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_013335-22xlxxvy/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0117     0.155     0.708   0.00018      1.54     0.892     0.138    0.0246     0.301     0.888     0.766     0.645       0.2      2.96      2.97         0    0.0177     0.827     0.309         0    0.0552     0.302         0         0         0       0.5     0.685         0\n",
      "Evolved fitness:     0.3722     0.203     0.121   0.04514   0.03134   0.01444   0.03092\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01981, lrf=0.19231, momentum=0.765, weight_decay=0.00017, warmup_epochs=1.45251, warmup_momentum=0.69279, warmup_bias_lr=0.12961, box=0.0232, cls=0.2924, cls_pw=0.93214, obj=1.2996, obj_pw=0.73952, iou_t=0.2, anchor_t=2.62454, anchors=2.88, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.64768, hsv_v=0.4039, degrees=0.0, translate=0.08235, scale=0.29352, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.68196, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00017\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_013556-1qkpf0z9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1qkpf0z9\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1122.05it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.44 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.620-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 6.47 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.624-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G     0.037   0.03178   0.02435   0.09313         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03275   0.03372   0.02349   0.08997         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02695   0.03649   0.02266    0.0861        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02248   0.03847   0.02227   0.08321         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02043   0.03693   0.02187   0.07923         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02034   0.03451   0.02151   0.07636         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01952   0.03347   0.02146   0.07446         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01887   0.03067   0.02142   0.07097        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01739   0.02751   0.02117   0.06607         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01634   0.02738     0.021   0.06472        10       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.369       0.228       0.131      0.0553\n",
      "            Geranium         108         197       0.369       0.228       0.131      0.0553\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅▇█▇▆▅▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▃▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05526\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.36877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22834\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01634\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.021\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00534\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1qkpf0z9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_013556-1qkpf0z9/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0198     0.192     0.765   0.00017      1.45     0.693      0.13    0.0232     0.292     0.932       1.3      0.74       0.2      2.62      2.88         0    0.0164     0.648     0.404         0    0.0824     0.294         0         0         0       0.5     0.682         0\n",
      "Evolved fitness:     0.3688    0.2283     0.131   0.05526   0.02927   0.02468    0.0314\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01477, lrf=0.18866, momentum=0.7224, weight_decay=0.00018, warmup_epochs=1.64775, warmup_momentum=0.767, warmup_bias_lr=0.17205, box=0.02365, cls=0.36028, cls_pw=0.80834, obj=0.98081, obj_pw=0.83807, iou_t=0.2, anchor_t=2.33966, anchors=2.79525, fl_gamma=0.0, hsv_h=0.01581, hsv_s=0.66649, hsv_v=0.30052, degrees=0.0, translate=0.0659, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.57692, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.79525\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00018\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_013816-31ofnmko\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/31ofnmko\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1139.36it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.43: 0.9994 best possible recall, 5.75 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.646-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.43: 1.0000 best possible recall, 5.84 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.648-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03593   0.02381   0.02678   0.08652         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03226   0.02511   0.02574   0.08311         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02701   0.02675   0.02474   0.07849         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02256   0.02841   0.02471   0.07568         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01974   0.02849   0.02433   0.07255         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01932   0.02734   0.02424    0.0709         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G    0.0185   0.02706   0.02431   0.06986        12       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01764   0.02606   0.02431   0.06801         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01639   0.02606   0.02416   0.06661         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01531   0.02458   0.02393   0.06382         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.376       0.213       0.134      0.0548\n",
      "            Geranium         108         197       0.376       0.213       0.134      0.0548\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▃▅██▆▆▄▄▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.13449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.37638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01531\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/31ofnmko\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_013816-31ofnmko/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0148     0.189     0.722   0.00018      1.65     0.767     0.172    0.0237      0.36     0.808     0.981     0.838       0.2      2.34       2.8         0    0.0158     0.666     0.301         0    0.0659     0.349         0         0         0       0.5     0.577         0\n",
      "Evolved fitness:     0.3764    0.2132    0.1345   0.05485   0.02795   0.01922   0.03423\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01591, lrf=0.19837, momentum=0.73507, weight_decay=0.00019, warmup_epochs=1.69826, warmup_momentum=0.767, warmup_bias_lr=0.13523, box=0.0244, cls=0.36904, cls_pw=0.97731, obj=1.03477, obj_pw=0.78805, iou_t=0.2, anchor_t=2.65853, anchors=2.24551, fl_gamma=0.0, hsv_h=0.01548, hsv_s=0.7838, hsv_v=0.33401, degrees=0.0, translate=0.0716, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.24551\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_014037-3ey5i6k1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3ey5i6k1\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1116.96it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 4.44 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.627-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.38: 1.0000 best possible recall, 4.39 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.632-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.803G   0.03796   0.02695   0.03142   0.09633         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G    0.0343   0.02782   0.02969   0.09181        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02724   0.02992    0.0282   0.08536         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02242   0.03158   0.02794   0.08195         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02099   0.03075   0.02709   0.07883         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02073   0.02965   0.02704   0.07741         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02079   0.02797   0.02598   0.07474         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02064   0.02645   0.02545   0.07254         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01806    0.0249   0.02514   0.06809         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01713   0.02363   0.02475   0.06551         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.453       0.249       0.187      0.0446\n",
      "            Geranium         108         197       0.453       0.249       0.187      0.0446\n",
      "10 epochs completed in 0.035 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅▇█▇▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.18714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.0446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.45291\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.24873\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00437\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3ey5i6k1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_014037-3ey5i6k1/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0159     0.198     0.735   0.00019       1.7     0.767     0.135    0.0244     0.369     0.977      1.03     0.788       0.2      2.66      2.25         0    0.0155     0.784     0.334         0    0.0716     0.349         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.4529    0.2487    0.1871    0.0446   0.03012   0.02042   0.01714\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01587, lrf=0.20319, momentum=0.76842, weight_decay=0.00018, warmup_epochs=1.52675, warmup_momentum=0.7402, warmup_bias_lr=0.14097, box=0.02253, cls=0.33149, cls_pw=0.8819, obj=1.16598, obj_pw=0.71377, iou_t=0.2, anchor_t=2.77544, anchors=3.28117, fl_gamma=0.0, hsv_h=0.01775, hsv_s=0.75193, hsv_v=0.347, degrees=0.0, translate=0.06561, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.55377, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.28117\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00018\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_014257-3qrssqas\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3qrssqas\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1111.31it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.71 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.610-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.36: 1.0000 best possible recall, 6.71 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.615-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03635   0.02785    0.0264   0.09059         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G    0.0326   0.02941   0.02537   0.08738         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02646   0.03141   0.02462   0.08249         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02223   0.03278   0.02416   0.07916         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02021   0.03389   0.02355   0.07765         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01934   0.03157    0.0234   0.07432         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01839   0.03065    0.0236   0.07264        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01852   0.02802   0.02348   0.07002         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01697   0.02717   0.02324   0.06739         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01555   0.02538   0.02352   0.06444         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.429       0.218       0.134      0.0605\n",
      "            Geranium         108         197       0.429       0.218       0.134      0.0605\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▁▂▂▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▆▇█▆▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.13372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.42944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.21827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02352\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02789\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02272\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3qrssqas\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_014257-3qrssqas/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0159     0.203     0.768   0.00018      1.53      0.74     0.141    0.0225     0.331     0.882      1.17     0.714       0.2      2.78      3.28         0    0.0177     0.752     0.347         0    0.0656     0.349         0         0         0       0.5     0.554         0\n",
      "Evolved fitness:     0.4294    0.2183    0.1337   0.06055   0.02789   0.02272   0.03415\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01079, lrf=0.20714, momentum=0.765, weight_decay=0.00018, warmup_epochs=1.86187, warmup_momentum=0.68115, warmup_bias_lr=0.14709, box=0.02576, cls=0.383, cls_pw=0.65086, obj=1.0092, obj_pw=0.69151, iou_t=0.2, anchor_t=2.20223, anchors=3.40681, fl_gamma=0.0, hsv_h=0.01481, hsv_s=0.67084, hsv_v=0.37771, degrees=0.0, translate=0.05773, scale=0.21724, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.60018, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.40681\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00018\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_014518-2l0vn2ex\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2l0vn2ex\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 802.34it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.45: 0.9988 best possible recall, 5.39 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.660-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8599: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.45: 0.9994 best possible recall, 5.46 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.662-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03854   0.02066   0.02471   0.08391         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03532   0.02093   0.02396   0.08021         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.03073   0.02187   0.02345   0.07605        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02583   0.02268   0.02311   0.07162         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02248   0.02337   0.02275    0.0686         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G    0.0206   0.02384   0.02275   0.06719         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01947   0.02349   0.02236   0.06532         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G    0.0184   0.02336   0.02251   0.06428         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01699   0.02323   0.02231   0.06253        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G    0.0158   0.02255     0.022   0.06036         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197        0.36       0.193       0.143      0.0639\n",
      "            Geranium         108         197        0.36       0.193       0.143      0.0639\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▆▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▃▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁▂▄▅▇█▇▇▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.35954\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.19289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02954\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2l0vn2ex\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_014518-2l0vn2ex/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0108     0.207     0.765   0.00018      1.86     0.681     0.147    0.0258     0.383     0.651      1.01     0.692       0.2       2.2      3.41         0    0.0148     0.671     0.378         0    0.0577     0.217         0         0         0       0.5       0.6         0\n",
      "Evolved fitness:     0.3595    0.1929    0.1427   0.06393   0.02965   0.01672   0.02954\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.207, momentum=0.76517, weight_decay=0.0002, warmup_epochs=1.62803, warmup_momentum=0.76672, warmup_bias_lr=0.13799, box=0.0244, cls=0.383, cls_pw=0.85256, obj=1.08979, obj_pw=0.73464, iou_t=0.2, anchor_t=2.73, anchors=2.88224, fl_gamma=0.0, hsv_h=0.01639, hsv_s=0.741, hsv_v=0.34691, degrees=0.0, translate=0.06587, scale=0.34864, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.59397, mixup=0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml anchors with anchors=2.88224\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_014739-282dpbzm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/282dpbzm\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|███████| 1140/1140 [00:01<00:00, 991.61it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03923   0.02643   0.02961   0.09527         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03512   0.02806   0.02833   0.09151         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02843   0.03082   0.02747   0.08671         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02337   0.03184   0.02714   0.08235         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02043   0.03251   0.02667   0.07961         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01966   0.03141   0.02658   0.07765        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01969   0.02952   0.02658   0.07579         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01931   0.02814   0.02628   0.07372         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01743   0.02758   0.02632   0.07133        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01618   0.02552   0.02592   0.06763         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.429       0.223       0.114      0.0405\n",
      "            Geranium         108         197       0.429       0.223       0.114      0.0405\n",
      "10 epochs completed in 0.040 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▄▆▇█▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.11415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.04048\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.42869\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.22335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01618\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02552\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/282dpbzm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_014739-282dpbzm/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.207     0.765    0.0002      1.63     0.767     0.138    0.0244     0.383     0.853      1.09     0.735       0.2      2.73      2.88         0    0.0164     0.741     0.347         0    0.0659     0.349         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.4287    0.2234    0.1142   0.04048   0.03115   0.02124    0.0378\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01606, lrf=0.207, momentum=0.765, weight_decay=0.00018, warmup_epochs=1.63, warmup_momentum=0.84556, warmup_bias_lr=0.14454, box=0.02234, cls=0.31058, cls_pw=0.853, obj=0.99668, obj_pw=0.74507, iou_t=0.2, anchor_t=2.67277, anchors=2.88, fl_gamma=0.0, hsv_h=0.01658, hsv_s=0.741, hsv_v=0.38052, degrees=0.0, translate=0.07324, scale=0.37731, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.53419, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00018\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_015019-tr9gloe1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/tr9gloe1\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1184.63it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.54 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.617-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.55 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.621-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G    0.0353   0.02451   0.02397   0.08378         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G    0.0306   0.02579   0.02288   0.07927         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02429   0.02805   0.02217   0.07451         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02049   0.02889   0.02184   0.07122         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01878   0.02924   0.02165   0.06968         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01801   0.02664   0.02162   0.06626         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01782   0.02583   0.02164    0.0653         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01704   0.02463   0.02136   0.06303         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01609    0.0224   0.02143   0.05993        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01485   0.02184   0.02131     0.058         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.413       0.234       0.149      0.0623\n",
      "            Geranium         108         197       0.413       0.234       0.149      0.0623\n",
      "10 epochs completed in 0.034 hours.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▄▅▇██▆▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.14945\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.41331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/tr9gloe1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_015019-tr9gloe1/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0161     0.207     0.765   0.00018      1.63     0.846     0.145    0.0223     0.311     0.853     0.997     0.745       0.2      2.67      2.88         0    0.0166     0.741     0.381         0    0.0732     0.377         0         0         0       0.5     0.534         0\n",
      "Evolved fitness:     0.4133    0.2335    0.1494   0.06227   0.02749   0.01914   0.03181\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.207, momentum=0.72493, weight_decay=0.00017, warmup_epochs=1.58895, warmup_momentum=0.93834, warmup_bias_lr=0.138, box=0.0244, cls=0.383, cls_pw=1.11869, obj=1.10209, obj_pw=0.70049, iou_t=0.2, anchor_t=2.73, anchors=3.2569, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.73872, hsv_v=0.347, degrees=0.0, translate=0.07017, scale=0.2386, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.2569\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00017\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_015240-zwteq7or\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/zwteq7or\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1116.69it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.613-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.64 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03791   0.02563   0.03454   0.09809         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1/9    0.805G   0.03036   0.02886   0.03161   0.09083         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02314   0.03112   0.03104   0.08531         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02024   0.03048   0.03093   0.08164         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01936   0.02918   0.03004   0.07859         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G    0.0194   0.02826   0.02952   0.07718        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01955   0.02652   0.02865   0.07472         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G    0.0197   0.02502   0.02807   0.07279         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01764   0.02439   0.02796   0.06999        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01597   0.02328   0.02703   0.06629         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.347       0.234       0.187      0.0673\n",
      "            Geranium         108         197       0.347       0.234       0.187      0.0673\n",
      "10 epochs completed in 0.035 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▃▂▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▅▅▄▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▆█▇▆▅▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.18725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.34714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.2335\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01597\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02703\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02328\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02065\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0043\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/zwteq7or\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_015240-zwteq7or/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.207     0.725   0.00017      1.59     0.938     0.138    0.0244     0.383      1.12       1.1       0.7       0.2      2.73      3.26         0    0.0164     0.739     0.347         0    0.0702     0.239         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.3471    0.2335    0.1873   0.06731   0.03135   0.02065    0.0236\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.2085, momentum=0.76594, weight_decay=0.0002, warmup_epochs=1.63, warmup_momentum=0.75706, warmup_bias_lr=0.13788, box=0.02434, cls=0.38037, cls_pw=0.85365, obj=1.09368, obj_pw=0.72329, iou_t=0.2, anchor_t=2.71674, anchors=2.88, fl_gamma=0.0, hsv_h=0.01643, hsv_s=0.741, hsv_v=0.34853, degrees=0.0, translate=0.06634, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.59204, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_015501-3bw65cu5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3bw65cu5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1093.96it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.62 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.524/0.858-mean/best, past_thr=0.614-mean: 74,85,  115,126,  132,201,  214,161,  192,262,  222,350,  309,254,  314,381,  399,395\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8602: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 6.62 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.527/0.860-mean/best, past_thr=0.618-mean: 72,92,  108,119,  130,196,  204,171,  194,259,  284,255,  230,360,  316,374,  405,405\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03908   0.02619   0.02948   0.09475         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03514   0.02757   0.02819    0.0909         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02878   0.03029   0.02722   0.08629         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02407   0.03102   0.02687   0.08196         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02073   0.03205    0.0264   0.07918         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01957   0.03111   0.02642    0.0771         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01962    0.0294   0.02614   0.07516         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01964   0.02786   0.02593   0.07343         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01837   0.02719   0.02567   0.07122        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01648   0.02507   0.02505   0.06661         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.433       0.218       0.186       0.065\n",
      "            Geranium         108         197       0.433       0.218       0.186       0.065\n",
      "10 epochs completed in 0.035 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▄▄▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▂▄▆▇█▇▅▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.18575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.06501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.43348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.21827\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02505\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/3bw65cu5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_015501-3bw65cu5/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.208     0.766    0.0002      1.63     0.757     0.138    0.0243      0.38     0.854      1.09     0.723       0.2      2.72      2.88         0    0.0164     0.741     0.349         0    0.0663     0.349         0         0         0       0.5     0.592         0\n",
      "Evolved fitness:     0.4335    0.2183    0.1857   0.06501   0.03219    0.0196   0.03184\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01629, lrf=0.207, momentum=0.75893, weight_decay=0.0002, warmup_epochs=1.63, warmup_momentum=0.767, warmup_bias_lr=0.09643, box=0.02272, cls=0.38967, cls_pw=1.00919, obj=1.09367, obj_pw=0.8842, iou_t=0.2, anchor_t=2.73, anchors=3.94807, fl_gamma=0.0, hsv_h=0.016, hsv_s=0.81246, hsv_v=0.347, degrees=0.0, translate=0.05829, scale=0.37208, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.65466, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.94807\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7271276 parameters, 7271276 gradients, 17.0 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_015723-2d9p66bq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2d9p66bq\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:00<00:00, 1143.61it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 12 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.82 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.521/0.871-mean/best, past_thr=0.611-mean: 73,86,  114,122,  138,184,  110,251,  218,157,  193,257,  272,258,  204,347,  363,264,  275,370,  346,383,  404,403\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8717: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.82 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=12, img_size=416, metric_all=0.523/0.872-mean/best, past_thr=0.612-mean: 73,89,  110,124,  136,181,  107,261,  215,158,  192,250,  204,340,  267,263,  358,278,  280,369,  350,392,  406,406\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.807G   0.03724   0.03129   0.03447     0.103         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.807G   0.03316   0.03298   0.03321   0.09936         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.807G   0.02735   0.03591   0.03189   0.09514         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.807G   0.02277   0.03568   0.03093   0.08938         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.807G   0.02075   0.03581   0.03044     0.087        15       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.807G   0.02057   0.03409   0.03023   0.08489        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.807G   0.01963   0.03224   0.02958   0.08144         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.807G   0.01937   0.02968   0.02939   0.07843         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.807G   0.01748   0.02795   0.02924   0.07467         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.807G   0.01579   0.02663   0.02967   0.07209        10       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         108         197       0.357       0.244       0.127      0.0558\n",
      "            Geranium         108         197       0.357       0.244       0.127      0.0558\n",
      "10 epochs completed in 0.035 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▅▃▃▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▃▃▂▁▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆███▇▅▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆▇██▇▇▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▇▆▅▄▃▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.12709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.05584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.35663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.24365\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02967\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02707\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.04199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.02503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/2d9p66bq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_015723-2d9p66bq/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0163     0.207     0.759    0.0002      1.63     0.767    0.0964    0.0227      0.39      1.01      1.09     0.884       0.2      2.73      3.95         0     0.016     0.812     0.347         0    0.0583     0.372         0         0         0       0.5     0.655         0\n",
      "Evolved fitness:     0.3566    0.2437    0.1271   0.05584   0.02707   0.02503   0.04199\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01352, lrf=0.22975, momentum=0.69285, weight_decay=0.00025, warmup_epochs=1.2284, warmup_momentum=0.72194, warmup_bias_lr=0.13187, box=0.02367, cls=0.42965, cls_pw=0.78347, obj=1.02788, obj_pw=0.73686, iou_t=0.2, anchor_t=2.73, anchors=2.19419, fl_gamma=0.0, hsv_h=0.02239, hsv_s=0.741, hsv_v=0.29804, degrees=0.0, translate=0.06307, scale=0.23632, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.51839, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.19419\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00025\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_015945-1cf1ej6d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/1cf1ej6d\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Geranium-3/train/labels.cache' for images and labels... 1140 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.6GB): 100%|██████| 1140/1140 [00:01<00:00, 1108.03it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Geranium-3/valid/labels.cache' for images and labels... 108 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 1721 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 4.53 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm::   0%| | 0/1000 [00:00<?, ?\u001b[0m\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.828-mean/best, past_thr=0.622-mean: 92,102,  147,181,  190,266,  304,243,  255,362,  385,393\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8305: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 4.47 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.537/0.830-mean/best, past_thr=0.627-mean: 88,101,  133,175,  189,259,  288,247,  271,354,  393,394\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.774G   0.03837   0.02401   0.03173   0.09411        28       416"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!python train.py \\\n",
    "--img 416 \\\n",
    "--batch 8 \\\n",
    "--epochs 10 \\\n",
    "--data {dataset.location}/data.yaml \\\n",
    "--cfg ./models/custom_yolov5s.yaml \\\n",
    "--weights yolov5s.pt \\\n",
    "--project YOLOv5 \\\n",
    "--name yolov5s_geranium_evolve \\\n",
    "--cache \\\n",
    "--hyp \"./data/hyp.scratch.yaml\" \\\n",
    "--evolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJVs_4zEeVbF"
   },
   "source": [
    "# Evaluate Custom YOLOv5 Detector Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KN5ghjE6ZWh"
   },
   "source": [
    "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
    "\n",
    "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill 17409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOy5KI2ncnWd",
    "outputId": "fb342fb9-efd2-4ce6-e8f1-0b8565cb7750",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start tensorboard\n",
    "# Launch after you have started training\n",
    "# logs save in the folder \"runs\"\n",
    "# %load_ext tensorboard\n",
    "# # %reload_ext tensorboard\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C60XAsyv6OPe",
    "outputId": "47306a82-ad80-4f63-e983-0c25cc2de7f1"
   },
   "outputs": [],
   "source": [
    "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
    "from utils.plots import plot_results  # plot results.txt as results.png\n",
    "Image(filename='./runs/train/yolov5l6_geranium3/results.png', width=1000)  # view results.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLI1JmHU7B0l"
   },
   "source": [
    "### Curious? Visualize Our Training Data with Labels\n",
    "\n",
    "After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n",
    "\n",
    "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W40tI99_7BcH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print out an augmented training example / Mosaic Augmentation 적용된 train 이미지\n",
    "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
    "Image(filename='./runs/train/yolov5l6_geranium3/train_batch0.jpg', width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PF9MLHDb7tB6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display our ground truth data / test 데이터 정답값\n",
    "print(\"GROUND TRUTH TEST DATA:\")\n",
    "Image(filename='./runs/train/yolov5l6_geranium3/test_batch0_labels.jpg', width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display our prediction / test 데이터 예측 결과값\n",
    "print(\"PREDICT TEST DATA:\")\n",
    "Image(filename='./runs/train/yolov5l6_geranium3/test_batch0_pred.jpg', width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3qM6T0W53gh"
   },
   "source": [
    "#Run Inference  With Trained Weights\n",
    "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIEwt5YLeQ7P"
   },
   "outputs": [],
   "source": [
    "# trained weights are saved by default in our weights folder\n",
    "%ls ./runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SyOWS80qR32"
   },
   "outputs": [],
   "source": [
    "%ls ./runs/train/yolov5l6_geranium3/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/lab03/jupyter_home/yolov5/detect.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "!cd \n",
    "!python detect.py --weights /home/lab03/jupyter_home/yolov5/runs/train/yolov5l6_geranium3/weights/best.pt --img 256 --conf 0.4 --source /home/lab03/jupyter_home/yolov5/data/images/geraniumtest1.jpg\n",
    "Image(filename='/home/lab03/jupyter_home/yolov5/runs/detect/exp/geraniumtest1.jpg', width=600)\n",
    "# --conf : 라벨을 표시할 최소 확률 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mB5TXUR9edE_"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "!python detect.py --weights runs/train/yolov5l6_geranium3/weights/best.pt --img 256 --conf 0.4 --source data/images/geraniumtest1.jpg\n",
    "Image(filename='./runs/detect/exp/geraniumtest1.jpg', width=600)\n",
    "# --conf : 라벨을 표시할 최소 확률 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nmZZnWOgJ2S"
   },
   "outputs": [],
   "source": [
    "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
    "# use the best weights!\n",
    "%cd ./\n",
    "!python detect.py --weights runs/train/yolov5l6_geranium3/weights/best.pt --img 256 --conf 0.4 --source Geranium-2/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odKEqYtTgbRc"
   },
   "outputs": [],
   "source": [
    "#display inference on ALL test images\n",
    "#this looks much better with longer training above\n",
    "\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('./runs/detect/exp2/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the mAP on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd ./\n",
    "!python test.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd ./\n",
    "!python test.py --weights runs/train/yolov5l6_geranium3/weights/best.pt --data models/custom_yolov5l6.yaml --img 256 --name yolo_test_geranium --task 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uPq9mVgiBql"
   },
   "source": [
    "# Export Trained Weights for Future Inference\n",
    "\n",
    "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1x_wg3VeiXMW"
   },
   "outputs": [],
   "source": [
    "%cd ./\n",
    "# %mkdir YOLO v5 Weights\n",
    "%cp ./runs/train/yolov5l6_geranium3/weights/best.pt /home/lab03/jupyter_home/YOLOv5Weights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVpCFeU-K4gb"
   },
   "source": [
    "## Congrats!\n",
    "\n",
    "Hope you enjoyed this!\n",
    "\n",
    "--Team [Roboflow](https://roboflow.ai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_latest_p37]",
   "language": "python",
   "name": "conda-env-pytorch_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
