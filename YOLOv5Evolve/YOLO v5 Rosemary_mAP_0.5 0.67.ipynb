{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD9gUQpaBxNa"
   },
   "source": [
    "# YOLOv5 on Custom Objects\n",
    "\n",
    "To train our detector we take the following steps:\n",
    "\n",
    "* Install YOLOv5 dependencies\n",
    "* Download custom YOLOv5 object detection data\n",
    "* Write our YOLOv5 Training configuration\n",
    "* Run YOLOv5 training\n",
    "* Evaluate YOLOv5 performance\n",
    "* Visualize YOLOv5 training data\n",
    "* Run YOLOv5 inference on test images\n",
    "* Export saved YOLOv5 weights for future inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "# wandb.login()\n",
    "# wandb.init(project=\"YOLOv5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mangelajlee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/lab03/EvolveYOLO/wandb/run-20220622_095239-26zzy3h4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/angelajlee/YOLOv5_Rosemary/runs/26zzy3h4\" target=\"_blank\">restful-galaxy-16</a></strong> to <a href=\"https://wandb.ai/angelajlee/YOLOv5_Rosemary\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/angelajlee/YOLOv5_Rosemary/runs/26zzy3h4?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb72a389890>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"YOLOv5_Rosemary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ie5uLDH4uzAp",
    "outputId": "34e3857c-7780-4c62-b257-9a8058cfc1be",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "/home/lab03/EvolveYOLO/yolov5\n",
      "HEAD is now at 886f1c0 DDP after autoanchor reorder (#2421)\n"
     ]
    }
   ],
   "source": [
    "# clone YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "!git reset --hard 886f1c03d839575afecb059accf74296fad395b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab03/EvolveYOLO/yolov5\r\n"
     ]
    }
   ],
   "source": [
    "!cd ./\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wbvMlHd_QwMG",
    "outputId": "91c4fd5a-2f23-4393-e9ef-0ac530f6ce07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Setup complete. Using torch 1.8.1+cu111 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "# install dependencies as necessary\n",
    "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "from utils.google_utils import gdrive_download  # to download models/datasets\n",
    "\n",
    "# clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Knxi2ncxWffW",
    "outputId": "887cdb86-b534-4209-9372-6ec31885f59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=roboflow-yolov5\n"
     ]
    }
   ],
   "source": [
    "#follow the link below to get your download code from from Roboflow\n",
    "!pip install -q roboflow\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ug_PhK1oqwQA",
    "outputId": "7af362bb-621b-4696-9eb0-cea376f06967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab03/EvolveYOLO/yolov5\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in Rosemary-5 to yolov5pytorch: 100% [18640468 / 18640468] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Rosemary-5 in yolov5pytorch:: 100%|██████████| 2540/2540 [00:00<00:00, 4874.97it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd ./\n",
    "#after following the link above, recieve python code with these fields filled in\n",
    "\n",
    "# Version 1 metrics/mAP_0.5 0.04278\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"QWencAPU4nMRzIBHlDhp\")\n",
    "# project = rf.workspace(\"smart-pot\").project(\"test-sample-npc1h\")\n",
    "# dataset = project.version(2).download(\"yolov5\")\n",
    "\n",
    "# Version 2 metrics/mAP_0.5 0.34993\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"IBBTtAIXCLhJqbn75Abw\")\n",
    "project = rf.workspace(\"mulcam\").project(\"rosemary-umdoq\")\n",
    "dataset = project.version(5).download(\"yolov5\")\n",
    "\n",
    "# Version 3 metrics/mAP_0.5 0.23555\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"QWencAPU4nMRzIBHlDhp\")\n",
    "# project = rf.workspace(\"smart-pot\").project(\"rosemary-yqkfo\")\n",
    "# dataset = project.version(5).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zk3vl9cebmBk"
   },
   "outputs": [],
   "source": [
    "# curl -L \"https://app.roboflow.com/ds/EbfTvnORki?key=IHIDfi7nN4\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ZZ3DmmGQztJj",
    "outputId": "6ff5fd2f-92a7-452b-9825-cbf1f5dfa1c9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names: ['Rosemary', 'Rosemary Leaf Spot', 'Rosemary Pest Damage', 'Rosemary Powdery Mildew']\r\n",
      "nc: 4\r\n",
      "train: Rosemary-5/train/images\r\n",
      "val: Rosemary-5/valid/images\r\n",
      "test: Rosemary-5/test/images"
     ]
    }
   ],
   "source": [
    "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
    "%cat {dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count images on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2533\n",
      "1996\n",
      "358\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "!find {dataset.location} -name *.jpg | wc -l\n",
    "!find {dataset.location}/train -name *.jpg | wc -l\n",
    "!find {dataset.location}/valid -name *.jpg | wc -l\n",
    "!find {dataset.location}/test -name *.jpg | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwJx-2NHsYxT"
   },
   "source": [
    "# Define Model Configuration and Architecture\n",
    "\n",
    "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n",
    "\n",
    "You do not need to edit these cells, but you may."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dOPn9wjOAwwK"
   },
   "outputs": [],
   "source": [
    "# define number of classes based on YAML\n",
    "import yaml\n",
    "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1Rvt5wilnDyX",
    "outputId": "a061f445-aaa0-48d5-e6d3-93af55fb355b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parameters\r\n",
      "nc: 80  # number of classes\r\n",
      "depth_multiple: 0.33  # model depth multiple\r\n",
      "width_multiple: 0.50  # layer channel multiple\r\n",
      "\r\n",
      "# anchors\r\n",
      "anchors:\r\n",
      "  - [10,13, 16,30, 33,23]  # P3/8\r\n",
      "  - [30,61, 62,45, 59,119]  # P4/16\r\n",
      "  - [116,90, 156,198, 373,326]  # P5/32\r\n",
      "\r\n",
      "# YOLOv5 backbone\r\n",
      "backbone:\r\n",
      "  # [from, number, module, args]\r\n",
      "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\r\n",
      "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\r\n",
      "   [-1, 3, C3, [128]],\r\n",
      "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\r\n",
      "   [-1, 9, C3, [256]],\r\n",
      "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\r\n",
      "   [-1, 9, C3, [512]],\r\n",
      "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\r\n",
      "   [-1, 1, SPP, [1024, [5, 9, 13]]],\r\n",
      "   [-1, 3, C3, [1024, False]],  # 9\r\n",
      "  ]\r\n",
      "\r\n",
      "# YOLOv5 head\r\n",
      "head:\r\n",
      "  [[-1, 1, Conv, [512, 1, 1]],\r\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\r\n",
      "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\r\n",
      "   [-1, 3, C3, [512, False]],  # 13\r\n",
      "\r\n",
      "   [-1, 1, Conv, [256, 1, 1]],\r\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\r\n",
      "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\r\n",
      "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\r\n",
      "\r\n",
      "   [-1, 1, Conv, [256, 3, 2]],\r\n",
      "   [[-1, 14], 1, Concat, [1]],  # cat head P4\r\n",
      "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\r\n",
      "\r\n",
      "   [-1, 1, Conv, [512, 3, 2]],\r\n",
      "   [[-1, 10], 1, Concat, [1]],  # cat head P5\r\n",
      "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\r\n",
      "\r\n",
      "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\r\n",
      "  ]\r\n"
     ]
    }
   ],
   "source": [
    "#this is the model configuration we will use for our tutorial \n",
    "%cat ./models/yolov5s.yaml\n",
    "# %cat ./models/yolov5m.yaml\n",
    "# %cat ./models/yolov5x.yaml\n",
    "# %cat ./models/hub/yolov5l6.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "t14hhyqdmw6O"
   },
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate ./models/custom_yolov5s.yaml\n",
    "\n",
    "# parameters\n",
    "nc: {num_classes}  # number of classes\n",
    "depth_multiple: 0.33  # model depth multiple\n",
    "width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, BottleneckCSP, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, BottleneckCSP, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, BottleneckCSP, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uDxebz13RdRA"
   },
   "outputs": [],
   "source": [
    "# %%writetemplate ./models/custom_yolov5l6.yaml\n",
    "\n",
    "# # parameters\n",
    "# nc: {num_classes}  # number of classes\n",
    "# depth_multiple: 1.0  # model depth multiple\n",
    "# width_multiple: 1.0  # layer channel multiple\n",
    "\n",
    "# # anchors\n",
    "# anchors:\n",
    "#   - [ 19,27,  44,40,  38,94 ]  # P3/8\n",
    "#   - [ 96,68,  86,152,  180,137 ]  # P4/16\n",
    "#   - [ 140,301,  303,264,  238,542 ]  # P5/32\n",
    "#   - [ 436,615,  739,380,  925,792 ]  # P6/64\n",
    "\n",
    "# # YOLOv5 backbone\n",
    "# backbone:\n",
    "#   # [from, number, module, args]\n",
    "#   [ [ -1, 1, Focus, [ 64, 3 ] ],  # 0-P1/2\n",
    "#     [ -1, 1, Conv, [ 128, 3, 2 ] ],  # 1-P2/4\n",
    "#     [ -1, 3, C3, [ 128 ] ],\n",
    "#     [ -1, 1, Conv, [ 256, 3, 2 ] ],  # 3-P3/8\n",
    "#     [ -1, 9, C3, [ 256 ] ],\n",
    "#     [ -1, 1, Conv, [ 512, 3, 2 ] ],  # 5-P4/16\n",
    "#     [ -1, 9, C3, [ 512 ] ],\n",
    "#     [ -1, 1, Conv, [ 768, 3, 2 ] ],  # 7-P5/32\n",
    "#     [ -1, 3, C3, [ 768 ] ],\n",
    "#     [ -1, 1, Conv, [ 1024, 3, 2 ] ],  # 9-P6/64\n",
    "#     [ -1, 1, SPP, [ 1024, [ 3, 5, 7 ] ] ],\n",
    "#     [ -1, 3, C3, [ 1024, False ] ],  # 11\n",
    "#   ]\n",
    "\n",
    "# # YOLOv5 head\n",
    "# head:\n",
    "#   [ [ -1, 1, Conv, [ 768, 1, 1 ] ],\n",
    "#     [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],\n",
    "#     [ [ -1, 8 ], 1, Concat, [ 1 ] ],  # cat backbone P5\n",
    "#     [ -1, 3, C3, [ 768, False ] ],  # 15\n",
    "\n",
    "#     [ -1, 1, Conv, [ 512, 1, 1 ] ],\n",
    "#     [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],\n",
    "#     [ [ -1, 6 ], 1, Concat, [ 1 ] ],  # cat backbone P4\n",
    "#     [ -1, 3, C3, [ 512, False ] ],  # 19\n",
    "\n",
    "#     [ -1, 1, Conv, [ 256, 1, 1 ] ],\n",
    "#     [ -1, 1, nn.Upsample, [ None, 2, 'nearest' ] ],\n",
    "#     [ [ -1, 4 ], 1, Concat, [ 1 ] ],  # cat backbone P3\n",
    "#     [ -1, 3, C3, [ 256, False ] ],  # 23 (P3/8-small)\n",
    "\n",
    "#     [ -1, 1, Conv, [ 256, 3, 2 ] ],\n",
    "#     [ [ -1, 20 ], 1, Concat, [ 1 ] ],  # cat head P4\n",
    "#     [ -1, 3, C3, [ 512, False ] ],  # 26 (P4/16-medium)\n",
    "\n",
    "#     [ -1, 1, Conv, [ 512, 3, 2 ] ],\n",
    "#     [ [ -1, 16 ], 1, Concat, [ 1 ] ],  # cat head P5\n",
    "#     [ -1, 3, C3, [ 768, False ] ],  # 29 (P5/32-large)\n",
    "\n",
    "#     [ -1, 1, Conv, [ 768, 3, 2 ] ],\n",
    "#     [ [ -1, 12 ], 1, Concat, [ 1 ] ],  # cat head P6\n",
    "#     [ -1, 3, C3, [ 1024, False ] ],  # 32 (P6/64-xlarge)\n",
    "\n",
    "#     [ [ 23, 26, 29, 32 ], 1, Detect, [ nc, anchors ] ],  # Detect(P3, P4, P5, P6)\n",
    "#   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUOiNLtMP5aG"
   },
   "source": [
    "# Train Custom YOLOv5 Detector\n",
    "\n",
    "### Next, we'll fire off training!\n",
    "\n",
    "\n",
    "Here, we are able to pass a number of arguments:\n",
    "- **img:** define input image size\n",
    "- **batch:** determine batch size\n",
    "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
    "- **data:** set the path to our yaml file\n",
    "- **cfg:** specify our model configuration\n",
    "- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n",
    "- **name:** result names\n",
    "- **nosave:** only save the final checkpoint\n",
    "- **cache:** cache images for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "YhGDpUkHFpx5",
    "outputId": "656c06bc-9476-4fce-e8a7-86b48b820993",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Google utils: https://cloud.google.com/storage/docs/reference/libraries\r\n",
      "\r\n",
      "import os\r\n",
      "import platform\r\n",
      "import subprocess\r\n",
      "import time\r\n",
      "from pathlib import Path\r\n",
      "\r\n",
      "import requests\r\n",
      "import torch\r\n",
      "\r\n",
      "\r\n",
      "def gsutil_getsize(url=''):\r\n",
      "    # gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du\r\n",
      "    s = subprocess.check_output(f'gsutil du {url}', shell=True).decode('utf-8')\r\n",
      "    return eval(s.split(' ')[0]) if len(s) else 0  # bytes\r\n",
      "\r\n",
      "\r\n",
      "def attempt_download(file, repo='ultralytics/yolov5'):\r\n",
      "    # Attempt file download if does not exist\r\n",
      "    file = Path(str(file).strip().replace(\"'\", '').lower())\r\n",
      "\r\n",
      "    if not file.exists():\r\n",
      "        try:\r\n",
      "            response = requests.get(f'https://api.github.com/repos/{repo}/releases/tags/v5.0').json() # github api\r\n",
      "            assets = [x['name'] for x in response['assets']]  # release assets, i.e. ['yolov5s.pt', 'yolov5m.pt', ...]\r\n",
      "            tag = response['tag_name']  # i.e. 'v1.0'\r\n",
      "        except:  # fallback plan\r\n",
      "            assets = ['yolov5s.pt', 'yolov5m.pt', 'yolov5l.pt', 'yolov5x.pt']\r\n",
      "            tag = subprocess.check_output('git tag', shell=True).decode().split()[-1]\r\n",
      "\r\n",
      "        name = file.name\r\n",
      "        if name in assets:\r\n",
      "            msg = f'{file} missing, try downloading from https://github.com/{repo}/releases/'\r\n",
      "            redundant = False  # second download option\r\n",
      "            try:  # GitHub\r\n",
      "                url = f'https://github.com/{repo}/releases/download/{tag}/{name}'\r\n",
      "                print(f'Downloading {url} to {file}...')\r\n",
      "                torch.hub.download_url_to_file(url, file)\r\n",
      "                assert file.exists() and file.stat().st_size > 1E6  # check\r\n",
      "            except Exception as e:  # GCP\r\n",
      "                print(f'Download error: {e}')\r\n",
      "                assert redundant, 'No secondary mirror'\r\n",
      "                url = f'https://storage.googleapis.com/{repo}/ckpt/{name}'\r\n",
      "                print(f'Downloading {url} to {file}...')\r\n",
      "                os.system(f'curl -L {url} -o {file}')  # torch.hub.download_url_to_file(url, weights)\r\n",
      "            finally:\r\n",
      "                if not file.exists() or file.stat().st_size < 1E6:  # check\r\n",
      "                    file.unlink(missing_ok=True)  # remove partial downloads\r\n",
      "                    print(f'ERROR: Download failure: {msg}')\r\n",
      "                print('')\r\n",
      "                return\r\n",
      "\r\n",
      "\r\n",
      "def gdrive_download(id='16TiPfZj7htmTyhntwcZyEEAejOUxuT6m', file='tmp.zip'):\r\n",
      "    # Downloads a file from Google Drive. from yolov5.utils.google_utils import *; gdrive_download()\r\n",
      "    t = time.time()\r\n",
      "    file = Path(file)\r\n",
      "    cookie = Path('cookie')  # gdrive cookie\r\n",
      "    print(f'Downloading https://drive.google.com/uc?export=download&id={id} as {file}... ', end='')\r\n",
      "    file.unlink(missing_ok=True)  # remove existing file\r\n",
      "    cookie.unlink(missing_ok=True)  # remove existing cookie\r\n",
      "\r\n",
      "    # Attempt file download\r\n",
      "    out = \"NUL\" if platform.system() == \"Windows\" else \"/dev/null\"\r\n",
      "    os.system(f'curl -c ./cookie -s -L \"drive.google.com/uc?export=download&id={id}\" > {out}')\r\n",
      "    if os.path.exists('cookie'):  # large file\r\n",
      "        s = f'curl -Lb ./cookie \"drive.google.com/uc?export=download&confirm={get_token()}&id={id}\" -o {file}'\r\n",
      "    else:  # small file\r\n",
      "        s = f'curl -s -L -o {file} \"drive.google.com/uc?export=download&id={id}\"'\r\n",
      "    r = os.system(s)  # execute, capture return\r\n",
      "    cookie.unlink(missing_ok=True)  # remove existing cookie\r\n",
      "\r\n",
      "    # Error check\r\n",
      "    if r != 0:\r\n",
      "        file.unlink(missing_ok=True)  # remove partial\r\n",
      "        print('Download error ')  # raise Exception('Download error')\r\n",
      "        return r\r\n",
      "\r\n",
      "    # Unzip if archive\r\n",
      "    if file.suffix == '.zip':\r\n",
      "        print('unzipping... ', end='')\r\n",
      "        os.system(f'unzip -q {file}')  # unzip\r\n",
      "        file.unlink()  # remove zip to free space\r\n",
      "\r\n",
      "    print(f'Done ({time.time() - t:.1f}s)')\r\n",
      "    return r\r\n",
      "\r\n",
      "\r\n",
      "def get_token(cookie=\"./cookie\"):\r\n",
      "    with open(cookie) as f:\r\n",
      "        for line in f:\r\n",
      "            if \"download\" in line:\r\n",
      "                return line.split()[-1]\r\n",
      "    return \"\"\r\n",
      "\r\n",
      "# def upload_blob(bucket_name, source_file_name, destination_blob_name):\r\n",
      "#     # Uploads a file to a bucket\r\n",
      "#     # https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python\r\n",
      "#\r\n",
      "#     storage_client = storage.Client()\r\n",
      "#     bucket = storage_client.get_bucket(bucket_name)\r\n",
      "#     blob = bucket.blob(destination_blob_name)\r\n",
      "#\r\n",
      "#     blob.upload_from_filename(source_file_name)\r\n",
      "#\r\n",
      "#     print('File {} uploaded to {}.'.format(\r\n",
      "#         source_file_name,\r\n",
      "#         destination_blob_name))\r\n",
      "#\r\n",
      "#\r\n",
      "# def download_blob(bucket_name, source_blob_name, destination_file_name):\r\n",
      "#     # Uploads a blob from a bucket\r\n",
      "#     storage_client = storage.Client()\r\n",
      "#     bucket = storage_client.get_bucket(bucket_name)\r\n",
      "#     blob = bucket.blob(source_blob_name)\r\n",
      "#\r\n",
      "#     blob.download_to_filename(destination_file_name)\r\n",
      "#\r\n",
      "#     print('Blob {} downloaded to {}.'.format(\r\n",
      "#         source_blob_name,\r\n",
      "#         destination_file_name))\r\n"
     ]
    }
   ],
   "source": [
    "%cat ./utils/google_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zvsnVTpBAObq",
    "outputId": "92caf0d2-116e-4f36-df62-a39357acc237",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Hyperparameters for COCO training from scratch\r\n",
      "# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\r\n",
      "# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\r\n",
      "\r\n",
      "\r\n",
      "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\r\n",
      "lrf: 0.2  # final OneCycleLR learning rate (lr0 * lrf)\r\n",
      "momentum: 0.937  # SGD momentum/Adam beta1\r\n",
      "weight_decay: 0.0005  # optimizer weight decay 5e-4\r\n",
      "warmup_epochs: 3.0  # warmup epochs (fractions ok)\r\n",
      "warmup_momentum: 0.8  # warmup initial momentum\r\n",
      "warmup_bias_lr: 0.1  # warmup initial bias lr\r\n",
      "box: 0.05  # box loss gain\r\n",
      "cls: 0.5  # cls loss gain\r\n",
      "cls_pw: 1.0  # cls BCELoss positive_weight\r\n",
      "obj: 1.0  # obj loss gain (scale with pixels)\r\n",
      "obj_pw: 1.0  # obj BCELoss positive_weight\r\n",
      "iou_t: 0.20  # IoU training threshold\r\n",
      "anchor_t: 4.0  # anchor-multiple threshold\r\n",
      "# anchors: 3  # anchors per output layer (0 to ignore)\r\n",
      "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\r\n",
      "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\r\n",
      "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\r\n",
      "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\r\n",
      "degrees: 0.0  # image rotation (+/- deg)\r\n",
      "translate: 0.1  # image translation (+/- fraction)\r\n",
      "scale: 0.5  # image scale (+/- gain)\r\n",
      "shear: 0.0  # image shear (+/- deg)\r\n",
      "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\r\n",
      "flipud: 0.0  # image flip up-down (probability)\r\n",
      "fliplr: 0.5  # image flip left-right (probability)\r\n",
      "mosaic: 1.0  # image mosaic (probability)\r\n",
      "mixup: 0.0  # image mixup (probability)\r\n"
     ]
    }
   ],
   "source": [
    "%cat ./data/hyp.scratch.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %cd ./\n",
    "# !python train.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"YOLOv5\",\n",
    "#            config={\n",
    "#                \"batch_size\": 32,\n",
    "#                \"learning_rate\": 0.01,\n",
    "#                \"dataset\": \"Rosemary-5\",\n",
    "#            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1 metrics/mAP_0.5 0.04278\n",
    "## Version 2 metrics/mAP_0.5 0.34993\n",
    "## Version 3 metrics/mAP_0.5 0.23555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1NcFxRcFdJ_O",
    "outputId": "c6d79ddc-8011-4532-9b9b-12e3d23d511b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab03/EvolveYOLO/yolov5\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 1118 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
      "YOLOv5 v4.0-126-g886f1c0 torch 1.8.1+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Namespace(adam=False, batch_size=8, bucket='', cache_images=True, cfg='./models/custom_yolov5s.yaml', data='/home/lab03/EvolveYOLO/yolov5/Rosemary-5/data.yaml', device='', entity=None, epochs=10, evolve=False, exist_ok=False, global_rank=-1, hyp='./data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], linear_lr=False, local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='yolov5s_rosemary', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov5s_rosemary', single_cls=False, sync_bn=False, total_batch_size=8, weights='yolov5s.pt', workers=8, world_size=1)\n",
      "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, anchors=3, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mangelajlee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_223618-4zf5m6d7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov5s_rosemary\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/4zf5m6d7\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 795.09it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB): 100%|███████████| 358/358 [00:00<00:00, 737.05it/s]\u001b[0m\n",
      "Plotting labels... \n",
      "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.89 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.593-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 1.0000 best possible recall, 8.88 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.593-mean: 103,139,  169,162,  148,239,  263,212,  172,340,  231,302,  338,273,  298,357,  380,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/yolov5s_rosemary\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.761G   0.08064   0.04329    0.0427    0.1666         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440      0.0329      0.0823       0.022     0.00435\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.05428   0.05406   0.04012    0.1485         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.302       0.318      0.0587      0.0168\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.04134   0.05412    0.0386    0.1341         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.281      0.0425       0.013     0.00539\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.04083   0.04664   0.03844    0.1259        12       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.148       0.518       0.162      0.0874\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G    0.0365   0.03865   0.03859    0.1137        10       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.206       0.467       0.195       0.109\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.03164   0.03316   0.03802    0.1028         6       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440        0.23       0.494       0.218       0.151\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.02733   0.02931   0.03781   0.09446         7       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.247       0.475       0.223       0.164\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.02328   0.02685   0.03839   0.08852         7       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.254       0.464       0.235       0.183\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.02013   0.02541    0.0385   0.08404         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.239       0.498       0.233       0.185\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01826    0.0237   0.03823   0.08018         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.261       0.496       0.236        0.19\n",
      "            Rosemary         358         180       0.369       0.522       0.344       0.262\n",
      "  Rosemary Leaf Spot         358          44       0.123       0.295      0.0625      0.0506\n",
      "Rosemary Pest Damage         358         131       0.373       0.695       0.388       0.322\n",
      "Rosemary Powdery Mildew         358          85       0.177       0.471        0.15       0.125\n",
      "Optimizer stripped from runs/train/yolov5s_rosemary/weights/last.pt, 14.8MB\n",
      "Optimizer stripped from runs/train/yolov5s_rosemary/weights/best.pt, 14.8MB\n",
      "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
      "10 epochs completed in 0.119 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▂▁▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▄▅▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁█▇▄▆▆▇▇▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▂▅▁█▇█▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▄▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▄▂▂▂▁▁▂▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▆██▆▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▆▄█▃▃▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss █▅▃▂▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▅█▄▅▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.23591\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.18998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.2605\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.49573\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01826\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.03823\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.03378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.03816\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov5s_rosemary\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/YOLOv5/runs/4zf5m6d7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 49 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_223618-4zf5m6d7/logs\u001b[0m\n",
      "CPU times: user 8.54 s, sys: 1.31 s, total: 9.85 s\n",
      "Wall time: 7min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%%wandb\n",
    "\n",
    "%cd ./\n",
    "!python train.py \\\n",
    "--img 416 \\\n",
    "--batch 8 \\\n",
    "--epochs 10 \\\n",
    "--data {dataset.location}/data.yaml \\\n",
    "--cfg ./models/custom_yolov5s.yaml \\\n",
    "--weights yolov5s.pt \\\n",
    "--name yolov5s_rosemary \\\n",
    "--cache \\\n",
    "--hyp \"./data/hyp.scratch.yaml\" \\\n",
    "# --resume \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Evolution (Optional. 300 scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 1118 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
      "YOLOv5 v4.0-126-g886f1c0 torch 1.8.1+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Namespace(adam=False, batch_size=8, bucket='', cache_images=True, cfg='./models/custom_yolov5s.yaml', data='/home/lab03/EvolveYOLO/yolov5/Rosemary-5/data.yaml', device='', entity=None, epochs=10, evolve=True, exist_ok=False, global_rank=-1, hyp='./data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], linear_lr=False, local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='evolve', noautoanchor=False, nosave=False, notest=False, project='runs', quad=False, rect=False, resume=False, save_dir='runs/evolve', single_cls=False, sync_bn=False, total_batch_size=8, weights='yolov5s.pt', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.2565, momentum=0.765, weight_decay=0.00021, warmup_epochs=1.63, warmup_momentum=0.61014, warmup_bias_lr=0.15705, box=0.02422, cls=0.31328, cls_pw=0.75759, obj=0.69492, obj_pw=0.72215, iou_t=0.2, anchor_t=2.28309, anchors=2.88, fl_gamma=0.0, hsv_h=0.01775, hsv_s=0.86611, hsv_v=0.31777, degrees=0.0, translate=0.07901, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mangelajlee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_233114-xk1hy248\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/xk1hy248\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 805.54it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.44: 0.9987 best possible recall, 6.96 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.656-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8710: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.44: 0.9987 best possible recall, 6.90 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.658-mean: 103,139,  169,162,  148,239,  263,212,  172,340,  231,302,  338,273,  298,357,  380,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.765G   0.03576   0.01493   0.02239   0.07307         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03182   0.01523   0.02141   0.06845         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02337   0.01671   0.02059   0.06067         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01851   0.01787   0.02048   0.05686        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01608    0.0179    0.0204   0.05438         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01495   0.01736   0.02028   0.05258         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01384   0.01644   0.02026   0.05055         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01322   0.01522   0.02013   0.04857         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G    0.0125   0.01434   0.01989   0.04673         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01205   0.01331   0.01963   0.04499         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.216        0.38       0.186        0.13\n",
      "            Rosemary         358         180       0.355       0.711       0.413       0.272\n",
      "  Rosemary Leaf Spot         358          44       0.102       0.182      0.0507      0.0358\n",
      "Rosemary Pest Damage         358         131       0.282       0.427       0.199       0.156\n",
      "Rosemary Powdery Mildew         358          85       0.124         0.2      0.0796      0.0552\n",
      "10 epochs completed in 0.101 hours.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▃▃▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▃▄▆██▇▆▄▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.18556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.12977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.21558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.3801\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01205\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01963\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01331\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01965\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/xk1hy248\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_233114-xk1hy248/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.257     0.765   0.00021      1.63      0.61     0.157    0.0242     0.313     0.758     0.695     0.722       0.2      2.28      2.88         0    0.0177     0.866     0.318         0     0.079     0.349         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.2156    0.3801    0.1856    0.1298   0.01688  0.009276   0.01965\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01675, lrf=0.207, momentum=0.77635, weight_decay=0.0002, warmup_epochs=1.69801, warmup_momentum=0.69175, warmup_bias_lr=0.10204, box=0.0244, cls=0.36891, cls_pw=1.02317, obj=1.12555, obj_pw=0.6507, iou_t=0.2, anchor_t=2.72586, anchors=2.51568, fl_gamma=0.0, hsv_h=0.01298, hsv_s=0.741, hsv_v=0.36467, degrees=0.0, translate=0.07966, scale=0.37384, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.60898, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.51568\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_233737-3kofk8ni\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/3kofk8ni\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 840.07it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 0.9996 best possible recall, 8.06 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.622-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.02 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.623-mean: 103,140,  168,161,  147,239,  263,212,  172,342,  232,302,  338,273,  298,356,  381,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G    0.0376   0.02516   0.03255   0.09531         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1/9    0.805G   0.02928   0.02729   0.03031   0.08689         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02075   0.03042   0.02918   0.08036        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01996   0.02819   0.02893   0.07708        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01897    0.0259   0.02882   0.07369         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01802   0.02331   0.02855   0.06988         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01649   0.02064   0.02843   0.06556         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01479   0.01937   0.02814    0.0623         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G    0.0131   0.01839   0.02774   0.05923         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G    0.0119    0.0175   0.02672   0.05612         9       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.261       0.505       0.306         0.2\n",
      "            Rosemary         358         180       0.377       0.717       0.597       0.363\n",
      "  Rosemary Leaf Spot         358          44      0.0996       0.273      0.0688      0.0428\n",
      "Rosemary Pest Damage         358         131       0.373       0.595       0.418       0.298\n",
      "Rosemary Powdery Mildew         358          85       0.196       0.434       0.138      0.0966\n",
      "10 epochs completed in 0.098 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▃▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▄▄▃▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆█▇▆▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.30561\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.26143\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.50479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0119\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0175\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/3kofk8ni\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_233737-3kofk8ni/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0168     0.207     0.776    0.0002       1.7     0.692     0.102    0.0244     0.369      1.02      1.13     0.651       0.2      2.73      2.52         0     0.013     0.741     0.365         0    0.0797     0.374         0         0         0       0.5     0.609         0\n",
      "Evolved fitness:     0.2614    0.5048    0.3056    0.2003   0.01781   0.01327   0.02551\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01419, lrf=0.21801, momentum=0.76685, weight_decay=0.00021, warmup_epochs=1.69328, warmup_momentum=0.78197, warmup_bias_lr=0.14261, box=0.02394, cls=0.383, cls_pw=0.82567, obj=1.13231, obj_pw=0.734, iou_t=0.2, anchor_t=2.72228, anchors=2.527, fl_gamma=0.0, hsv_h=0.01562, hsv_s=0.67815, hsv_v=0.39046, degrees=0.0, translate=0.05959, scale=0.34826, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.62837, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.527\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_234350-lvkgfxi2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/lvkgfxi2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 823.60it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 0.9996 best possible recall, 8.06 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.622-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.01 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.623-mean: 103,140,  168,161,  147,239,  263,212,  172,342,  232,302,  338,273,  298,356,  381,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G    0.0364   0.02766   0.02864    0.0927         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G    0.0284   0.03033   0.02695   0.08568         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G    0.0203   0.03374   0.02628   0.08033         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01973   0.03079   0.02594   0.07646         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01894   0.02727    0.0261   0.07231         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01787   0.02436   0.02598   0.06822         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01632   0.02192   0.02602   0.06426         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01435   0.02117   0.02575   0.06127         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01317    0.0194   0.02528   0.05785         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01162   0.01866   0.02454   0.05482         7       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.271       0.527       0.309       0.222\n",
      "            Rosemary         358         180         0.4       0.733       0.647       0.435\n",
      "  Rosemary Leaf Spot         358          44       0.152       0.341      0.0676      0.0489\n",
      "Rosemary Pest Damage         358         131       0.348       0.611       0.391       0.307\n",
      "Rosemary Powdery Mildew         358          85       0.187       0.424       0.133      0.0966\n",
      "10 epochs completed in 0.097 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▃▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▃▄▃▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆█▇▅▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.30949\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.2219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.27148\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.52711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01162\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02454\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01637\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01465\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/lvkgfxi2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_234350-lvkgfxi2/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0142     0.218     0.767   0.00021      1.69     0.782     0.143    0.0239     0.383     0.826      1.13     0.734       0.2      2.72      2.53         0    0.0156     0.678      0.39         0    0.0596     0.348         0         0         0       0.5     0.628         0\n",
      "Evolved fitness:     0.2715    0.5271    0.3095    0.2219   0.01637   0.01465   0.02281\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01606, lrf=0.2114, momentum=0.78597, weight_decay=0.0002, warmup_epochs=1.40295, warmup_momentum=0.767, warmup_bias_lr=0.138, box=0.0244, cls=0.37689, cls_pw=0.81799, obj=1.15856, obj_pw=0.80309, iou_t=0.2, anchor_t=2.73, anchors=3.29045, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.67355, hsv_v=0.347, degrees=0.0, translate=0.06853, scale=0.36273, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.56831, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.29045\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_235001-2wubhp8p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/2wubhp8p\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 801.36it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 0.9996 best possible recall, 8.07 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.621-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.02 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.623-mean: 103,140,  168,161,  147,239,  263,212,  172,342,  232,302,  338,273,  298,356,  381,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03732   0.02972   0.02804   0.09509         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02908   0.03195   0.02648   0.08752         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02162   0.03435   0.02574   0.08171         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02127   0.03034   0.02534   0.07695         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G    0.0196   0.02793   0.02559   0.07312         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01888   0.02409   0.02515   0.06812         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01652   0.02241   0.02465   0.06358         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01452   0.02085   0.02345   0.05881         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01349   0.01989   0.02306   0.05643         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01215   0.01867   0.02229   0.05312         6       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.308       0.447       0.333       0.227\n",
      "            Rosemary         358         180       0.426       0.678       0.598       0.357\n",
      "  Rosemary Leaf Spot         358          44       0.127       0.114      0.0816      0.0606\n",
      "Rosemary Pest Damage         358         131       0.442       0.586        0.52       0.398\n",
      "Rosemary Powdery Mildew         358          85       0.237       0.412       0.131      0.0927\n",
      "10 epochs completed in 0.100 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▅▄▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▆▇█▆▅▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.33256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.22709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.30792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.4472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02229\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01752\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0046\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/2wubhp8p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_235001-2wubhp8p/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0161     0.211     0.786    0.0002       1.4     0.767     0.138    0.0244     0.377     0.818      1.16     0.803       0.2      2.73      3.29         0    0.0164     0.674     0.347         0    0.0685     0.363         0         0         0       0.5     0.568         0\n",
      "Evolved fitness:     0.3079    0.4472    0.3326    0.2271   0.01752   0.01604   0.02061\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01505, lrf=0.207, momentum=0.77547, weight_decay=0.00019, warmup_epochs=1.68891, warmup_momentum=0.77341, warmup_bias_lr=0.138, box=0.0261, cls=0.37604, cls_pw=0.8206, obj=1.14687, obj_pw=0.75613, iou_t=0.2, anchor_t=2.73144, anchors=3.10462, fl_gamma=0.0, hsv_h=0.01693, hsv_s=0.741, hsv_v=0.347, degrees=0.0, translate=0.0659, scale=0.35012, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.60202, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.10462\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220621_235621-211s83ur\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/211s83ur\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|██████| 1996/1996 [00:01<00:00, 1421.44it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 0.9996 best possible recall, 8.07 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.621-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.02 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.623-mean: 103,140,  168,161,  147,239,  263,212,  172,342,  232,302,  338,273,  298,356,  381,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03978   0.02847   0.02807   0.09632         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03073   0.03109   0.02635   0.08817         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02225   0.03375   0.02561   0.08161        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02121   0.03098   0.02558   0.07778        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02075   0.02789   0.02571   0.07434         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G      0.02   0.02489   0.02535   0.07023         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01748   0.02279   0.02547   0.06574         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01571   0.02104   0.02544   0.06219         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01358   0.01986   0.02546    0.0589         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01267    0.0191   0.02522   0.05699         2       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.231       0.531       0.232       0.168\n",
      "            Rosemary         358         180       0.372       0.667       0.465       0.324\n",
      "  Rosemary Leaf Spot         358          44      0.0833       0.341      0.0753      0.0569\n",
      "Rosemary Pest Damage         358         131       0.307       0.656       0.286       0.213\n",
      "Rosemary Powdery Mildew         358          85       0.164       0.459       0.103      0.0761\n",
      "10 epochs completed in 0.099 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▃▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▄▂▂▂▁▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▇█▇▅▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.23218\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.16751\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.23132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.53072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01267\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.0191\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/211s83ur\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220621_235621-211s83ur/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "     0.015     0.207     0.775   0.00019      1.69     0.773     0.138    0.0261     0.376     0.821      1.15     0.756       0.2      2.73       3.1         0    0.0169     0.741     0.347         0    0.0659      0.35         0         0         0       0.5     0.602         0\n",
      "Evolved fitness:     0.2313    0.5307    0.2322    0.1675   0.01738   0.01499   0.02498\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01375, lrf=0.2067, momentum=0.81847, weight_decay=0.00019, warmup_epochs=1.63, warmup_momentum=0.84293, warmup_bias_lr=0.12283, box=0.02143, cls=0.40097, cls_pw=0.67668, obj=0.92103, obj_pw=0.74445, iou_t=0.2, anchor_t=3.21918, anchors=2.88, fl_gamma=0.0, hsv_h=0.01609, hsv_s=0.741, hsv_v=0.39552, degrees=0.0, translate=0.0659, scale=0.31009, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.61203, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_000257-3c0ld4m2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/3c0ld4m2\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:03<00:00, 643.75it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.31: 1.0000 best possible recall, 8.55 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.606-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.31: 1.0000 best possible recall, 8.51 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.607-mean: 103,139,  169,162,  148,239,  263,212,  172,340,  231,302,  338,273,  298,357,  380,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03386   0.02405   0.02619    0.0841         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02701    0.0265   0.02482   0.07832         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.01849   0.03001   0.02428   0.07278        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G    0.0178   0.02683   0.02434   0.06898        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01719   0.02339   0.02428   0.06487         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01584   0.02097   0.02397   0.06078         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01419   0.01897   0.02404    0.0572         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01285   0.01834   0.02397   0.05516         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01129   0.01705   0.02393   0.05227         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G  0.009917   0.01631   0.02389   0.05012         7       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.262       0.455       0.219       0.156\n",
      "            Rosemary         358         180       0.393       0.572       0.424        0.29\n",
      "  Rosemary Leaf Spot         358          44       0.149       0.182      0.0701      0.0509\n",
      "Rosemary Pest Damage         358         131       0.342       0.631       0.255       0.189\n",
      "Rosemary Powdery Mildew         358          85       0.164       0.435       0.125      0.0947\n",
      "10 epochs completed in 0.096 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▄▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆█▆▅▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.21868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.15614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.26194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.45501\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.00992\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02389\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01508\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02368\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/3c0ld4m2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_000257-3c0ld4m2/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0138     0.207     0.818   0.00019      1.63     0.843     0.123    0.0214     0.401     0.677     0.921     0.744       0.2      3.22      2.88         0    0.0161     0.741     0.396         0    0.0659      0.31         0         0         0       0.5     0.612         0\n",
      "Evolved fitness:     0.2619     0.455    0.2187    0.1561   0.01508    0.0124   0.02368\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01536, lrf=0.20773, momentum=0.77917, weight_decay=0.0002, warmup_epochs=1.64624, warmup_momentum=0.78566, warmup_bias_lr=0.14088, box=0.02444, cls=0.39681, cls_pw=0.80469, obj=1.04862, obj_pw=0.72569, iou_t=0.2, anchor_t=2.68068, anchors=2.90822, fl_gamma=0.0, hsv_h=0.01646, hsv_s=0.741, hsv_v=0.36159, degrees=0.0, translate=0.06492, scale=0.34933, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.56996, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.90822\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_000906-30e1k4d8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/30e1k4d8\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 806.43it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 0.9996 best possible recall, 8.00 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.624-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8713: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 0.9996 best possible recall, 7.94 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.625-mean: 103,139,  169,162,  148,239,  263,212,  172,340,  231,302,  338,273,  298,357,  380,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03682   0.02484    0.0291   0.09076         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02745   0.02703   0.02732    0.0818         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02037    0.0296   0.02686   0.07683         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G    0.0198   0.02659   0.02627   0.07266         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01852   0.02579    0.0265    0.0708         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01801   0.02264   0.02603   0.06669         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01625   0.02056   0.02526   0.06206         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01501   0.01886   0.02429   0.05817         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01347   0.01791   0.02369   0.05507         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01227   0.01674   0.02311   0.05213         1       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.283       0.504       0.319       0.233\n",
      "            Rosemary         358         180        0.38       0.672       0.595       0.414\n",
      "  Rosemary Leaf Spot         358          44        0.13       0.341      0.0699      0.0484\n",
      "Rosemary Pest Damage         358         131       0.415       0.618       0.487       0.378\n",
      "Rosemary Powdery Mildew         358          85       0.208       0.386       0.123      0.0917\n",
      "10 epochs completed in 0.100 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▃▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▅▄▄▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▇█▆▆▄▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.31874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.23289\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.28314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.50441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01674\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01725\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02127\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.0132\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00435\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/30e1k4d8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_000906-30e1k4d8/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0154     0.208     0.779    0.0002      1.65     0.786     0.141    0.0244     0.397     0.805      1.05     0.726       0.2      2.68      2.91         0    0.0165     0.741     0.362         0    0.0649     0.349         0         0         0       0.5      0.57         0\n",
      "Evolved fitness:     0.2831    0.5044    0.3187    0.2329   0.01725    0.0132   0.02127\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.19762, momentum=0.765, weight_decay=0.00025, warmup_epochs=2.10526, warmup_momentum=0.69503, warmup_bias_lr=0.12656, box=0.02903, cls=0.4165, cls_pw=0.88706, obj=1.16852, obj_pw=0.71211, iou_t=0.2, anchor_t=3.14933, anchors=2.92798, fl_gamma=0.0, hsv_h=0.01426, hsv_s=0.5705, hsv_v=0.347, degrees=0.0, translate=0.07676, scale=0.349, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.43736, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.92798\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00025\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_001528-1vu7qsu9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/1vu7qsu9\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 688.19it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.32: 1.0000 best possible recall, 8.50 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.607-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.32: 1.0000 best possible recall, 8.46 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.608-mean: 103,139,  169,162,  148,239,  263,212,  172,340,  231,302,  338,273,  298,357,  380,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.04545    0.0277   0.03294    0.1061         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.03632   0.03037   0.03106   0.09775         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02684    0.0327   0.02994   0.08948         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02419   0.03245   0.02986    0.0865         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.02279   0.03059    0.0298   0.08318         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.02178   0.02764   0.02962   0.07904         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G    0.0201   0.02413   0.02932   0.07355         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01839   0.02264   0.02903   0.07006         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01662   0.02106   0.02859   0.06627        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G    0.0145   0.01994   0.02781   0.06226         3       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.247       0.553       0.326       0.225\n",
      "            Rosemary         358         180        0.32         0.8       0.667       0.418\n",
      "  Rosemary Leaf Spot         358          44        0.13       0.341      0.0764      0.0585\n",
      "Rosemary Pest Damage         358         131       0.349       0.626       0.406       0.309\n",
      "Rosemary Powdery Mildew         358          85       0.188       0.447       0.154       0.116\n",
      "10 epochs completed in 0.104 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▄▄▄▃▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▇██▇▅▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.3259\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.22521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.24693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.55348\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.0145\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02781\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02594\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01545\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/1vu7qsu9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_001528-1vu7qsu9/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.198     0.765   0.00025      2.11     0.695     0.127     0.029     0.416     0.887      1.17     0.712       0.2      3.15      2.93         0    0.0143     0.571     0.347         0    0.0768     0.349         0         0         0       0.5     0.437         0\n",
      "Evolved fitness:     0.2469    0.5535    0.3259    0.2252   0.02057   0.01545   0.02594\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01509, lrf=0.20418, momentum=0.76833, weight_decay=0.00021, warmup_epochs=1.70257, warmup_momentum=0.7361, warmup_bias_lr=0.138, box=0.02379, cls=0.35314, cls_pw=0.86045, obj=1.04472, obj_pw=0.77121, iou_t=0.2, anchor_t=2.73, anchors=3.06014, fl_gamma=0.0, hsv_h=0.01561, hsv_s=0.70727, hsv_v=0.35866, degrees=0.0, translate=0.06407, scale=0.34114, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.65906, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=3.06014\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_002202-37bjpt2n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/37bjpt2n\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 784.84it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 0.9996 best possible recall, 8.07 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.621-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.02 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.623-mean: 103,140,  168,161,  147,239,  263,212,  172,342,  232,302,  338,273,  298,356,  381,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03652   0.02687   0.02729   0.09068         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02922   0.02912   0.02572   0.08405         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02108   0.03216   0.02489   0.07814         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01993   0.02978   0.02482   0.07453         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01868   0.02633   0.02474   0.06976         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01807   0.02398   0.02462   0.06667         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01675   0.02198   0.02472   0.06345         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G    0.0149   0.02054   0.02462   0.06007         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G     0.013   0.01902   0.02458    0.0566         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01125   0.01838   0.02427    0.0539         4       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440        0.23       0.545       0.232       0.157\n",
      "            Rosemary         358         180       0.368       0.665       0.478       0.309\n",
      "  Rosemary Leaf Spot         358          44      0.0956       0.432      0.0919      0.0661\n",
      "Rosemary Pest Damage         358         131       0.306       0.649       0.258       0.183\n",
      "Rosemary Powdery Mildew         358          85       0.151       0.435      0.0997      0.0705\n",
      "10 epochs completed in 0.097 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▃▃▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▄▂▂▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆█▇▅▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.23187\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.15698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.23004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.54536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02427\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01838\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01641\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01419\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00423\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/37bjpt2n\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_002202-37bjpt2n/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0151     0.204     0.768   0.00021       1.7     0.736     0.138    0.0238     0.353      0.86      1.04     0.771       0.2      2.73      3.06         0    0.0156     0.707     0.359         0    0.0641     0.341         0         0         0       0.5     0.659         0\n",
      "Evolved fitness:       0.23    0.5454    0.2319     0.157   0.01641   0.01419   0.02414\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01485, lrf=0.19832, momentum=0.765, weight_decay=0.0002, warmup_epochs=1.69038, warmup_momentum=0.75565, warmup_bias_lr=0.14557, box=0.02352, cls=0.38058, cls_pw=0.81023, obj=1.1197, obj_pw=0.734, iou_t=0.2, anchor_t=2.73, anchors=2.96644, fl_gamma=0.0, hsv_h=0.01706, hsv_s=0.78528, hsv_v=0.34645, degrees=0.0, translate=0.06561, scale=0.33642, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.594, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.96644\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_002811-2nvxi58b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/2nvxi58b\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 832.95it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 0.9996 best possible recall, 8.07 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.621-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.37: 1.0000 best possible recall, 8.02 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.623-mean: 103,140,  168,161,  147,239,  263,212,  172,342,  232,302,  338,273,  298,356,  381,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03602   0.02679   0.02818     0.091         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02844   0.02931   0.02656   0.08431         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02035   0.03172   0.02571   0.07778         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01935   0.03019    0.0257   0.07524        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G    0.0184   0.02717   0.02564   0.07121         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01786   0.02422   0.02539   0.06747         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01652    0.0219    0.0251   0.06353         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01485   0.02053   0.02424   0.05961         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01306   0.01963   0.02309   0.05578         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01199   0.01893   0.02239    0.0533         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.266       0.534       0.316       0.227\n",
      "            Rosemary         358         180       0.355       0.744       0.605       0.411\n",
      "  Rosemary Leaf Spot         358          44        0.11       0.341      0.0556      0.0373\n",
      "Rosemary Pest Damage         358         131       0.381       0.603        0.46       0.358\n",
      "Rosemary Powdery Mildew         358          85       0.216       0.447       0.142       0.101\n",
      "10 epochs completed in 0.100 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▃▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▅▅▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▇█▇▆▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.31578\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.22668\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.26558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.53387\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02239\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02116\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01461\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/2nvxi58b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_002811-2nvxi58b/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0149     0.198     0.765    0.0002      1.69     0.756     0.146    0.0235     0.381      0.81      1.12     0.734       0.2      2.73      2.97         0    0.0171     0.785     0.346         0    0.0656     0.336         0         0         0       0.5     0.594         0\n",
      "Evolved fitness:     0.2656    0.5339    0.3158    0.2267   0.01622   0.01461   0.02116\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01827, lrf=0.13818, momentum=0.73212, weight_decay=0.0002, warmup_epochs=1.21516, warmup_momentum=0.62465, warmup_bias_lr=0.15566, box=0.02, cls=0.2951, cls_pw=0.81295, obj=1.53672, obj_pw=0.734, iou_t=0.2, anchor_t=2.95361, anchors=2.62399, fl_gamma=0.0, hsv_h=0.01809, hsv_s=0.84074, hsv_v=0.33083, degrees=0.0, translate=0.07482, scale=0.39188, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.65112, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.62399\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.0002\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_003431-3pm5imss\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/3pm5imss\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|██████| 1996/1996 [00:01<00:00, 1113.50it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 8.33 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.613-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 8.32 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.613-mean: 103,139,  169,162,  148,239,  263,212,  172,340,  231,302,  338,273,  298,357,  380,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G    0.0318   0.03869   0.02215   0.09265         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02636    0.0414   0.02113    0.0889         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G    0.0202   0.04436   0.02034    0.0849         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02002   0.03879   0.02014   0.07895         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01814   0.03376   0.02017   0.07207         0       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01675   0.03123   0.01996   0.06794         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G    0.0148   0.02823   0.02004   0.06308         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01326   0.02707    0.0201   0.06042         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01115   0.02524   0.02005   0.05645         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.00956   0.02433   0.01978   0.05367         5       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.248       0.498       0.229       0.171\n",
      "            Rosemary         358         180       0.377       0.689       0.408       0.299\n",
      "  Rosemary Leaf Spot         358          44       0.127       0.205       0.101      0.0684\n",
      "Rosemary Pest Damage         358         131       0.314       0.664       0.308       0.241\n",
      "Rosemary Powdery Mildew         358          85       0.174       0.435       0.101      0.0748\n",
      "10 epochs completed in 0.100 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▄▄▄▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▂▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▆▇█▆▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.22937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.17074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.24786\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.49821\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.00956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.02433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01424\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00403\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/3pm5imss\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_003431-3pm5imss/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0183     0.138     0.732    0.0002      1.22     0.625     0.156      0.02     0.295     0.813      1.54     0.734       0.2      2.95      2.62         0    0.0181     0.841     0.331         0    0.0748     0.392         0         0         0       0.5     0.651         0\n",
      "Evolved fitness:     0.2479    0.4982    0.2294    0.1707   0.01424   0.01855   0.01973\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01474, lrf=0.21787, momentum=0.77103, weight_decay=0.00021, warmup_epochs=1.67941, warmup_momentum=0.767, warmup_bias_lr=0.12921, box=0.0244, cls=0.37571, cls_pw=0.853, obj=1.0741, obj_pw=0.734, iou_t=0.2, anchor_t=2.90678, anchors=2.73308, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.69303, hsv_v=0.35409, degrees=0.0, translate=0.06598, scale=0.334, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.61824, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.73308\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_004048-261dnkhi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/261dnkhi\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 843.16it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 0.9996 best possible recall, 8.27 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.615-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8715: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.34: 1.0000 best possible recall, 8.26 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.615-mean: 103,139,  169,162,  148,239,  263,212,  172,340,  231,302,  338,273,  298,357,  380,385\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03791   0.02713    0.0289   0.09394         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02952   0.02974    0.0272   0.08646         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02128   0.03275   0.02627    0.0803        11       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.02068   0.02985   0.02618   0.07671         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G    0.0194   0.02753   0.02597    0.0729        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01846   0.02461   0.02572   0.06879         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01703   0.02232   0.02532   0.06467         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01556   0.02103   0.02436   0.06095         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01378   0.01985   0.02375   0.05738        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01261   0.01881   0.02306   0.05448         6       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.569       0.394       0.328       0.232\n",
      "            Rosemary         358         180       0.444       0.667        0.63       0.424\n",
      "  Rosemary Leaf Spot         358          44           1           0       0.064      0.0511\n",
      "Rosemary Pest Damage         358         131       0.512       0.603        0.47       0.344\n",
      "Rosemary Powdery Mildew         358          85        0.32       0.306        0.15       0.111\n",
      "10 epochs completed in 0.098 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▆▃▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▅▄▄▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▆█▇▅▄▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.32845\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.23249\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.56892\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.3939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02306\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0174\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02073\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00431\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/261dnkhi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_004048-261dnkhi/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0147     0.218     0.771   0.00021      1.68     0.767     0.129    0.0244     0.376     0.853      1.07     0.734       0.2      2.91      2.73         0    0.0164     0.693     0.354         0     0.066     0.334         0         0         0       0.5     0.618         0\n",
      "Evolved fitness:     0.5689    0.3939    0.3284    0.2325    0.0174   0.01388   0.02073\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.19521, momentum=0.7722, weight_decay=0.00019, warmup_epochs=1.77614, warmup_momentum=0.79358, warmup_bias_lr=0.13479, box=0.0246, cls=0.41305, cls_pw=0.74263, obj=1.03148, obj_pw=0.79516, iou_t=0.2, anchor_t=2.44095, anchors=2.96752, fl_gamma=0.0, hsv_h=0.01643, hsv_s=0.72341, hsv_v=0.31391, degrees=0.0, translate=0.0659, scale=0.36794, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.62943, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.96752\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00019\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_004702-1dr9cl4j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/1dr9cl4j\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 812.20it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.41: 0.9987 best possible recall, 7.45 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.641-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8709: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.41: 0.9996 best possible recall, 7.37 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.587/0.871-mean/best, past_thr=0.642-mean: 102,141,  170,160,  148,234,  259,215,  169,348,  232,308,  337,271,  293,357,  383,383\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G    0.0362   0.02518   0.02875   0.09013         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02724   0.02763   0.02708   0.08195         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.01987   0.03014   0.02642   0.07642         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01942   0.02751   0.02612   0.07305         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01831   0.02507   0.02626   0.06964         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01816   0.02225   0.02625   0.06666         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01574    0.0201   0.02621   0.06205         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G    0.0146   0.01915   0.02604   0.05979         9       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01299    0.0176   0.02584   0.05643         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01152   0.01687    0.0253   0.05369         7       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.261       0.432       0.291       0.195\n",
      "            Rosemary         358         180       0.328       0.733       0.614       0.388\n",
      "  Rosemary Leaf Spot         358          44       0.192       0.136      0.0875      0.0596\n",
      "Rosemary Pest Damage         358         131       0.341       0.588       0.343       0.249\n",
      "Rosemary Powdery Mildew         358          85       0.184       0.271       0.121      0.0848\n",
      "10 epochs completed in 0.099 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▃▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▅▃▃▃▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▇█▇▅▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.29129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.19521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.26122\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.43202\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.0253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.0245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01313\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/1dr9cl4j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_004702-1dr9cl4j/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.195     0.772   0.00019      1.78     0.794     0.135    0.0246     0.413     0.743      1.03     0.795       0.2      2.44      2.97         0    0.0164     0.723     0.314         0    0.0659     0.368         0         0         0       0.5     0.629         0\n",
      "Evolved fitness:     0.2612     0.432    0.2913    0.1952     0.017   0.01313    0.0245\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01468, lrf=0.207, momentum=0.75626, weight_decay=0.00024, warmup_epochs=1.63, warmup_momentum=0.83061, warmup_bias_lr=0.14376, box=0.0244, cls=0.42887, cls_pw=0.853, obj=0.96808, obj_pw=0.74293, iou_t=0.2, anchor_t=2.54366, anchors=2.88, fl_gamma=0.0, hsv_h=0.01495, hsv_s=0.76559, hsv_v=0.35882, degrees=0.0, translate=0.06268, scale=0.3744, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.53564, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.88\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7263185 parameters, 7263185 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00024\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_005319-3c748a6t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/3c748a6t\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 789.42it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.39: 0.9992 best possible recall, 7.72 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.589/0.868-mean/best, past_thr=0.632-mean: 111,142,  189,162,  157,244,  291,212,  176,356,  235,295,  357,285,  298,362,  384,390\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8713: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.39: 0.9996 best possible recall, 7.68 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.588/0.871-mean/best, past_thr=0.634-mean: 103,142,  170,161,  149,242,  168,344,  266,219,  232,308,  343,277,  292,358,  381,383\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.805G   0.03607   0.02248   0.03247   0.09101         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.805G   0.02712   0.02461   0.03065   0.08237         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.805G   0.02007   0.02663   0.03005   0.07676         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.805G   0.01881   0.02518   0.02996   0.07396         6       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.805G   0.01776   0.02357   0.02926   0.07059         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.805G   0.01728   0.02211   0.02849   0.06788         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.805G   0.01666    0.0199   0.02757   0.06414         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.805G   0.01521   0.01855   0.02636   0.06011         7       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.805G   0.01385   0.01716   0.02518   0.05619         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.805G   0.01284   0.01633   0.02481   0.05398         8       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.286       0.495       0.323        0.21\n",
      "            Rosemary         358         180       0.379         0.8        0.64       0.363\n",
      "  Rosemary Leaf Spot         358          44       0.211       0.159      0.0908      0.0677\n",
      "Rosemary Pest Damage         358         131       0.363       0.656       0.451       0.328\n",
      "Rosemary Powdery Mildew         358          85        0.19       0.364        0.11      0.0809\n",
      "10 epochs completed in 0.093 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▃▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▆▆▅▄▄▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▅▇█▇▆▅▃▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.32281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.20995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.2855\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.49491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01284\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01633\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01267\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00415\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/3c748a6t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_005319-3c748a6t/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0147     0.207     0.756   0.00024      1.63     0.831     0.144    0.0244     0.429     0.853     0.968     0.743       0.2      2.54      2.88         0    0.0149     0.766     0.359         0    0.0627     0.374         0         0         0       0.5     0.536         0\n",
      "Evolved fitness:     0.2855    0.4949    0.3228      0.21   0.01747   0.01267   0.02251\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0152, lrf=0.19333, momentum=0.76393, weight_decay=0.00021, warmup_epochs=1.78799, warmup_momentum=0.75812, warmup_bias_lr=0.12491, box=0.02596, cls=0.38818, cls_pw=0.853, obj=0.94427, obj_pw=0.74047, iou_t=0.2, anchor_t=2.50906, anchors=2.07868, fl_gamma=0.0, hsv_h=0.0164, hsv_s=0.71924, hsv_v=0.347, degrees=0.0, translate=0.07189, scale=0.35563, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.5427, mixup=0.0\n",
      "Overriding model.yaml anchors with anchors=2.07868\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [4, [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients, 16.9 GFLOPS\n",
      "\n",
      "Transferred 258/370 items from yolov5s.pt\n",
      "Scaled weight_decay = 0.00021\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.18\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/lab03/EvolveYOLO/yolov5/wandb/run-20220622_005916-2b6b7qnw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mevolve\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/2b6b7qnw\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Rosemary-5/train/labels.cache' for images and labels... 1996 fo\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.0GB): 100%|███████| 1996/1996 [00:02<00:00, 755.41it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 0.00, Best Possible Recall (BPR) = 0.0000. Attempting to improve anchors, please wait...\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 6 anchors on 2398 points...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Rosemary-5/valid/labels.cache' for images and labels... 358 found\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.40: 0.9983 best possible recall, 5.22 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.601/0.839-mean/best, past_thr=0.641-mean: 140,150,  185,250,  176,349,  316,239,  273,340,  374,374\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8446: 100%|█| 1\u001b[0m\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.40: 0.9987 best possible recall, 5.12 anchors past thr\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=6, img_size=416, metric_all=0.593/0.845-mean/best, past_thr=0.639-mean: 113,142,  182,186,  168,305,  295,241,  259,329,  363,365\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
      "\n",
      "Image sizes 416 train, 416 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/evolve\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/9    0.887G   0.03821   0.02237   0.02945   0.09004         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       1/9    0.889G   0.02815   0.02495   0.02751   0.08061         5       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       2/9    0.889G   0.02117   0.02578   0.02657   0.07352         2       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       3/9    0.889G   0.02122   0.02485   0.02541   0.07147         4       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       4/9    0.889G   0.01955   0.02315   0.02498   0.06768        10       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       5/9    0.889G   0.01905   0.02087    0.0244   0.06432         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       6/9    0.889G   0.01735   0.01907   0.02307   0.05949         3       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       7/9    0.889G   0.01591   0.01772   0.02293   0.05656         1       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       8/9    0.889G   0.01391   0.01649   0.02259   0.05298         8       416\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       9/9    0.889G   0.01292   0.01514     0.022   0.05007         1       416\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         358         440       0.295       0.472       0.341       0.225\n",
      "            Rosemary         358         180       0.317       0.744       0.617       0.349\n",
      "  Rosemary Leaf Spot         358          44       0.156       0.136      0.0991      0.0697\n",
      "Rosemary Pest Damage         358         131       0.469       0.641       0.522       0.385\n",
      "Rosemary Powdery Mildew         358          85       0.238       0.365       0.125      0.0944\n",
      "10 epochs completed in 0.101 hours.\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▅▃▃▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▅▄▄▃▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▆▇█▇▆▅▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁▁▁▁▁▁▁▁█\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁▁▁▁▁▁▁▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁▄▆█▇▇▅▄▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.34099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.22456\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.29503\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.47168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.01292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01514\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.01956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01194\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mevolve\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/angelajlee/runs/runs/2b6b7qnw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220622_005916-2b6b7qnw/logs\u001b[0m\n",
      "\n",
      "       lr0       lrf  momentumweight_decaywarmup_epochswarmup_momentumwarmup_bias_lr       box       cls    cls_pw       obj    obj_pw     iou_t  anchor_t   anchors  fl_gamma     hsv_h     hsv_s     hsv_v   degrees translate     scale     shearperspective    flipud    fliplr    mosaic     mixup\n",
      "    0.0152     0.193     0.764   0.00021      1.79     0.758     0.125     0.026     0.388     0.853     0.944      0.74       0.2      2.51      2.08         0    0.0164     0.719     0.347         0    0.0719     0.356         0         0         0       0.5     0.543         0\n",
      "Evolved fitness:      0.295    0.4717     0.341    0.2246   0.01956   0.01194   0.02083\n",
      "\n",
      "train.py:576: UserWarning: loadtxt: Empty input file: \"evolve.txt\"\n",
      "  x = np.loadtxt('evolve.txt', ndmin=2)\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 579, in <module>\n",
      "    w = fitness(x) - fitness(x).min()  # weights\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/numpy/core/_methods.py\", line 43, in _amin\n",
      "    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n",
      "ValueError: zero-size array to reduction operation minimum which has no identity\n",
      "CPU times: user 2min 13s, sys: 1min 25s, total: 3min 39s\n",
      "Wall time: 1h 34min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!python train.py \\\n",
    "--img 416 \\\n",
    "--batch 8 \\\n",
    "--epochs 10 \\\n",
    "--data {dataset.location}/data.yaml \\\n",
    "--cfg ./models/custom_yolov5s.yaml \\\n",
    "--weights yolov5s.pt \\\n",
    "--project YOLOv5_Rosemary \\\n",
    "--name rosemary_evolve \\\n",
    "--cache \\\n",
    "--hyp \"./data/hyp.scratch.yaml\" \\\n",
    "--evolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJVs_4zEeVbF"
   },
   "source": [
    "# Evaluate Custom YOLOv5 Detector Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KN5ghjE6ZWh"
   },
   "source": [
    "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
    "\n",
    "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kill 17409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOy5KI2ncnWd",
    "outputId": "fb342fb9-efd2-4ce6-e8f1-0b8565cb7750",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start tensorboard\n",
    "# Launch after you have started training\n",
    "# logs save in the folder \"runs\"\n",
    "# %load_ext tensorboard\n",
    "# # %reload_ext tensorboard\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C60XAsyv6OPe",
    "outputId": "47306a82-ad80-4f63-e983-0c25cc2de7f1"
   },
   "outputs": [],
   "source": [
    "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
    "from utils.plots import plot_results  # plot results.txt as results.png\n",
    "Image(filename='./runs/train/yolov5l6_rosemary4/results.png', width=1000)  # view results.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLI1JmHU7B0l"
   },
   "source": [
    "### Curious? Visualize Our Training Data with Labels\n",
    "\n",
    "After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n",
    "\n",
    "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W40tI99_7BcH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print out an augmented training example / Mosaic Augmentation 적용된 train 이미지\n",
    "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
    "Image(filename='./runs/train/yolov5l6_rosemary/train_batch0.jpg', width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PF9MLHDb7tB6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display our ground truth data / test 데이터 정답값\n",
    "print(\"GROUND TRUTH TEST DATA:\")\n",
    "Image(filename='./runs/train/yolov5l6_rosemary/test_batch0_labels.jpg', width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display our prediction / test 데이터 예측 결과값\n",
    "print(\"PREDICT TEST DATA:\")\n",
    "Image(filename='./runs/train/yolov5l6_rosemary/test_batch0_pred.jpg', width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3qM6T0W53gh"
   },
   "source": [
    "#Run Inference  With Trained Weights\n",
    "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIEwt5YLeQ7P"
   },
   "outputs": [],
   "source": [
    "# trained weights are saved by default in our weights folder\n",
    "%ls ./runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SyOWS80qR32"
   },
   "outputs": [],
   "source": [
    "%ls ./runs/train/yolov5l6_rosemary/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./detect.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "!cd ./\n",
    "!python detect.py --weights runs/train/yolov5l6_rosemary/weights/best.pt --img 256 --conf 0.4 --source data/images/rosemarytest1.jpg\n",
    "Image(filename='./runs/detect/exp/rosemarytest1.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nmZZnWOgJ2S"
   },
   "outputs": [],
   "source": [
    "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
    "# use the best weights!\n",
    "%cd ./\n",
    "!python detect.py --weights runs/train/yolov5l6_rosemary/weights/best.pt --img 256 --conf 0.4 --source Rosemary-3/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odKEqYtTgbRc"
   },
   "outputs": [],
   "source": [
    "#display inference on ALL test images\n",
    "#this looks much better with longer training above\n",
    "\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('./runs/detect/exp2/*.jpg'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the mAP on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd ./\n",
    "!python test.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd ./\n",
    "!python test.py --weights runs/train/yolov5l6_rosemary/weights/best.pt --data models/custom_yolov5s.yaml --img 256 --name yolo_test_rosemary --task 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uPq9mVgiBql"
   },
   "source": [
    "# Export Trained Weights for Future Inference\n",
    "\n",
    "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1x_wg3VeiXMW"
   },
   "outputs": [],
   "source": [
    "%cd ./\n",
    "# %mkdir YOLO v5 Weights\n",
    "%cp ./runs/train/yolov5l6_rosemary/weights/best.pt /home/lab03/MultiCampus/YOLOv5Weights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVpCFeU-K4gb"
   },
   "source": [
    "## Congrats!\n",
    "\n",
    "Hope you enjoyed this!\n",
    "\n",
    "--Team [Roboflow](https://roboflow.ai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_latest_p37]",
   "language": "python",
   "name": "conda-env-pytorch_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
